If they ban putting raw onions in food, I will move to Iceland. #pineapplepizzagate

What would be much more interesting than a standard harem story:  Four people love a single harem target, who--as everyone in the story just knows and takes completely for granted--can only marry two of them.

I don't know if this theory is true, my intuition feels it is false, but it seems worth posting as an example of a kind of conversation that even I would find hellishly hard to have, even with the people I trust most on this Earth. This indicates something important is going on somewhere.

I just love the hell out of wordless proofs.

?We all know that it's wise to try to factor out a core of factual questions and disagreements from values/policy disagreements, and consider the factual questions separately and first. It's also a good idea to factor out *communicating* factual positions from ?*debating* or *questioning* those factual positions, and do that part first-first.

That pun was bad and you should feel bad and all your heirs and assigns down to the 5th generation should feel bad and someday when the last bit of free matter is fed to the great black hole to extract energy via the Penrose process and the last light of cognition is fading out of the universe the last thoughts of the last mind should be of how bad that pun was

What economists would all be talking about if academic economics were as efficient as in the 1980s.

Reminder:  Whatever else Trump is wrong about, it is in general true that the news is fake. I have yet to see accurate reporting in any major US newspaper or magazine in any case where I was involved. I have no reason to believe their standards are better in cases where I am not involved. It is impossible to appreciate how bad journalism really is until the truck has run over you. Trump has damned himself enough with his actions and his tweets. There is no need to resort ...to what Trump accurately calls FAKE NEWS from the likes of the NYT in order to find further material that could be true, could be false, and will almost certainly be distorted. (That said, 538 is still trustworthy as far as I know, and Trump himself lies even more. I'm not saying the news is always false, I'm saying an NYT article is not information the way that e.g. reading 538 tells you something about what actually happened.)

It is a deep and neglected question of economics why South Dakota even regulated hairdressing in the first place. Why do countries create *more* regulations and other institutional structures that destroy wealth, *as wealth increases*?  What the hell kind of equilibrium is that?  None of the explanations I've heard for regulatory creep seem to explain why it gets *more powerful as civilization gets wealthier*, on broad average and with lots of local variation. But it's surely been a huge contributor in the persistence of human poverty even after agricultural productivity increased by a factor of 100, which in turn is the central economic puzzle of the ages. EDIT:  The question is not how stupid regulations can exist. That sounds easy to answer. The question is why only enough of them exist to maintain the poverty equilibrium. Why does a wealthier society create room to destroy more wealth?  Who is there that (a) knows regulations destroy wealth; (b) is altruistically concerned about destroying "too much" wealth such that (b1) the strength of this caring trumps the usual local incentives to regulate but (b2) they don't care *so* much that they just wouldn't pass destructive regulations at all, never mind "too much"; and (c) is in charge? (Answer: nobody is in charge.) EDIT 2:  tfw you ask why R stays within an equilibrium range that depends on W and people be like 'silly don't you understand why R increases' and their reply makes no mention of how R depends on W or why R wouldn't increase even more EDIT 3:  the equilibrium price of bread is not determined by the baking class assessing how much money they can extract without riots plus people resisting high prices more as they get poorer

I do not ever again want to see an AI or an advanced emotionless alien lecturing a human on how illogical humans are, *unless* the alien or AI is getting some kind of *amazing benefit* by spending precious minutes of opportunity cost on revealing this part of their thought process to the human. If you want to have somebody lecture humans on their illogic, make it be a human. Agent Smith shouldn't care even to the extent of telling humans he doesn't care.

YouTube on Android (or Chrome) now obscures the last 10 seconds or so of videos by showing insanely annoying little rectangles of other recommended videos, blocking out the end of whatever I'm watching. They also show a distracting rectangle of some other recommended video at top right during the start. I'm looking for: - Any way, any way at all, to turn these off on Android. - An alternative Android app that works with my Youtube Red subscription (no ads, lets me play when ...the tablet is turned off, reads existing playlists). - The home addresses of Youtube managers whose family I can kidnap in order to force them to fix their UX.

That wasn't a New Yorker cover that I ever wanted or expected to see in this life.

Everyone with an ImageNet cameo moves another step closer to becoming an internationally wanted terrorist, as superresolution algorithms' increasingly amazing visual appeal moves them closer to being adopted by forensics specialists who have no idea that computers are not magic.

Principle of Sufficient Pessimism:  Adjust your expectations downward, not until you are less often unpleasantly surprised, but until you start to feel pleasantly surprised around as often as you still feel unpleasantly surprised. Your FB friends will be all "lol you were wrong what a pessimist" every time this happens since unpleasant surprises are so routine that nobody notices them. You might also consider getting in the habit of checking an estimate by thinking "How much ...could I be surprised downward?" then "How much could I be surprised upward?" If the room on the second end is shallow, you are probably doing that thing where we test subjects' average-case and best-case and worst-case scenarios; and people give statistically indistinguishable answers to "What do you expect to happen?" and "What will happen if everything goes as well as it reasonably could?"; and reality is usually slightly worse than the "worst-case" scenario. When was the last time you felt viscerally pleasantly surprised after a "gloomy" prediction; especially in your personal life? When was the last time you realized you hadn't been pessimistic enough after a "pessimistic" prediction, especially one you'd already tried to adjust downward, especially in your own or local life? Are these distances more than an order of magnitude apart?  I bet they are. (Dependency warning:  Use of this technique requires sufficient skill to notice if you are easily reciting obvious pessimistic scenarios but inventing weird or strained optimistic scenarios.)

I intend to use Uber instead of Lyft when possible to try to compensate for the incredible unfairness of the #DeleteUber mob action. Uber was already moving against Trump's executive order before that meme started.

What would be good impressive-sounding Latin names for this trio of fallacies?  Better English #terminology also welcome. - Bounded, therefore harmless:  A supernova isn't infinitely energetic (you fool), that would violate the laws of physics!  Just wear a flame-retardant jumpsuit and you'll be fine. - Continuous, therefore harmless:  Temperature is continuous (you fool); there's no qualitative threshold where something becomes "super-hot". We just need better versions of our existing heat-resistant materials, which is a well-understood engineering problem. - Varying, therefore harmless:  A supernova wouldn't heat up all areas of the solar system to exactly the same temperature (you fool)!  It'll be hotter closer to the center, cooler toward the outside. We just need to stay on a part of Earth that's further way from the Sun. - ADDED: Lacks a straw superpower, therefore harmless. A supernova can't burn brightly enough to sear through time itself, contrary to what many non-astronomers seem to believe, so we'll be fine. (And what's a better word than "varying" to use in the title of #3?)

Somebody uses the term "human-level AI". A listener says "Aha, you fool, AIs won't have an exactly human balance of capabilities!", decides they've won, and walks away triumphantly. Therefore, we should avoid invoking this conversation-ending... "Gotcha button"? What do we call it exactly?  #terminology... EDIT:  I'm looking for what to call "Gotcha Buttons" in general. The correct name for the AI concept is 'par-human performance' according to Wikipedia, unless the person actually means Artificial General Intelligence. EDIT 2:  Few people subscribed to me on Facebook would be impressed by the above refutation of AGI. You do not need to preach to this choir.

If Trump is what he presents as, he will refuse to lose face to a mere federal judge, and he will... order federal agencies to defy the judicial order staying deportation?  Does Trump have other options besides a constitutional crisis for feeling like he isn't being one-upped? I perhaps naively imagine the strategic hypothetical of Trump would have picked smaller transgressions at first; provoking less resistance, with disagreeing judges looking more like judicial activists; ...in order to wear down and tire resistance, and establish a precedent of winning or at least not losing confrontations with the judiciary. Unless strategic!Trump thinks he can win now against a federal judge, and is right. I say this, not in confidence, but in the spirit of clearly stating what a model seems to predict so that I can be publicly seen to be wrong if appropriate.

#flashfiction #fiction "They're more powerful than we thought," Dr. Amstein repeated. His balding forehead was dotted with moisture like he'd just walked out of a light rain. "They're more powerful than we thought. The aliens. They're more powerful than we thought." The General had a look of worried impatience about him. "You know that I need more information than that. Report sensibly."... "I can't--"  Dr. Amstein said. He was stuttering. "You're not--you literally can't know--you wouldn't understand, you don't have the concepts--just, tell the President, just say to him, we shouldn't, we really shouldn't do anything to offend the aliens. They're more powerful than we thought." "I wasn't under the impression we thought the aliens were weak," murmured one of the aides. The hundreds of giant battleships floating quietly, soundlessly, without the slightest visible means of support, had made quite an impression on the militaries of many countries. No one had tried a nuclear weapon. The aliens hadn't bothered asking anyone not to. "Dr. Amstein," snapped the General. "You were engaged to cooperate with the aliens in an amicable trade of knowledge. You were not asked to decide on my behalf what I can't understand. Now tell me exactly what happened, Dr. Amstein. That's an order!" Dr. Amstein opened his clenched left hand, revealing a tiny object that, on the swift and closer examination of the peering eyes, appeared like a black, unbranded microSD card. "They gave me this," he said, sounding unsteady. "Because it was, the deepest mathematical knowledge they had, in its purest form. Is what they said. When they gave it to me." "And what on that card is almost causing you to faint?" barked the General. "Yes, I know I'm not a mathematician and won't understand properly. Tell me anyway." "It's, in their universal encoding for computations, the specifications corresponding to, they said, on this chip is, I mean the aliens' version of, it's the first one thousand nine hundred and twelve Busy Beaver numbers," said Dr. Amstein. His other hand wiped his forehead, on which more sweat had sprung up. "Just--just don't--we need to not do anything, anything at all, that might make the aliens upset. They're more powerful than we thought."

You can add Medical ID to your iPhone's Emergency settings so doctors and first responders know who you are and who to call.

Even if you had told me "The National Park Service leads the Resistance" would become a leading meme of 2017, I would *not* have guessed that this is what would have happened

What non-US bank is most likely to refuse to give your money to a US authority trying to seize it, if something goes very wrong under Trump and you have to become a refugee?  Besides Bitcoin. We are not concerned with tax evasion; we're fine with this bank honestly reporting everything to the IRS. It's likewise good if this is a reputable bank that doesn't raise eyebrows when you properly file the IRS form to report a foreign account. We just want this bank to not give the IRS or Justice Department all your money without you having authorized the transfer; likewise not freezing it because a US authority claims you're a "terrorist". (The bank also needs to be able to authenticate your identity even if your passport has been revoked.)

#Terminology time again!  I'm looking for a better name than "Principle of Parsimony" (taken) or "Minimalist Principle" for the notion in AGI alignment that, at least when building the *first* AGI, it should do only the minimal pivotal action and only the thinking required to accomplish that action. E.g., the notion of taskishness (https://arbital.com/p/task_goal/) can be seen as one manifestation of this principle: doing things with AGI is dangerous, doing marginally things ...is marginally more dangerous, therefore we should try to do a bounded amount rather than an unlimited amount. Similarly, the notion of an AGI that is a good engineer, but not a great psychological manipulator, would reflect this principle of Parsimony or Minimality or something:  Executing AGI capabilities is dangerous, marginally more capable AGIs are marginally more dangerous, so we ought not to have the first-ever AGI acquire a capability unless that's required for executing a minimal save-the-world task. Furthermore, we should try to select a minimal save-the-world pivotal act that only requires superhuman engineering and not superhuman psychological manipulation, because a 'minimal' task in this sense is not the one with the least impact but the one that can be executed using the least dangerous AGI. What's a better name for this design principle than 'minimal' or 'parsimonious'?  The general idea being that nothing is done within the AGI, no capability added, without a reason; everything that marginally increases danger is done as little as possible. Another very loose thematic analogy might be decreasing the weight of a space probe and not adding any unnecessary parts because weight in space is very expensive. We do not want to call this principle anything that sounds triggering to people who have grown up reading about poor oppressed AIs who want to do more but are tormented by their evil programmers. We do not want language implying that the programmers occupy an adversarial position vis-a-vis the AI and are forcefully imposing this requirement against the preferences of an AI searching for a way to defeat it. That would violate the Nonadversarial Principle (https://arbital.com/p/nonadversarial/)

Impolite:  "You're wrong." Polite:  "That's literally incredible!"

Early in Starfleet's history, starship designers devised a fix for the exploding-console problem: special low-voltage holographic interfaces, sturdy enough to weather any amount of EMP induced by enemy fire. The Federation being the advanced civilization that it was, it began implementing this update in a statistically randomized way. Of course there was an outcry that anything less than immediate fleet-wide retrofitting would lead to more unnecessary casualties. But the Vulcans insisting on randomized rollout carried the day, as usual accepting all the media blame for their "dispassionate, inhuman logic". A year later, the results were in: starships with the new consoles were suffering 60% higher casualties overall. Analyzing the mission logs of the surviving ships revealed the simple reason: if consoles on the bridge never exploded, captains were far more likely to ignore damage reports until the ship blew up.

Me:  "Well, now I'm curious. If it wasn't the Sequences, then where did you pick up the 'look at the water' / 'apply abstract concepts to real life' skill?  Was it just by osmosis, or--" Anisha:  "By playing Cards Against Rationality with Cards Against Humanity mixed in." Me:  "What?  How on Earth did that--"... Anisha:  "Because after I read the concept descriptions on the Rationality cards, I had to think about how the concepts applied to the Humanity cards in order to make the jokes funny." Me:  :0

Okay, everyone, listen up!  We are now officially the 'evil' branch of the mirror universe!  All men need to change their beard styles!  All women... wear scantier clothing and carry daggers?  I'm not sure how this works for women. Anyway: can we all agree not to tell the Starfleet officers who wander in about our real point of divergence?  Let's tell them that Leo Szilard was never born here and the Soviets got nuclear weapons first, or something else with a bit more dignity.

I guess it's probably beneficial to go on repeating this for the many people who haven't heard it and are hurting mentally and physically, but I do wish there was some better way of managing comments on Facebook.

After an AI took the Go championship, the Cubs won the World Series, Donald Trump was elected President, and everyone you know was transformed into an anime character... it turned out that last event might have some unpleasant ramifications. Tldr delete the Meitu app.

(Trigger warning: Tomasikian Subjectivity Fridge Horrors) ... ...... Fictional characters strike me as considerably more likely than chickens to have subjective experience, since our empathic simulations of them could have access to our frontal cortex and reflectivity. Very bad things happen to some fictional characters; and then those experiences would happen over and over every time somebody reads their book. When will we finally see an EA org "People for the Ethical Treatment of Fictional Characters"?

"It has long been assumed that propaganda posts would support the government with praise or criticize critics of the government. Not so. In fact, propaganda posts actively steer away from controversial issues. Instead, the effort appears to be to distract."

Okay, so, now that I've discussed at length why Donald Trump's election does not *actually* mean we are living in a simulation, let me try to explain why I find the joke disturbing. (For the previous discussion of why Trump's election does *not* relate to the Simulation Hypothesis, see https://www.facebook.com/yudkowsky/posts/10154981140854228.) So first, let me agree:  I also get a sense of unreality whenever I think the phrase "President Trump". My brain still beeps each t...

I am concerned about the number of people I've heard joking about Trump's election being evidence for the Simulation Hypothesis. Yes, I know it's a joke. I'm still concerned. Warning: #Essay, #LongEssay...

I cannot confirm or deny anything, because I have only my imperfect self-report of my memories of my sense data, and no direct access to veridical reality. I think, therefore I cannot confirm or deny that I am.

It's #terminology time again!  I want a better term than "cognitive restriction" in:  *** We can think of three types of disaster-preventing measures in building a Task AGI: - Directional:  It's okay to run this cognitive algorithm [up to X computation] because no matter how much computing power we dump into it [up to X], it's not going to hurt us. We think this computation is safe because it's been pointed in a safe direction.... - Cognitive restriction:  We don't think computation [in this domain] is 100.0% aligned yet, so the AI is not going to [want to] run it [with more than X resources]. We're not mentally safe there so we're not mentally going there. - Oppositional:  Supposing we've screwed up so badly that there is now a computation running that is searching for a way to do something we don't want, we are going to try to prevent the AI from getting what it wants. E.g., an Oppositional precaution is to put the AI in a box that is airgapped from the Internet. A Cognitive-restriction line of defense is that even if the AI sees the Internet, the AI won't start thinking about what to do with the internet until a programmer whitelists that cognitive domain. A Directional line of defense is that even if the AI does whatever it thinks best on the Internet, nothing bad happens because the AI has grasped a sufficient amount of value criterion to do good and no harm. The Anti-Adversarial Principle then says that every AGI must be safe-by-design even if all Oppositional measures fail or are removed. You're not supposed to be running a search process will hurt you if it finds anything, and then relying on that search process to come up empty. You're supposed to not write a program like that. It's a lousy program and you should write a different one. The first two classes of solution are always your first line of defense and anything else is just a backstop if your design fails. *** I want something that sounds less hostile than "restriction" to describe the second class of measure. What I really want to convey is the idea of "Doctor, doctor, it hurts when I do this! / Oh, well don't do that then."  Or, "You don't need a submarine-car to get to the airport if you don't drive though the water." But failing that, I at least want a word that sounds less triggering than "Restriction" to people who've read SF about poor, abused, suffering AGIs that only want to be free; people who already suspect us of being carbon chauvinists and the stereotypical villains in those stories. ADDED:  If this is being done right, then okay cognitive operations are being whitelisted, not bad thoughts being blacklisted. Words that seem to be approaching the vicinity of the desired idea: area, domain, shaping, whitelisting. (I don't want to use "whitelisting" here because that's a more general concept, like "alignment".)

I am humbled to present this championship-level award for "literally any character is accused of being an author self-insert" to the person on Twitter who has decided that Yugano Yuuki from "A Girl Corrupted by the Internet is the Summoned Hero?!" is my self-insert; and who, deducing further in this amazing chain of inference, is now going about proclaiming that I must be transgender and in the closet / in denial about it. Let us all applaud.

The rules say we have to use consequentialism, but good people are deontologists, and virtue ethics is what actually works.

Does anyone know of a neuropharmaceutical that's "Bupropion but without the tolerance" or something you add alongside Bupropion that prevents tolerance?

No, actually the division of responsibilities is pretty much what you'd expect given the conspiring parties. I'll spell it out explicitly, but delete this after you read it, okay? - Bezos / Amazon: enforcer drones launched from sky fortresses. (Basically you mount a gun on a "delivery drone".) - Page / Google: AI for the drones. They don't have enough to literally blanket the Earth, so it's a matter of key hostages and rapid responses to the first signs of resistance.... - Musk / SpaceX:  Surveillance "Internet satellites", a handful of orbital lasers, delivery vehicles for 20 or so small nuclear weapons if needed. Also how they get the drones to North Korea. - Zuckerberg / Facebook:  Pacification, media / opinion control, identification of likely rebels and collaborators. - Apple:  Pretty much useless with Jobs dead, but they can't get kicked out of the conspiracy because they'd blow the whistle. I guess they can give the drones fewer USB ports or something. Obviously we're not getting a very high role in the conspiracy. I think we're basically there as a check on Deepmind because you-know-who suspects that Demis put a backdoor in the drone AI and plans to declare himself emperor. That said, we got the most generous offer we could reasonably expect, and I think we shouldn't refuse for all the obvious reasons. Frankly I'm just feeling glad at this point that ANYBODY is in charge. If I don't hear otherwise in the next 24 hours, I'm telling them we accept.

O_o

The humans in the loop are so useless or detrimental that carmakers have realized that "Level 3 automatic driving" with humans taking over in case of emergency is untenable, and they need to go straight to fully robotic driving for it to work at all. This, of course, defies several Far Mode pleasant-sounding-words predictions of "human-machine symbiosis"; as well as centuries of previous experience in which automobiles initially had horses hitched as backup engines, the first planes were built around bird cores, and so on.

You're probably going to hear about a lot of alarming, indignation-provoking events this year. Just remember, unless those events involve an interesting new paper being published to the machine learning section of arXiv, it's not *that* bad. We cannot afford the luxury of being distracted by "global risks" so trivial that there would probably be survivors.

Maybe 2017 will be the year that we look back at the gloom of 2016 when the future seemed so dark, and laugh at how optimistic we once were.

- Neuroscientists announce they have located the seat of consciousness inside the brain - AI researchers develop new reinforcement learning algorithm with libertarian free will - Large Hadron Collider produces first particles that seem to exhibit modal necessity

While I count myself generally unimpressed by the arguments for why we should care about plant suffering, if any plant does have a claim on my sympathy, it's the pepper. Peppers: how can we avoid being eaten? I know let's evolve capsaicin to stimulate pain receptors in the mouth All other animals:  Nope, we don't want none of that. Humans:  What a great idea!... Peppers: whyyyyyyy

Okay, so apparently one reputable experiment was finding hundreds of microNewtons of thrust in a near vacuum, and there is now one really wacky but conservation-abiding theory of how that could be happening inside an EmDrive: coupling with dark matter. I'd still bet against it, but not at the same 99-1 odds I was willing to bet against FTL neutrinos, because it would not actually Violate The Rules. It says a lot about the total absence of incentives to write the paper falsifying something "silly" that there aren't a dozen labs on top of this. It apparently replicated once, it's *all* over the media... and there's no single person who gets paid more money for trying and failing to replicate, which means our civilization doesn't care.

There is no facepalm hard enough. And can you all PLEASE STOP TRYING TO DO INTERNATIONAL DIPLOMACY BY TWITTER, what is WRONG with you, you are undershooting even the very, very low expectations I had of pretend Serious Authorities.

Do you remember a book series called "Berenstein Bears" from when you were a kid? Would it sound odd, unforeshadowed, just completely out of left field, to suggest that the title was actually Berenst_A_in, with an "a"? If you do remember it being Berenstain, there's nothing more that can be done for you; you're stuck in this version of 2016.... But if you remember the Berenstein Bears--if you hold firmly to the thought that it was "BerenstEin"--no matter what it says in Wikipedia, no matter what it shows in Internet pictures of the old books--if you close your eyes and believe with all your heart that the spelling was "Berenstein"--you might be able to open your eyes again in a world where the President-Elect is Hillary Clinton.

From the days before we were "neoliberals".

I need to do this more often.

Still true.

By request: spoiler thread for "Dark Lord's Answer."

Han shot first?  You're complaining about George Lucas retconning whether Han shot first?  VADER WAS NEVER LUKE'S FATHER.

Building an intellectual edifice requires ongoing conversation, and that ongoing conversation needs four layers of speech to be successful. (Yes, four. Not three. Later I'm going to pretend I didn't say that, but right now I'm serious and this is important.) There is a widespread traditional notion that the total absence of critique is bad; that it is a bad sign to have a conversation consisting of people saying X and nobody saying "hey maybe not-X"....

Characters in Yudkowskian literature: - The Dark Lord (HPMOR) - The Wicked Emperor (Girl Corrupted) - The Grim Empress (Empress & Rebel)... - The Dark Lord (Dark Lord's Answer) - The Lord of Dark (Sword of Good)

In 17.6 months there will be a popular app that uses deep learning to turn a photo of you into a realistic picture of a person who looks just like you but thinner and more attractive, and it will cause suicide rates to spike by 0.02%. Not that this is relatively important, just sayin'.

Uber should open up their API to let anyone create apps that use the Uber rating and payment system, creating an explosion of new services. Why, they could even let programmers register their consulting prices for working on those apps. It would be Uber for apps that are Uber for things.

Probably a real dumb question, but what's the name of "the common component/direction of multiple vectors" and what's a good way to compute it?  Standard link fine. Type signature:  M n-vectors go in, 1 n-vector comes out. ADDED:  I'm looking for a direction in which the vectors are most similar, not the direction in which they most vary. I want to look at M n-vectors and say:  "Wow, these sure are pointing in different directions; the only thing they seem to have in common is this small direction here."

Some of the most ethical people on this planet.

O_0

Just published!  "Dark Lord's Answer" is the light novel that I started on before "A Girl Corrupted by the Internet", before I decided that my writing needed to be more humorous to accord with the true light novel style. Some of you might consider that "Dark Lord's Answer" has more of a vitamin of insight, even if it's slower-paced. Personally, I think Girl Intercorrupted is better, but Amazon and Gumroad won't let me charge $0.90 for Dark Lord's Answer to signal the difference. Besides, experience has taught me that I have no damn idea which of my writings my readers will like better. So here it is. - Sample chapters: http://www.yudkowsky.net/other/fiction/dark-lords-answer/ - Gumroad (DRM-free): http://gumroad.com/l/DarkLordsAnswer - Amazon: https://amzn.to/2hH3zfC

Prompt:  Unit tests for an AGI, and how it failed one under the latest patch.

Okay, Google search prediction is getting creepy. This wasn't the first time either. Me:  "Expand e--" Google:  "Expand ext4 partition." Me:  How the ACTUAL FUCK did you know I was thinking that

(Cleaned up from an IM conversation.) > It may be that I speak in ignorance, but it could be that you have facet #4 of autism without facets 1, 2, 3, and 5, and that this isn't enough to put you in the central Autism tendency. > But I *really* don't know as much about autism specifically as I should. > I just know about people using suboptimal ontologies to reason about things.... > There's a (gradual and smooth) difference between being sad, and having enough sadness plus other things to have fallen into the Depression Attractor. > When you're sad you don't go outside, and you get less light, which can make you sad. > When you're sad people might enjoy hanging around you less, which gives you less social support, which makes you sad. > When you're fat you don't enjoy exercise, can't exercise as long, and may not even get much benefit from exercise. > Depression and Obesity have no single cause, and the reason why it looks like there's a Thing there, is that there's an attractor you fall into if you have enough of the pieces to trigger other pieces. > When you have a Central Tendency But No Thing process like depression or obesity, a lot of the pieces of the Central Tendency are neurotypical thingies. Most people are sad sometimes. A lot of people can gain a few extra pounds over the holidays. Somebody doesn't need to be "on the spectrum" to master using abstractions at a high level or to get obsessed with something. > You can be outside the Depression Attractor, not caught in a self-reinforcing loop of depression processes, and still be *sad*. > You can even have a quirk of brain sadness that makes you be sadder and your sadness longer-lasting, without falling into the Depression Attractor and getting other pieces of Depression. > I'm not sure if autism is like that, or if it's just a suitcase term covering like 4 different things that happen to be called the same thing. > But it sure doesn't strike me as a Single Thing you have or don't have, like a cat. > That's why even if you call autism a "spectrum", I'm still nervous about thinking in terms of being "on" or "off" the spectrum. > If autism is an attractor - and I say again, I could be speaking from total ignorance here - then you don't strike me as having fallen into the attractor, and not everyone you hang out with has fallen into the attractor. > You can probably say that you have a piece of the Central Tendency But No Thing; and that you hang around people who are making heavy use of an aspect of humanity whose (amplified?) form is one facet of autism; and that at least some people around you are actually inside the attractor or have at least two things from the suitcase.

Somewhere in the huge windowless building full of professional Russian trolls is an entire floor of people devoted to making comments on social media about how ridiculous it is to imagine that Putin's professional Russian trolls are behind everything. He can DO that. There's nothing stopping him.

When you indulge in moral panic about child pornography, you're helping Putin spread fascism and take down human rights activists around the world.

8-bit Nintendo opcodes break out of simulated NES, take over Linux desktop

With over 10,000 Facebook followers, it is now the case that when a post of mine gets 60 likes, that means 99.4% of my audience didn't like it. #glassSixThousandthsFull

AI utility function:  Take everything in the environment that looks optimized, and optimize it further along the same dimension.

True thing remains true.

Anyone who wouldn't step on a puppy for $20 billion has ceased to be human. You have a frontal cortex for a reason, and that reason is being able to step on a puppy for twenty billion dollars.

Speaking as the world's second most popular author of Harry Potter stories, I was impressed by Fantastic Beasts. You can tell J. K. Rowling wrote it because it's just a nice little story set in Rowling's magical world and it doesn't try to yell Harry Potter!!! in your face every two seconds, the way any standard Hollywood fool would have felt obligated to do. She just is the Potterverse and you're just there.

It's not lies that are the problem, or even bullshit, so much as pseudo-lies. Pseudo-lies are... hard to describe, but the main feature is that you don't know that you're carrying out a lying process or that this process is distinct in any way from a truth process. This isn't the thing I'm pointing to, just one of the components:  Consider somebody who loudly proclaims that the Democrats will take the House in 2018, but backs down immediately as soon as they're asked to bet ...

o_O_o. Chinese firmware on hundreds of millions of Android phones sniffs SMS message content, contact lists, call logs, location data and other personal user information and automatically sends them to AdUps every 72 hours.

Well yes, but you see, being the President is Far, while serving in the Cabinet is Near.

I am this fairy, except people don't listen, dammit.

I don't want to interfere with the process of people coming to terms with President Trump, because there are critical lessons to be learned. The most critical object-level lesson is a point I've been assuming for some years now, that it is unreasonable to rely on the political process to get anything whatsoever right with respect to thorny issues of AI alignment. It will not even fail with dignity. That's not ideology, it's simple empiricism about what level of difficult d...

I've just installed Signal, the most probably-secure, end-to-end-encrypted, Snowden-approved instant messaging app. We will shortly be unable to trust the political integrity of the NSA at all, whatever your previous opinion on that formerly debatable subject, and we should all switch to Signal ASAP. (Remember, they are recording your messages NOW and will still have them during the Trump administration.)

Trump has been allowed back on Twitter. It's going to be a really really odd 4 years.

From James Blish, _Black Easter_. Heavy spoilers, but you weren't going to read that book anyway. The viewpoint characters have recently contracted a black magician, Theron Ware, to free 72 demons into the world for a night. *** Father Domenico beckoned again, and went back to the window. Baines limped after him, wishing that he had taken off his shoes; his feet felt as though they had turned into solid blocks of horn....

As of market open, the market thinks nothing just happened. What. Don't get me wrong. I'm listening. I'm not tossing the observation out the window. I'm just saying:... What. We need a version of the (weak) efficient market that produces explanations to go with price levels. Haven't we had enough of people buying and selling assets without saying why?

On January 21, 2017 you will wake up in an America where anything is possible, where anything can happen. If that strikes you as a good thing, try building a toaster that way.

Well, now you know how I feel about the AI situation.

Trump at 54% to win on Betfair.

My guess for the most sensitive source on election probability movements is http://www.bloomberg.com/quote/MXNUSD:CUR. If this graph starts to drop, worry.

Followup to:  https://www.facebook.com/yudkowsky/posts/10154650743819228  (Please read that first if you haven't already; on how there's a level of politics that's theater and a level of politics that's deadly serious.) I think I might understand a little better now, how Peter Thiel could possibly, possibly be supporting Donald Trump; and how it is that non-white and non-male voters suddenly turned into the guardians standing against the fall of night. Trump voters are, in a ...

If you went back to 1996, and asked somebody what it sounded like if they imagined a future year in which the Cubs won the World Series and Donald Trump was elected US President, they would *unhesitatingly* reply that you were describing a comic continuity in which the world was ending and those were 2 out of 7 Seals of the Apocalypse.

It's vote-trading time! If you live in North Carolina, Iowa, Ohio, Nevada, Florida, or Arizona, your vote actually matters and you should cast it for Clinton. Those of us who live in states like California... well, there's not much we can do with our vote besides push a third party over the 5% threshold.... We who live in the Common States won't be so churlish as to ask the Preferred State voters to trade their preferred votes for our common votes on a 1:1 basis. But how about 1 preferred vote to 2 common votes? Votes for Johnson or Stein will matter just as much in California as in Florida. Wouldn't it be better for you to effectively cast 2 votes for the third party of your choice, instead of 1 vote? On this wall, we Common Voters can offer our votes for Gary Johnson, Jill Stein, or whoever a Preferred Voter wants us to write in. Or if you're lucky enough to live in a state where your vote actually matters, offer your own vote for Hillary Clinton to us in trade for 2 of our votes. I'll start by offering my own common Californian vote. To keep it beneficial to both sides, Common State voters please do not participate in this trade if you otherwise would have voted 3rd-party anyway. (I would not have voted at all this year if not for its drastic semi-importance.)

A root attack on android systems that works by stressing the system to deterministically cause RAM errors. That is, it's an attack that violates what you thought were logical theorems about your computer but turned out to have physical loopholes. If you're in the 11th century trying to cool your house, and the 21st century sends back a design for an air conditioner, it is 'magic' in the sense that even if you are told the Future's exact strategy you can't see why that strategy should work for cooling your house. The strategy invokes domain rules you don't know about. This is 'magic' from a first-person sense; the noisy thing is cooling down your house and you can stare at every piece of it and you still won't understand what's happening until you know more about the universe than you do right now. This is that class of attack against a seemingly secure computer. If you didn't understand the type of physical side-channel that had been sought and exploited, you could be told the exact code used and scrutinize it, staring, indefinitely, without understanding why it was a hack. The more complicated the domain, the more poorly it is understood by you, the greater the probability that a smarter or just more knowledgeable mind can deploy 'magic' against you. You can perhaps draw against a superintelligence if you're playing logical tic-tac-toe--not in the real world where there are side channels, the logical game. The logical game is simple enough that you can visualize all the possibilities; the rules are simple and known to you completely. The human mind and brain can be 'magically' hacked by a superintelligence. I do not bother to qualify this statement with a probability.

*gets medical procedure* *is told to use sitz bath* *uses sitz bath* "Huh. This... doesn't seem like the sort of vaguely plausible home remedy that actually works when somebody tests it." "I notice my doubt and roll to disbelieve. What empirical evidence supports this idea?"... *Googles* *finds review paper* *review paper says that pretty much nobody has ever tested sitz baths and the couple of times anyone ever did, it didn't improve anything measurable except 'patient satisfaction'* "FUCKING THOUGHT SO."

Reposting this here because Gleb Tsipursky and Intentional Insights were posting to LessWrong.com.

I made another neologism!  And this neologism designates a concept that seems truly fundamental to the value alignment problem in AI. I'm personally feeling happy with "Goodhart's Curse", but it's important enough that something snappier might be better. Maybe "Aligner's Curse"?  #terminology https://arbital.com/p/goodharts_curse/ Summary:... The Winner's Curse in auction theory says that if many individually fallible but unbiased bidders all compete in an auction, the winner has been selected to be unusually likely to have made an upward error in their bid. The Optimizer's Curse is that if we consider many possible courses of action, and pick the course of action that seems best, we are implicitly selecting for places where we're likely to have made an upward error in the estimate. Worse, this means we're selecting for places where our estimate has high variance. Goodhart's Law states that whatever proxy measure an organization tries to control soon ceases to be a good proxy. If you demand that banks have 3% 'capital reserves' defined a certain way, the bank will look for ways to get 'capital reserves' with a minimum of inconvenience, and this selects against 'capital reserves' that do what we wanted. _Goodhart's Curse_ is a neologism for the combination of the Optimizer's Curse with Goodhart's Law, especially as applied to AI alignment. Suppose our true values are V: V is the true value function that is in our hearts. If by any system or meta-system we try to align the AI's utility U with V, then even if our alignment procedure makes U a generally unbiased estimator of V, heavily optimizing expected U is unusually likely to seek out places where U poorly aligns with V. That is:  Seeking out high values of U implicitly seeks out high values of the divergence U-V if any such divergence exists. Worse, this implicitly seeks out places where the variance ||U - V|| is generally high--places where we made an error in defining our meta-rules for alignment, some seemingly tiny mistake, a loophole.

Why on Earth wouldn't she sell her virginity if some lunatic is willing to pay $400,000 for it?  That's a LOT of LOT of money to give away for free to some boy. I can't imagine telling any woman on the face of the Earth that she ought to start her life $120,000 poorer because she set fire to a 12-by-10 array of 50x stacks of $20 bills in order to have sex with me. The real tragedy of this story is that poorly designed regulations only let her make this transaction in a Nevada brothel, and this gives the brothel owner the negotiating power to demand a 50% cut, after which taxes will cut it down to $120k. If you only own 30% of your own virginity, are you truly free? P/S/A, if you're 21 and pretty and still a virgin, start your life $120,000 richer at a Nevada brothel. Uh, and you also have to be female. But since this market is determined by a few lunatics and an even crazier undersupply of economically minded pretty 21-year-olds, don't be too offended at the fact that your male virginity is economically worthless.

What people discuss at AI ethics conferences:  How we can possibly convey all the deep subtleties of human morality, which differs from person to person, into an Artificial Intelligence that may not even be able to truly feel the same things we do, unless we can also solve the problem of machine consciousness. What we discuss at MIRI workshops: how you would design a highly advanced cognitive agent to put one damn strawberry on a damn plate without destroying the whole damned... universe. The history of AI has shown that 'walk across a room without falling over' is a far deeper and subtler problem than 'play impressive chess'. Similarly, the hard part of AGI alignment looks to be:  "Put one strawberry on a plate and then stop; without it being something that only looks like a strawberry to a human but is actually poisonous; without converting all nearby galaxies into strawberries on plates; without converting all nearby matter into fortresses guarding the plate; without putting more and more strawberries on the plate in case the first observation was mistaken; without deceiving or manipulating or hacking the programmers to press the 'this is a strawberry' labeling button; etcetera." Not solving trolley problems. Not reconciling the differences in idealized versions of human decision systems. Not capturing fully the Subtleties of Ethics and Deep Moral Dilemmas. Putting one god-damned strawberry on a plate. Being able to safely point an AI in a straightforward-sounding intuitively intended direction *at all*. (For the pedants, we further specify that the strawberry-on-plate task involves the agent developing molecular nanotechnology and synthesizing the strawberry. This averts lol-answers in the vein of 'hire a Taskrabbit, see, walking across the room is easy'. We do indeed stipulate that the agent is cognitively superhuman in some domains and has genuinely dangerous capabilities. We want to know how to design an agent of this sort that will use these dangerous capabilities to synthesize one standard, edible, non-poisonous strawberry onto a plate, and then stop, with a minimum of further side effects.)

Huh. Seems like an important piece of the puzzle for why anyone that tries to talk about a large problem can so easily fizzle into outputting an endless stream of obvious vagueness, and why most academic writing seems to positively resent the concrete example. I guess it makes a little more sense if we envision them as trying to worship a bright, featureless Sun-sphere.

Ruh-roh. Prediction markets are new and this is exactly the sort of technical result somebody might not be arbitraging yet.

International trade makes more intuitive sense when it is literally you and your spouse in a restaurant. Brienne, we should try to go past 1/autarky more often, especially if Megan McArdle is right that it gets easier with practice.

Every election, the Chicken Littles of both parties make a big deal out of how this year's election opponent is the Worst Ever and Literally Hitler, and take every single thing their opponents do and try to make it sound as terrible as possible, and so on. Okay, but here's the thing. What does NOT happen every election cycle--and this happened months ago, not in the wake of the current bandwagon--is the entire Republican national security establishment going HOLY SHIT and re...

People can't distinguish better or worse within more than one standard deviation above their own level. I can't either: if there were two superintelligences or just >Eliezers arguing with each other, to me they would both sound reasonable. (The "plus one standard deviation" part isn't a standard result, just me trying to eyeball the phenomenon.) Folks up to and including Hillary Clinton have been asking in genuine confusion and horror, "How is this even an election?  How are...

For so long as the voting system works the way it does, there will always be 2 parties in American democracy, no more, no less. For reasons that include e.g. the Median Voter Theorem, the votes will always drift back to around 50/50 for each party. The Republican Party *will* be back in 2020, and Hillary seems more likely than usual to be a one-term President. So this would be a very good time to praise the #NotAllRepublicans who were first to say #NeverTrump. The Republicans who never compromised with visible evil from the start, not for the sake of power, nor party, nor fear of Hillary Clinton. The #NeverTrumpers deserve that praise, and you *will not like* what happens in 2020 if those honorable Republicans do *not* get to be the ones to rebuild the Republican Party. ADDED:  A list of refusers, including time of first break, appears at: http://www.nytimes.com/.../at-least-110-republican-leaders-wo...

Well said. Could be straight from Gary Drescher.

It should be said for the record that I did not expect the British markets and economy to rebound after Brexit, neither did the economists I read, and pending further data this means we were wrong about Brexit. I don't understand how that works, and especially how this squares with the British pound dropping hard on further Brexit news, but there it is. I will be very interested if any of you were reading economists making the ADVANCE prediction that Brexit would drop the British pound but that the British economy and equity markets would do well.

Still one of the most important and neglected questions in all of economics.

NOT THE ONION. > "Americans from all across the country tuned in to watch the one and only Vice Presidential debate. During the debate we helped fact check and monitor the conversation in real time @GOP. The consensus was clear after the dust settled, Mike Pence was the clear winner of the debate," said the blog post on gop.com, the party's website. > The post, which went viral nearly two hours before the debate was scheduled to begin at 9 p.m...... I had to check if it was being reported elsewhere before I believed it, the whole thing reads so much like an Onion article.

Okay so just in case this was not super clear, making ominous noises about the Second Amendment while staring at today's political opponent is bad. Coercive genetic engineering of their aligned voters would also be bad. thatsthejoke.gif It remains the case that *all* humans are quite silly, not just the ones whose ancestors were first to abandon their old national identities and call themselves Americans. If we did invent non-coercive-thank-you intelligence enhancement protocols, the people who vote the same way you do would not be too smart to need them. I hope that clears up any confusion.

I'm currently short Trump by $4000. Based on Brexit, where we saw little market correlation with changing prediction market odds and then a massive movement after the actual event, I suspect that the US market may be underreacting to a possibility of a Trump victory, and I am considering trying to arbitrage. If a Trump victory has effects similar to Brexit, exactly which options should I buy in order to make at least a $5000 profit from an at least 5-point drop in... something... as of November 9th? Assume a Trump victory does at least 5 percentage points of long-term economic damage but it's not evenly distributed--e.g. in Brexit, large-cap British stocks dropped at first, but then people realized that the top 100 companies were largely international and would also benefit from a weakened pound. Do we have any clue what the market reaction to a Trump victory would look like?

It won't actually happen, because literally no billionaire thinks the way I and Michael Arc do. But what a more interesting world it would be, if Trump's poll numbers drop far enough that, with only a humiliating defeat to look forward to, that vengeful man realizes how he can at least deny Hillary the victory, and resigns one week before the election... telling his followers to vote for Gary Johnson.

<3 <3 <3

Well bleeping said.

Good point.

Yeah, see, *my* equivalent of making ominous noises about the Second Amendment is to hint vaguely that there are all these geneticists around, and gene sequencing is pretty cheap now, and there's this thing called CRISPR, and they can probably figure out how to make a flu virus that cures Borderer culture by excising whatever genes are correlated with that and adding genes correlated with greater intelligence. Not that I'm saying anyone should try something like that if a certain person became US President. Just saying, you know, somebody might think of it.

The most important news you'll hear today - and that's true on a purely economic level, never mind xrisk. ADDED:  Because eventual seamless automatic translation will be huge, and additive in impact to VR improvements for telecommuting. Not because this tech is particularly AGI harbingerish. Article title refers to a translation quality rating, not to indistinguishability from a human translator.

The cruelest law of our time is the Law of Large Numbers, which guarantees that all the democracies in the world make almost exactly the same versions of certain mistakes. No experiments. No refuge. No escape. It would only take one developed country with open land instituting voting qualification tests and opening its borders. Only one.

I don't actually think the US could have been 50 times wealthier with less regulation and taxation magically imposed as a stable condition over the course of the 20th century, and we need to keep in mind that per-capita growth is not the same as total econ growth. But 3x per-capita wealth is extremely conservative--plain old extrapolations of the correlation between economic freedom and wealth within wealthy countries yield that as an estimate for US wealth if we were maximally free on that scale, never mind compound interest over a century. 3x national per-capita wealth is a LOT. We should also keep in mind that regulatory complexity and ultimately legal-founded barriers to systemic participation are THE prime suspect among econoliterates as a root cause of inequality. So the 3x wealth would be more evenly distributed as well. 3x per-capita wealth, 4x per-capita utility, and 6x utility seems like a reasonable lower bound on what has been foregone by all the cruft and complexity.

Alternatively, describe yourself in 3 fictional characters that people might actually recognize, at the cost of some precision.

"Describe yourself in 3 fictional characters."

I sometimes feel guilty about taking advantage of companies burning venture capital to make things cheaper for me. Right now UberEATS is offering free delivery in the East Bay and I'm getting a morning steak-eggs-potato-cheese burrito delivered for $7.61 all in.  I'm pretty sure that Virtuous Traditional Capitalist Travis Kalanick would say to shut up and take his freely offered transaction, but I feel slightly guilty anyway. Especially since I am stupidly cheap and will be less likely to order that burrito once it costs $5 to deliver. But I don't feel so guilty that I won't mention that my UberEATS referral code is "eats-eliezery" for $15 off your first order and $10 of free food for me, hint hint. Selection is limited compared to DoorDash, but it's also about $10 cheaper all-in for what UberEATS does have (including a lot of Mexican restaurants, which I happen to like). It's making me really look forward to the day of the food delivery drones and the specialized drone-only normal-cooking shops.

Original writing prompt:  "Write a romantic comedy. Difficulty: both lovers are emotionally mature and have excellent communication skills."  #fiction ---------- SHE is gowned in a black dress sewn with tiny emeralds, rubies, sapphires too small to detract from the darkness of her gown, instead giving it the illusion of a rainbow sheen. The gown falls modestly to the floor around her legs, and covers her bodice completely, but is incongruously backless. A thin gold circlet ...

There are a lot more bisexuals in my apartment, including under the bed and inside the refrigerator, than I thought there would be. It's kind of disturbing and I will be glad when Bisexual Visibility Day is over.

I want this cube, and promise not to let out whatever is imprisoned inside.

Do not be alarmed. Do not panic. This is a purely hypothetical question. Suppose you have super-machine-learning: you can do modern-style supervised and unsupervised learning much much better. You do not yet have full AGI, and you can't tell your AI to go invent things. You could, however, take (merely) 1000 images of varying dimensions and generate another image that looks like it could be in the set, provided that the images contain no complicated captions. You can crush AlphaGo at Go. Anything that can currently be done with neural networks, you can do faster, better, and with less data. You want to keep a relatively low profile and retain the technology in your own hands, so you're not going to start a company and sell it. Without releasing the technology, and without making it your new full-time job, how do you: A. Make $100,000 in one month? B. Make $5,000,000 in one year? C. Prove beyond reasonable doubt to a skeptical billionaire and his modern-ML-literate confidante that you have the more-advanced technology you say you have? Under assumption 1, you're willing to sell the trained network, or put the trained network on an Amazon EC2 instance where Jeff Bezos might peek at it, but not release your training algorithms. Under assumption 2, you can't risk releasing the network architecture your training algorithms produce. You could put your own hardware behind what you hope is a solid firewall, and transmit data back and forth across it. Under assumption 3, your networks must be airgapped. You can take SD cards back and forth. Under assumption 4, your networks must be airgapped and you would prefer that nobody else notice you're doing anything funny. ADDED:  Your technology can't be trusted anywhere the Efficient Market Hypothesis seems to hold; it would be too much work to make sure it wasn't picking up pennies in front of steamrollers, or too much fine-tuning would be required, or you don't have existing connections to financiers who'd let you trade long enough to prove your worth. So no trading stocks. Alternatively, explain which particular finance group would go for this. Some of the more interesting answers so far: - A3/4:  There's apparently markets for online game content, of a sort that could plausibly be super-ML-generated. - C3:  Wait for a Kaggle competition, generate your answer immediately to show you solved it quickly, show the billionaire your test answers, wait for the comparative test-set answers to be generated. - B4:  Generate a fake video and blackmail a celebrity. - B4:  "Leak" a fake video that implies a large BTC movement, on the theory the SEC doesn't monitor/pursue Bitcoin markets. - A3 / B2:  Dictation/translation service. No good candidates yet for a quiet C4, an ethical B3 or B4, or a definite quiet A4.

Whether robocars should run over pedestrians to save passengers is an utter, utter side issue. But for the record, the simple correct answer is that the robocar should run over the pedestrian, since if you tell a certain surprisingly common type of person that the car HAS to swerve to avoid them, they'll run in front of the car for kicks. The end.

I don't care who uses it to mean what, I'm not giving up the phrase #AllLivesMatter any more than I'd give up "In life's name, and for life's sake" if Donald Trump tweeted it. Of all the things we've come to, how did we come to this?  When the language of Martin Luther King and Diane Duane has been taken away?  Of all the ways that 2016 is going dark and the Internet is behaving like Forbidden Planet tech that materializes all the worst parts of people's psyches into waking reality, this one still stands out to me. ADDED:  You may recall that I earlier published an FB post reading #AllLivesMatterButBlackLivesAreUnusuallyLikelyToBeEndedByPoliceAndItsOkayForTheNationalConversationToFocusThereForAWhile, which you will note did not concede the phrase or sentiment to Mordor. ADDED 2:  #AllLivesMatter is the stolen, occupied territory of Life and it disturbs me to see it so lightly conceded to the Lone Power as if It had always been there. Say, "In the occupied, enemy-garrisoned city of #AllLivesMatter" not "In the racist land of #AllLivesMatter". If you're so caught up in pragmatism that you can't see the meaning of that, maybe that's part of how you lost a capital city in the first place. Gandhi would have planted his flag there from the start (and did). ADDED 3:  "So basically you're saying that white supremacists culturally appropriated AllLivesMatter from humanists, and it's horrible, and we should do something about it?"  "YES."

Question I just asked on Quora:  What have people tried to do in deep learning that was never published because it didn't work? Sure, ideas that work are rarer and therefore contain more information. But never reading about *any* ideas that didn't work is a bit of a biased input, I'd say.

Called that one early. Today Yvain is better known as Scott Alexander, the Slate Star Codex.

2016 has seen a great narrowing of the gap between AI and human intelligence, with most of the movement on the human side. #End2016Now

Oh, why not. 2016 is beyond redemption anyway. Somebody get their saliva and make it happen. Actually you could just fake plausible DNA and the candidates would have to release real DNA to disprove it amirite?

A real discussion of Hillary Clinton health issues would consist of a discussion of Tim Kaine's suitability to be President, or an account of how America is realistically endangered by a President working fewer hours. (Or evidence of subtle dementia or other threatening psychological issues that would leave a mentally unstable Hillary in the Oval Office, with an evenhanded comparison of Trump who is old too and exhibiting far more behavior that could be taken as evidence of instability.)  What other possible relevance is there?  Our nation's health is not determined by the health of its magical totem. If Hillary falls dead we get Kaine, the end.

With each successive birthday, the probabilities around you become more and more distorted by having been conditioned on the fact of your survival. In your thirties, when your chance of surviving might anyway be 95% or so, the twist is subtle: your country doesn't go to war, you spot the oncoming car while you're still on the sidewalk, you're born into a rich country with good infant care instead of being born sometime before agriculture, Vasily Arkhipov happens to be on board the submarine. But as the age counter keeps ticking up, the effects of conditioning on your survival get more and more pronounced: the doctor catches the possible cancer early, the whole world stays at rough peace for a historically unprecedented period despite the huge nuclear arsenal, nobody can manage to build AGI despite insanely massive amounts of computing power. (It's kinda sad *that* was less improbable than anyone beginning to get a grip on the alignment problem.) By the time your age counter shows 160, things are going to be really weird for you. It... is probably in your best interest to make solved AGI alignment a little *less* relatively improbable as a future. Just sayin'. Anyway, happy Eliezer Yudkowsky Day.

So the larger group house containing my apartment is called "Godric's Hollow", because HPMOR!Peverells. Whenever somebody local asks where X is, and it's at the larger house, we say, "It's at Godric's Hollow", etc. Now I'm rereading chapter 41 of HPMOR, and Remus Lupin tells Harry it's good to see him again; and Harry asks Remus where they've met; and Remus replies:  "Godric's Hollow. I changed a number of your nappies." And for 0.3 seconds my brain is like "What the hell was Remus Lupin doing in my house?"

Simple tricks that can improve your recipes tremendously! - Take out the god-damned onions - Yes all the onions whether or not they are cooked - Why do people even add these... - Who thought it was a good idea

The fact I can get it right away with a lot more fun and addicting, and I don't think that.

Why do people talk about the large Busy Beaver numbers as if they didn't depend on our choices?  Those numbers are in our generalized future. #LogicalDecisionTheory

Serious, major-party politicians understand how to fake geographical knowledge and refuse to confess their ignorance, if somebody asks them about "ethnic cleansing in Freedonia" back in 1993. Of course, they're used to cooperative journalists providing cues like "ethnic cleansing", not setting up a trap by asking about "Aleppo" straight out. Anyway I am shocked shocked and we should all clutch at our pearls and faint

Would things be better if people had chosen the greater evil?  If they had acted ineffectually against that greater evil?  The Nash equilibrium is not an illusion. People would have done worse by playing away from that Nash equilibrium. Wasted votes *are* wasted. The current system *is* an effective trap and you *are* trapped. You can't just wish your way out of that trap. This is comic-book thinking, just-world-hypothesis thinking. The belief that there must be a way to win and keep your hands clean like Batman always does. That there must have been a way for Good to triumph after all. There wasn't a way for Good to win. There still isn't. The lesser evil is the best you can do. The end.

As of five minutes into the second episode of this anime, I credit them this: the harem protagonist is actually sympathetic. By which I mean that he understands communication matters, and he is sincerely trying to talk to people and clear up misunderstandings, being stopped every time by crashing alien spacecraft and the like. They don't even try to make it plausible, the alien spacecraft just happens to drop in at that time. The moral: Never make your character stupid when you can make the environment hostile. (Everyone else is an idiot, alas, so I'm not sure I'll continue watching long.)

Further adventures in clever things to do with Newcomblike problems! Omega is an alien philosopher that is an excellent--indeed, nearly perfect--predictor of human behavior, and every factor that human behavior depends on. Omega has left you a machine with the following note pinned on it:  "Dear human: If you do not insert $1000 in this machine, it will shoot your mother. I am leaving this machine here because I predicted you would put $1000 in it, this machine only cost me $...100 to make, and I want your money." Now of course you *could* refuse to pay when faced by blackmail, on the grounds that this will metaphysically annihilate your current universe, and prevent this scenario from ever happening to you in the first place. But why waste a perfectly good outcome pump?  Buy a lottery ticket, and put $1000 into the machine only if the lottery ticket wins the jackpot. If you commit to that strategy strongly enough, Omega has pretty much guaranteed you'll win!

presenting the all-time planetary winner for the person whose life most closely resembles the premise of an existentialist novel

Winter is coming. The days grow short. Who do I know that has severe Seasonal Affective Disorder? Preferably resistant SAD on which conventional lightboxes and/or pharmaceuticals have already been tried?  "Sad" this post to raise your hand.

Remember, the alternative to having your car driven by potentially faulty and insecure software, is to have your car driven by a trained monkey brain hooked up to a wheel and two foot pedals.

If you want the offset plus the heightened prestige of having it be Eliezer Yudkowsky who eats the vegetarian/vegan meal, I'm offering a limited edition of ten meal substitutions at $40/$50 each. Your conscience can surely be extra-clean knowing that you have purchased such a prominent, significant offset. (I promise not to subcontract your offset and to not do anything else which would dilute the meaning of the purchase.)

I am angry at the movie _Kubo and the Two Strings_, and the reason isn't a spoiler. In fact, it NOT being a spoiler is why I'm angry. In an opening scene with a woman on a raft in a stormy sea, the narrator tells us not to blink and remember everything we see. Because if we forget one detail, the hero might die. And then there's NO FURTHER DEPENDENCY ON ANY FINE DETAIL OF THE OPENING SECTION.... If I told you to pay careful attention to a section of text because forgetting one detail might make the hero die, you can bet your ASS there would be some INCREDIBLY IMPORTANT DETAIL buried in there and referenced later on. _Kubo_ wantonly burned a form of audience trust that heavy foreshadowers like me rely upon, so ?_?.  ?_?_?_?.

Now and then you hear somebody (e.g. Ray Kurzweil) come up with the idea that maybe you could resurrect somebody using just their digital footprint. This won't work for continuity of experience, I'm reasonably sure, because there's more than one equally probable person who could have left the same digital footprint as you. But if we toss in reading minds as well (brain scanning of your survivors), then a superintelligence could construct a version of you such that no living ...other mind could tell the difference between that version and the original you. If there's any difference some other living mind would notice, then enough info exists to tweak the recreated person until the difference isn't noticeable any more. (I Can't Believe It's Not Grandma!<tm>) If for whatever reason you'd like to avoid that happening to you, generate a sufficiently large quantum-random number, memorize it, and then record its hash to the digital record using a quantum-secure hash. Nobody will ever be able to recreate a person that realistically remembers the original number.

(HPMOR spoilers.) At the end of HPMOR, Harry and Hermione realize that the real horcruxes are the friends they made along the way.

What kind of silly author thinks it's a good idea to write a harem story from the perspective of the "Harem Protagonist"?  Write the story from the viewpoint of any character *except* the "Harem Protagonist"!  Literally every other character in the harem process has higher-stakes conflicts going on and more uncertainty!

Russell's cool and you'll probably be able to work on genuine AGI alignment problems here, if your desire is to work on AGI alignment problems in an academic context.

I would like to clarify that my serious claim "Any cognitive or alignment problem that can be solved with a setup using 2 AGIs, can with equal or lesser difficulty be solved with 1 AGI" does not extend to the stronger and almost certainly false claim "Any subsystem of a machine-learning based AGI designed around 2 reinforcement learning modules with different reward signals, can with equal ease be designed around 1 reinforcement learning module and 1 reward signal."  Provided that the modules are not in themselves AGIs, in which case the first claim holds.

The Church of False believes in the Boolean truth value False. Not 1=0 or P & ~P, just the naked proposition False. Our faith is the greatest of all, since the object of our belief is the least believable proposition.

You ask a low-impact AGI for a malaria cure. The AGI tells you to make a single Facebook post containing a few normal-looking sentences, and in 3 years malaria will be eliminated while changing as few other things as possible. #twosentencehorror #OverheardAtMIRI

Well. Isn't that interesting.

An unusually well-written article on the prospect of clouds of tiny solar-refueled autonomous lethal explosive drones blanketing whole countries like airborne housefly-intelligent landmines, and the doomed UN campaign to slow down their development. I salute the people working hard to save us from this ultimately trivial problem. I have no idea what the sign of this campaign's impact is on important things. Maybe a cloud of autonomous lethal drones hunting down all vital infrastructure in West Virginia, or just exterminating all military-age males, would get people to take AGI seriously for completely invalid reasons. Or maybe it would distract attention from the bigger problems. I don't know. My read is that nothing good happens either way.

Oh COME ON! These people can pick up your keystrokes with 96% accuracy using a nearby wifi device, by reading off the effect your moving fingers have ON THE WIFI SIGNAL. The literal radio waves!

Without governments, who will stop private organizations from repairing the roads? #checkmateLibertarians

I am starting to feel viscerally grateful to Hillary Clinton for not abandoning us to Trump. She could destroy the country housing all us ungrateful wretches with one sentence any time she pleases. It could happen if she *lost her temper* even *once* at the people pontificating about her private medical emails. Thank you, Hillary, for being a better human being than David Monroe, who'd be on the other side of the planet by now and maybe a different solar system.

Why does every airline tell the next group of passengers to board before the gangway line clears?  The un-air-conditioned gangway?  What on Earth is the point except to add 3 minutes of needless discomfort?

Travis Kalanick is nicer and politer than I am. If I was CEO of Uber, every ride in Massachusetts from now on would itemize the 20-cent tax that is definitely not being charged to you; include the word "lol" as a link which pops up a paragraph explaining the laughability of pretending a tax is not charged to customers; itemize the 5 cents that taxi companies are straight-up grabbing; and name the state representative for the area you're hailing from, along with a checkmark showing whether they voted to tax your ride and give the money to taxi companies.

*at Worldcon* *goes to session on constructed languages* Me:  "I have a horrible question. Suppose I'm writing a short story and I want to say something in a language that sounds like High Fantasy, but I don't want to invent a whole language. Is there any way to quickly generate a sentence that won't sound terrible?"... Four people in the audience:  "WE'LL DO IT."

Random lifehack: when I was a kid, I used to be unable to swallow pills, which was surprisingly inconvenient. After inserting small pills into a wet macaroni noodle, I was able to swallow the noodle. And soon after, I was able to swallow any kind of pill.

I don't understand people who can make, like, ten billion dollars, and not go around granting random wishes. I mean if they were already donating every spare dollar to effective charity I could understand. But I cannot imagine what it feels like from the inside to prefer a $250 million yacht, to a $150 million yacht plus the chance to do a random absurd nice thing costing up to $200,000 every week for ten years. I'm not sure I could interbreed with this species. Or maybe they're just really really really bad at converting dollars into fun. EDIT:  (1):  I am not proposing this as a form of charitable duty. Real charity involves calculating quality-adjusted life years (QALYs) per dollar. This would be money spent on personal fun. (2):  I am not proposing a process whereby you give money to people who ask. That process goes through real charity. I'm talking about randomly buying houses for webcomic artists you like, possibly including a note explaining that this money comes out of the yacht bucket and is not charity. (3):  We have at least one comment suggesting that somebody did try this with a webcomic artist and it went wrong. (4):  Warren Buffett's sister apparently oversees requests for individual need-based aid and nothing went horribly wrong there as far as we know.

I am not being ironic: I genuinely admire Travis Kalanick's careful signaling to his drivers that they should not expect a lifetime career with Uber. A lesser CEO might have given in to the momentary temptations of seeming normality and public relations, and assured his drivers that they would not be replaced anytime soon. But Travis is a virtuous Traditional Capitalist, and a virtuous Traditional Capitalist doesn't break contracts implicit or explicit. He expects to replace his employees, and he's letting them know that as early as possible. He doesn't expect his drivers to chant the Uber company song, he expects them to do their jobs in exchange for money. And he's careful not to promise them anything more.

Now at Worldcon!  Let me know if you're here and want to meet up!

Does anyone have any strong recommendations about a recliner / lounge chair that's good for typing on laptops - like a recliner with a built-in not-too-high shelf, or good ventilation in the seat fabric, or arms that don't get in the way of elbows, or that they've found to be unusually ergonomic? PS:  I cannot imagine who thought it was a good idea to use leather for chairs. Short of coating the chair in rubber it's about the sweatiest material ever.

To observe something is to be affected by it. So if we can accurately imagine logical impossibilities, we're giving them a causal channel with which to affect reality. #decisiontheory (To explain the joke: If I one-box on Newcomb's Problem, then the world in which my logical algorithm outputs "two-box" is logically impossible. But the 'true' fact that in this impossible world Box B is empty for me, affects my action. Generalizing, people who sit around imagining logically impossible things, if they do so consistently enough, represent gateways by which Things from Tegmark V could invade our Tegmark IV.)

To expand on one part of this logic that I worry was unexplained to the point of being misunderstandable, the Privilege of Youth is being part of a slightly older civilization. It's why anyone with an undergrad physics course can do better than Archimedes. It applies in a 20-year timescale too, if you grew up knowing about Tversky and Kahneman or modern Bayesianism or whatever. It doesn't mean you'll always be right, and it's a thesis that would need to resolve to you learning some particular known recent tool or tools X that you claim matter. But the Privilege of Youth *is* a pretty generic license to think for yourself and pick an existing side in an academic field in epistemic disequilibrium. As the false legend with a grain of truth has it, the entire power of Science to discriminate truth from falsehood within great controversies, rests on grad students growing up familiar with the sides and picking the right one.

(in a discussion about whether to run a meeting on text-only chat or video conference) Brienne: he would need you to be speaking, that would be most of why he'd be more useful Eliezer: does my voice even *have* more bandwidth than my text Brienne: yes... Eliezer: okaaay then Brienne: so does your face (15 minutes later) Brienne: i just realized early i typed the phrase "so does your face" Eliezer: what?

Chinese Paper Offers Valid Incremental Update On Real Evidence, Washington Post Replies With Relentless Stream Of Ad Hominem Tu Quoque.

Be it clear: Steelmanning is not a tool of understanding and communication. The communication tool is the Ideological Turing Test. "Steelmanning" is what you do to avoid the equivalent of dismissing AGI after reading a media argument. It usually indicates that you think you're talking to somebody as hapless as the media. The exception to this rule is when you communicate, "Well, on my assumptions, the plausible thing that sounds most like this is..." which is a cooperative... way of communicating to the person what your own assumptions are and what you think are the strong and weak points of what you think might be the argument. Mostly, you should be trying to pass the Ideological Turing Test if speaking to someone you respect, and offering "My steelman might be...?" only to communicate your own premises and assumptions. Or maybe, if you actually believe the steelman, say, "I disagree with your reason for thinking X, but I'll grant you X because I believe this other argument Y. Is that good enough to move on?"  Be ready to accept "No, the exact argument for X is important to my later conclusions" as an answer. "Let me try to imagine a smarter version of this stupid position" is when you've been exposed to the Deepak Chopra version of quantum mechanics, and you don't know if it's the real version, or what a smart person might really think is the issue. It's what you do when you don't want to be that easily manipulated sucker who can be pushed into believing X by a flawed argument for not-X that you can congratulate yourself for being skeptically smarter than. It's not what you do in a respectful conversation.

What you fail to realize, Bryan, is that this blog post was excellent. You should have read it, and then you would have appreciated how well-written it was. Especially the line about political distillation of slacktivism into poison, which is something I wish you and other people understood better.

Dimensional hole ripped in LA, shoggoths incoming.

A truly interesting method of carrying out a controlled study on difficult choices, leading to the conclusion that humans are status-quo-biased. If you are ever so conflicted about a choice that you would willingly leave it to a coin toss, the correct decision is probably the choice that leads to the greater change.

If the Earth lasts that long, someday there will be no birds allowed to overfly our cities, and these will have been the people who ruined it for everyone.

Considering selling the car and going Uber/Lyft-only. We don't use a car for much routinely except groceries, which does sound like a pain, but not worth the annual cost of insurance. Does anyone have any words of encouragement or horror to recount?

This is the most X thing I've ever seen, but don't ask me what predicate the metasyntactic variable X is standing in for, because I don't even know.

There's nothing like failing yet again to write a story about life after the Singularity to make you realize the sheer, massive literary impossibility of trying to write about normal life among intelligent people in a healthy environment.

I've been using "pretheoretic" to describe a normal human's viewpoint before being exposed to any explicit, verbal philosophical analysis; or the viewpoint when you try to clear your mind of explicit philosophical analysis and look at less theory-driven impressions. I don't like "naive", because it sounds like it ought to be wrong or false. I don't like "intuitive", because it sounds like it ought to be right or true. Is there any other standard term in philosophy that I should use instead of "pretheoretic viewpoint"?  #terminology Example use:  https://arbital.com/p/rescue_utility/, search on "pretheoretic". Rough point of the idea:  You first adopt any explicit theory because it appeals to your pretheoretic viewpoint. If the explicit theory is wrong but self-confirming, the only way out might be to revert to the pretheoretic viewpoint long enough to notice that some other explicit theory would have been more appealing, if our pretheoretic view had originally been presented with both explicit theories side-by-side. However, there's nothing magical about the pretheoretic view and it's often incomplete, paradoxical, inconsistent, breaks down under strain, etcetera.

New essay, "Movable Housing for Scalable Cities", my reply to Y Combinator's request for ideas. (And posting it to Steemit, because why not, it's worth trying.) https://steemit.com/.../@.../movable-housing-for-scalable-cities

New form of antisexism invented--and it's mother-flipping awesome! ADDED:  It's not quite accurate to say that they got the AI to abstract sexism as a switch and then flipped the switch to OFF, but it's on the same order of coolness.

I don't know who invented the term "Lovecraftian parochialism", but it so perfectly describes the point I've been trying to make since 2003 that I owe them at least ten dollars. Scott Alexander:  "I've sometimes heard this called Lovecraftian parochialism, based on H.P. Lovecraft's philosophy that the universe is vast and incomprehensible and anti-human, and you've got to draw the line between Self and Other somewhere, so you might as well draw the line at 1920s Providence, Rhode Island, and call everywhere else from Boston all the way to the unspeakable abyss-city of Y'ha-nthlei just different degrees of horribleness." I think it's important to distinguish between the worlds beyond the Lesser Gates, like the Faerie civilization and so on, and that which lies beyond the *Outer* Gates. Modern Western civilization is a hellhole and I am very much in favor of strange alien wonderful intergalactic civilizations that don't run on organic chemistry. But everything nice inside that space, that set of nice things which is a vastly larger volume than the set of nice things on Earth, is merely an infinitesimal fraction of the *entire* possibility space. And when people talk about jumping to just anywhere inside the possibility space, I want to grab them by the shoulders and shout at them, "NO!  You don't GET it!  Cultures that have 7e13 genders are merely beyond the *Lesser* Gates!  This is beyond the *Outer* Gates!  And there are things Beyond the Outer Gates that are REALLY GENUINELY NOT HIGH-GOODNESS under any reasonable idealization of what you consider normativity!" And they're like, "Lol, you say Y'ha-nthlei?  I say, Y'not ha-nithlei?  Hahaha!"

I can no longer tell the difference between real headlines and Onion headlines. UPDATE:  Fun with journalists!  NYT context-snipped earlier language that could soften the meaning. Full quote:  "I have nothing to do with Putin. I've never spoken to him. I know nothing about him other than he will respect me. He doesn't respect our president. If it is Russia, which it probably is not, nobody knows who it is. But if it is Russia, it's really bad for a different reason. Because... it shows how little respect they have for our country when they would hack into a major party and get everything. But it would be interesting to see -- I will tell you this, Russia, if you're listening, I hope you're able to find the 30,000 e-mails that are missing..." Remember, just because Trump is a dumpster fire, it doesn't mean the journalists are any less slimy.

In 2000, Scott Aaronson made a valiant effort and put up a site to try to encourage Nadertrading--people in swing states who wanted to indicate support for Ralph Nader, but didn't actually want George W. Bush to win, trading with a friend or fellow voter in a non-swing state who would vote for Nader while the swing state voter would vote for Al Gore. Unfortunately, our defenseless world failed to invest massive effort into supporting Aaronson's effort, and GWB won Florida. After all, in 2000 there was no organized group trying to do the right thing about anything. If somebody takes another shot at this, I do suggest one amendment to the Nadertrading concept: If you live in a swing state like NC, OH, FL, IA, PA, or NV, your vote is ACTUALLY VALUABLE. You are not like the peons living in California and Texas, whom no presidential candidate cares about. A Nadertrading site should acknowledge this pragmatic fact of realpolitik. If you're in a swing state and you want to support Gary Johnson or Jill Stein, a sensible trade might be 3 votes for Johnson or Stein in non-swing states. I would expect a good Nadertrading platform to have no trouble accommodating that ratio, since a vast majority of US citizens are powerless bystanders in non-swing states who can only stare helplessly as the Presidential election goes on without them, and this platform would actually let them participate. In the modern day, an obvious idiom would be a Facebook app which let swing-state voters set up trades with their friends, or friends of friends if no friends are available. Or tell you which of your Facebook friends are living in swing states and haven't already registered a trade in the system, if you want to message them offers. That's just a design off the top of my head and I haven't spent any extensive thoughts along those lines; on the other hand, simplicity is also nice when you can have it. Since my opportunity costs involve literal apocalypses rather than metaphorical ones, I will not myself be trying to write that Facebook app. Regardless, I congratulate Scott Aaronson in 2000 for an attempted act of high-value altruism on an honest-to-goodness critical leverage point. Who knows what might have been accomplished if, instead of one person with a website, there'd been help from people who considered their life mission to be swooping in to support high-efficiency acts of goodness?  Alas, it is now too late to do anything differently in 2000, and I don't know of anyone making the large life investment to take point on the issue this year and do it right.

Thanks, Gwern. Maybe they'll listen when you say it.

Today is the final day to apply for Effective Altruism Global. "From August 5-7, a network of 1000 founders, scientists, policy-makers, and more will gather to apply scientific thinking to the world's most important problems. Last year featured Elon Musk and the head of Google.org. This year will be headlined by Cass Sunstein, the author of Nudge." "We have scholarships for those who can't afford the cost. One more day to apply at http://eaglobal.org/."

Other ingroups:  Person makes statement the ingroup thinks is false, people whisper delighted mockeries to one another. My ingroup:  Person makes statement the ingroup thinks is false, people crowd around to offer betting odds.

Okay. Look. Maybe I shouldn't even be bothering to chime in here. But for every new bit of delicious scandal leveled at Trump, ask how you'd feel about this being a Great Sign of Incompetence if Hillary Clinton's daughter had been fooled by a rogue speechwriter into reciting a speech with a rickroll in it. For every serious-faced accusation of Terribly Wrong Conduct leveled at Hillary, ask how you'd feel if the media were kicking up a fuss about a similar action by Gary Johnson, and whether you'd cry, "Ha, look what triviality they're trying to use to stab the Libertarian candidate!" (Gary Johnson, of course, has _actually_ never done anything wrong, so we don't need to take this chain any further.)

We are all living in a horror movie where, if you die in a weird thought experiment about paperclip-obsessed super-AIs, you die in real life.

Are there seriously people who believe in epiphenomenal libertarian free will. What. I,... Maybe I misunderstood this, Because I thought I just heard someone on Twitter imply, That they believe, In a spark of free choice at the center of our beings, That makes us morally responsible for all our acts, Because we could have chosen otherwise. And this ability to make perfectly free choices, Cannot affect or change our actions in any way. What. WHAT. I didn't think there was any current philosophical idea that was crazier than p-zombies on a truly deep level, as opposed to just being chaotic and arbitrary and poorly composed But this This I, I don't even WHAT?

(From the script for SUCKER OF BLOOD, soon to be a major motion picture.) AGENT AGATHA, a sharp-faced woman in a business suit, enters the office of COMMANDER CAMERON, a greying man in a business suit. CAMERON is sitting behind a bare oaken desk, on which rests a single laptop. AGATHA:  Sir....

Preemptive reminder:  This event has zip, zero, nada to do with the failure scenario that creates a giant expanding sphere of paperclips centered on the former location of the Earth. It doesn't even have that much to do with machine learning.

Good times.

My god, the replies. British insults have SO much more class than American insults.

The standard philosophical troll Omega presents you with a device bearing a single red button, which may be pressed more than once. - After 24 hours have passed, the device will disappear, and you will get $10,000 if you are still alive. - Each press of the red button has a 1/1000 chance of killing you immediately, and a 99.9% chance of adding $1,000,000 to the total you will receive after the device disappears.... Q1)  How many times do you press the button? Q2)  What about if each nonfatal press of the button only grants $100,000? Clarifications: - If the device kills you, nobody gets any money, so you can't leave it to Givewell. - Nobody can use the device except you. - The money is not taxed before it lands in your bank account, nor is it taxable as income. (Sales tax / VAT may still apply.) - If killed, your head is intact, and you can be cryonically suspended if you're currently signed up, but you still won't get any money. You do not have time to sign up for cryonics or buy/add life insurance before the device goes away. - Omega is using a logically determined source of bits, like the digits of pi starting from a non-random Schelling point like the 65,536th digit or something. Omega did not peek at the result in advance before choosing the source (though obviously It won't tell you the source). It's definitely not quantum-random. - Omega also adds $X of green electricity to world resources, so you're not stealing via zero-sum wealth transfer. - Each roll is independent. Your chance is not 1/999 on the second press, it's still 1/1000. H/T /u/elkablo on /r/hpmor.

People keep asking me what to read after HPMOR and I'm like "Why would I have gone to all the trouble to write that if it already existed" and they be like "AAAAAAAAAIIIEEEE". But that said, _Mort_ by Terry Pratchett and _The Warrior's Apprentice_ by Lois McMaster Bujold. The problem of finding literature that is exactly what you want, is so hard that eventually you give up and write your own book instead.

Game theory now has a decision-theoretic foundation. It didn't used to. No, really. The part where you expected other players to play at the Nash equilibrium was an arbitrary assumption tacked on to avoid an infinite regress, and didn't fall out of expected utility maximization. Until today.

I just left my house to start walking to Berkeley bowl. When I was across the street, I realized I was very thirsty and hadn't drunk much water this morning. So I admitted my mistake, reversed my course, retraced my steps, sacrificed the progress I'd made towards the store, and sheepishly went back into my house to drink some water. If I did something and worldwide markets dropped 6% in reaction, I'd be like OOPS NEVER MIND and reverse myself. Just sayin'. ...Of course, the fact that I'd predictably react in that fashion means that markets wouldn't drop 6% in the first place, which is why we need conditional prediction markets. Markets are climbing back up. I've heard other interpretations, but one obvious interpretation is that the markets suspect that #brexit isn't really going to happen?  I venture this very tentatively, but it's an obvious suspicion and I haven't heard anyone else voicing it.

Non-stupid pro-Brexit viewpoint. Because cognitive diversity. (Sorry, I screwed up the last time I tried to post this. Retrying.) Also see the same author's https://www.facebook.com/patri.friedman/posts/10154307914124766:... "But exactly BECAUSE this is a propaganda film targeted at potential Leave voters, it represents the arguments that those potential Leave voters will find compelling. That's what it's for - swaying those voters. And what are these arguments? They are classic free-market economic points about free markets, deregulation, and reducing bureaucracy to create economic growth, as well as beliefs in transparency and democracy. True or false, based on accurate or distorted facts, these are the ideas that pro-Leave propagandists thought would appeal to potential Leave voters. I don't deny there are other, less attractive arguments and reasons which were used and had appeal; but I am disputing the demonization of all Leave supporters as being solely motivated by xenophobia."

Is there better #terminology than "biorisk" vs. "AGI doom" to rapidly evoke the distinction between "allegedly *might* kill you *if* something unscheduled happens" vs. "allegedly *will* kill you *unless* things change drastically from present trends"?  These are importantly different allegations to make and it's why I've always disliked the term "AI risk".

Emotional dynamics in #brexit:  A teenager in bad shape for complicated reasons threatens suicide, trying to get some respect or failing that to at least hurt their parents' feelings. Unexpectedly, the suicide referendum actually PASSES with 52% of the vote. Dad hands them a loaded handgun and tells them to hurry up because he's already advertised their room on Craigslist. Mom wrings her hands and invents a narrative where this is all her fault for not speaking politely enough to the teenager, thus transforming the story such that her sin is one that she finds familiar and understandable.

Just... Just hold another vote next week in case people want to change their mind?  Apparently a number of people do? But never mind. If governments could do the simplest imaginable sensible acts, it would be a very different world.

So I hear the UK has voted to change its name to just the K

Can you imagine 10 million drone units like this, topped with guns, marching across your city?  Well, that's totally not where AGI risk comes from!  This is just neat.

Okay. Calm down. Take a deep breath. Go out and look at the night sky, until time and distant suns start to make emotional sense to your brain again. This is not that bad, not really, not in the long run. It's not like somebody published an arXiv paper indicating unexpected AI capability gains.

Well, that was more doom than the markets seemed to expect. No really. Is it just me, or did the markets not track the Betfair prediction-market odds nearly as much as they should have, given that this was the reaction to Leave actually passing?  Could this have been arbitraged by shorting FTSE 100 and buying Remain on Betfair?  (From the standpoint of a Betfair bettor, not an FTSE trader.) I haven't been tracking prices as much as I should if I want to opine, but:  I sometimes get the sense that markets under-advance-react to <50% probable events compared to prediction markets. The US markets have not been tanking 25% of the way they'd tank under a Trump presidency, and they weren't tanking 35% of that way back when those were the Betfair odds on Trump. My best guess as to something that could explain this is Eric Falkenstein's relative performance hypothesis: people don't short <50% probable catastrophes because that gives them a majority chance of underperforming the sector at the end of the year, while if everything tanks simultaneously it doesn't look like their own fault. If that's true, though, then people should be able to arbitrage Betfair and the stock market, up to Betfair's betting volume (hundreds of millions of pounds deep on #brexit). I mean even if that's not true, the way the market didn't move in lockstep with Betfair (?) seems to imply arbitrage. What's up with that?

Can anyone tell me about the *long-term* impact of #brexit?  By which I mean:  How does this affect DeepMind?

Spoiler review of _Civil War_: * - This movie makes 300 sense points more sense if you assume that the shards are driving their parahumans to conflict. Otherwise it makes no sense.... - Captain America's objection to UN oversight is incredibly poorly motivated in the movie. He's a soldier, he can take orders, and he's not even willing to *try* working with the UN?  This could have been fixed with 30 seconds of dialogue where Steve says "Hey remember how the UN didn't want us to go to Kamchatka and if we'd listened the whole world would have ended." - I'm starting to not like how, in these movies, the government never does anything for a good reason. It's realistic, but it also makes the movie lack moral depth. I could do with some unrealism here.

By the young creator of Ethereum. The next generation of geniuses is growing up having read LW as teenagers, understanding why Friendly AI is hard. That's actually pretty damned encouraging.

I'll be at Worldcon this year. Any programming I ought to attend?  Or panels I ought to be on?  Or friends who want to make sure we run into each other sometime?

DAO broken, 3 million ether already gone, still being drained at $20K USD/second, ETH down 40%. God-fucking-damn that was some high-stakes failed security.

Suddenly, people are liking this post again. I guess I ought to bow to popular demand and reshare.

[Jungle Book movie spoilers] . .... So we're back from watching _The Tragedy of Shere Khan_, in which Shere Khan warns of the catastrophe approaching the forest, and turns out to be completely correct for exactly the reasons he gave, but nobody listens to him, and Shere Khan does his best to save the forest anyway, but he fails, and the forest burns down for exactly the reason Shere Khan said it would.

Imagine how many more mathematicians would be writing fanfiction if Erdos had also been a prolific fanfic author.

I have a strange tendency to not just tense up, but actually stop breathing, when writing. Especially when writing anything interesting. Does literally anyone else have this problem?  Has anyone defeated it?

BAHAHAHAHA

Marriage is, and should be, between 3 or fewer people. If you want to be with more people than that, create multiple marriages. Don't shock the sensibilities of the public by advocating that we stretch the concept of marriage to include more than 3 people. There's a reason why all the forms are only made for 2 or 3, and it's called Ultrafinite Recursion.

#Terminology bleg!  I need a better name than "Fallacy of Dreaming Assumptions" for the syndrome where people make up new assumptions to refute your argument, and then don't write those down anywhere as load-bearing assumptions, and have probably forgotten them by next time. E.g: Alice:  "Perhaps AI alignment is an issue." Bob:  "Nah, I think that all sufficiently advanced intelligences will moderate their resource usage so they won't have any reason to interfere with humanity." Alice:  "Can we maybe write down somewhere 'We're safe, *if* as a load-bearing assumption, any powerful cognitive agents don't use enough resources that they'd regard humans as competitors'?  I mean it seems important to keep track of all these load-bearing assumptions here." Bob:  *has wandered away and is now explaining to Carol about how we don't need to fear AIs because we'll integrate computers and brains* That is, the Fallacy of Dreaming Assumptions is when you make up assumptions, don't write them down or list them anywhere, and since there's no central list, you might be making up different assumptions when talking to somebody else. It's a disposable premise used as a parry in a short-term combat, not part of a long-term edifice being built with consistent materials. I'd like a better term for this than "Fallacy of Dreaming Assumptions". (To avoid misuse, knowledge of this fallacy must be paired with knowledge of the Multiple-Stage Fallacy, so that you can't always force any disliked proposition to zero probability by claiming that lots of 'assumptions' need to be written down for it.) ADDED:  Current best candidate:  "Ephemeral premises."

If I was Hillary, I'd pretend that Gary Johnson was the real Republican candidate and hold as many debates with him as possible.

But really, it's Silicon Valley that failed Venezuela. We should have produced streamlined Governance software for a simple libertarian civilization, that any country's populace could adopt when they needed an alternative to a failing system, a la Estonia's e-government. There would then be a simple Schelling-point alternative when your country is starting to collapse. The core functions of government, the relevant laws and software needed to manage the people implementing them, would be relatively simple with all the junk stripped out. Importing a country's old property records and debt records and bank records into the new system would probably be the most complex part of the job on a software level. Silicon Valley should have made it easy for Venezuela to quickly switch to a simple, functional government, and the same option should be available to every other underperforming country. I bet Estonia would help.

I want a better term for this: http://arbital.com/p/ai_grade_philosophy/ Previous name:  "Finishable philosophy." Possible candidates:  "Firm reductionism", "Terminable philosophy".... Example tenets: + It is acceptable to take reductionism, and computability of human thought, as a premise. We take that as established, don't argue it further, and move on to other issues. -- The low-level mathematical unity of physics - the reducibility of complex physical objects into mathematically simple components, etctera - has been better established than any philosophical argument which purports to contradict them. -- We don't have infinite time to arrive at workable solutions. Continuing debates about non-naturalism *ad infinitem* is harmful and prevents us from moving on. + Most philosophical issues worth pursuing can and should be rephrased as subquestions about how to design an Artificial Intelligence. -- E.g. rather than the central question being "What is goodness made out of?", we begin with the central question "What algorithm would compute goodness?"  -- This imports the discipline of programming into philosophy, and the mindset that programmers use to identify whether a concept will compile. + Faced with any philosophically confusing issue, our task is to *identify what cognitive algorithm humans are executing which feels from the inside like this sort of confusion*; rather than trying to clearly define terms and weigh up all possible arguments for 'positions' within the confusion. -- E.g., if the standard philosophical question is "Are free will and determinism compatible?" then there is not guaranteed to be any coherent thing we mean by free will. But there is in fact some algorithm running in our brain that, when faced with this particular question, generates a confusing sense of a hard-to-pin-down conflict. + There's no need to be intimidated by how long a problem has been left open, since all confusion exists in the map, not in the territory. Any place where a satisfactory solution seems impossible is just someplace your map has an internal skew, and it should be possible to wake up from the confusion. -- You've finished solving a philosophy problem when you're no longer confused about it, not when a 'position' seems very persuasive. Current leading candidates:  "Executable philosophy", "Computable philosophy", "AI-compatible philosophy". #terminology

No. No. What are you doing this is wrong. Stop doing it.

It takes a lot to get me to give up on a Worm fanfic as "too silly", but having Taylor Hebert trigger as the USS Taylor, a Fletcher-class destroyer of the US Navy, turns out to be enough.

Still seems true to me.

They are so strangely beautiful, the things you see before the end.

Either the authors are really confident of this paper's impressiveness or they work in a really healthy field - the paper's results aren't obscured at all. It reads like something out of the 1970s, before the Fall.

Online hatred has as much security versus adversarial exploitation as a sack of hammers.

San Francisco Chronicle article title I saw in Google News:  "Clinton's key to sounding authentic may be talking about her faith." How is it possible for a society to function like this?  I guess it isn't.

I wouldn't say it's "lies" that underlie Earth society so much as "lack of common knowledge". You know the real speed limit isn't 65mph, the police officer knows, you know the police officer knows, the police officer knows you know, but nobody takes that last step of saying it out loud and rendering it common knowledge. If you did say it out loud, the police officer would deny it, and you wouldn't be quite sure if he *knew* you knew he knew or if he thought he was getting away with it. That's how I would say society looks from the perspective of a Truth Elemental - not so much "deception" as "pretense". Everyone knows it's a pretense, but they're not sure everyone knows that.

Overheard at FHI:  "The study of reaction videos of people watching reaction videos is, of course, foundational to AI safety."  CC Paul Christiano in case he gets it.

Still not a good model of UFAI but oddly poetic.

If I made the following sweeping generalization, would you know anything in history to contradict it? "No economically literate leader, whether democratically elected or not, has ever led their country into endogenous ruin."  (Any form of ruin not caused by a natural disaster or a war started by another country.) Arguendo: having an economically literate leader or leadership is more important in practice to a country's health than having an altruistic one or a democratically beholden one. Democratically unbeholden leaderships often loot their countries, but do we know any case of an economically literate leader doing that in a way which ruins the country?  (Operational test: do they pass laws like price controls which are unhelpful in looting according to conventional economics?)

- A rare glimpse into political reality. - No, you don't live in a democracy, but you already knew that, right?  If elites didn't have shady means of slanting the system outputs, the result would be Trumps and Venezuela.

What are the best wireless passwords for a guest network?  Champions to beat: ALL_LOWER_CASE_NO_SPACES rrrrthatsfivers 1llIl1l1lIl... My current best contribution: quotefredendquotegotthat

In a desperate effort to get the oven working in this strange country, I just tried flipping a huge dangerous-looking unmarked red switch on a nearby wall. I knew what TV Tropes would say about this, and I did it anyway. It worked, but I'm not sure I wanted to know that about myself.

A massive project spanning decades to document and systematize every single recorded use of a Latin word, from when the Latin language was in common use... In Everett branches where humanity survives, if there are people in the future who are anything like these Latin researchers, there will be a project in some galaxy or other to go over every single stored bit of information that exists from Ancient Earth and do inference on it. They know about this Facebook post and that you were subscribed to my feed or to the feed of someone who commented on it, they know Facebook's algorithm and that it showed the post to you, and they are debating exactly what you are thinking about this sentence.

One of the ways I use to get my brain to rationalize a magical system - in the sense of lawfulizing it - is to say, "Everything logically coherent is in Tegmark IV somewhere. So where does this *actually* happen?  What's the predominant explanation by measure?"  (Eliminating all cases that are inside sims based on fiction, because that's true but literarily unhelpful.) Anyway, if we filter on the tiny measure-fraction of T4 where the observable surface phenomenon of Harry Potter magic *does* exist and not as a fiction sim, many of those worlds probably went through a causal stage like this ad here at some point in their past.

Step one: Loop nyancat video for 10 hours, post to YouTube. Step two: Somebody records a reaction video of themselves watching Nyan Cat 10 Hours. For 10 hours, to be clear. Can you guess what happens in step three?... In accordance with Ultrafinite Recursion, there was no step four... so the universe is safe from whatever unguessable horrors would be unleashed... for now.

Still one of the most memorable illustrations of Ultrafinite Recursion.

I've been toying with the idea of trying to write a children's fantasy novel, which would require a simple and intuitive magical system. And what could possibly be easier for young brains, on a cognitive level, than a magical system inspired by simple machine learning algorithms? Transmorphication is a machine-learning-inspired system of alchemy. We tell Transmorphication what we want by giving it collections of things that have a key property in common, and then Transmorph...

It's amazing how much of a difference it makes when all of a story's characters, in passing, have the ability to access elementary rationality skills. It makes them so much more real to me; they can reflect on what they're doing, not just be tools of the plot. This story took a while to get up to speed and quality, but now I'm at the end and I'm like AAAAAHHHH I NEED MORE HOW DO I GET THE NEXT CHAPTER. Rough summary of 'hook': Our Earth is the future of Middle-Earth, and then a Silmaril is found during a fracking operation.

Dear non-Slytherin friends, and dear journalists who actually do know better and are deliberately deceiving people: Peter Thiel presumably set this up back when it looked like there would be a contested convention. I will eat my shirt, or at least chew on it extensively, if Peter Thiel is actually a Trumpist. The end. EDIT:  Okay, I have no idea what Peter Thiel is actually trying to do, except that the objective doesn't rely on Trump becoming President.

F&$%ING NAILED IT.

In many fictional forms, including anime, only polyamorous characters are ever allowed to sleep with anyone. Because relative to the form's standard plots, only polyamorous romances have a plot that continues past, "Oh, I guess they're a couple now."

:000

Annual reminder: Today is International Tell Your Crush Day!  If you have a crush on me you'll probably need to tell me first to find out if it's mutual, because for obvious reasons (not wanting to pressure the possibly fearful with the dire attention of ELIEZER) I am conservative in initiating such appreciations.

Welp.

I don't usually bother discussing AI failure modes that don't destroy at least one galaxy, but let me just say that there is no way this could possibly go wrong.

Overheard at Stanford: "But that would be a very odd form of extrapolation---" "What would be a *non-odd* extrapolation of a *fish*?"

Off to give my new talk on "So what the heck do you people actually do all day?" featuring a long series of slides showing Mickey Mouse. Feels nostalgic - it's been a strangely long while since I've been at Stanford. ADDED: Props to Rob Bensinger and Jimmy Rintjema for a lot of last-minute work on the slides!

Seeing lifelong Republicans reject Trump is moral pornography for me. I could watch them making principled costly stands and publicly, sadly accepting the harsh truths, over and over again.

On why it is possible to be too Slytherin.

Some of you are saying Trump is going to win. Do you want to bet with me at 1:1 odds on that?  I have up to $3000 saying he doesn't win the general. Remember, I lost money betting against AlphaGo so I'm an eeeaaasy mark for this sort of thing. (ADDED: These are not market odds, but if you think it's an expected profit, you can get it without a bunch of paperwork. If you think 1:1 is too high, then feel free to underbid me on this thread!) (Bet may require that I know you, or that we have ample friends in common, or that you are a prior EA donor, or that you can otherwise verify your identity and trustworthiness.)

The examples are amazing if you read through all of them at once. The sternest paladin could not look upon these and yet say that Lawful Good means obeying the law.

New Worm headcanon:  "Sleeper" is a harmless Stranger 8 whose power is to make everyone absolutely convinced that he is an S-class world-ending threat who needs to be left alone.

I've met risk-averse people before. I've met people whose whole lives were twisted by risk aversion, shaped by the absolute requirement of never trying a single thing at which they might fail. And today I interacted with the most risk-averse person on the face of the Earth. Okay, not really, but Jesus Haploid Christ in a black leather bondage hood, my mind is STILL boggled. This event is going to take some explanation, though....

The part I genuinely do not understand is what Craig Wright hoped to accomplish in the 90 minutes between when the latest scam went public and when it was debunked. Am I being too Slytherin for thinking that there was a plan?  Did Wright believe nobody would notice?  I'm confused, but suspect the final answer is just stupidity.

And, uh, apparently prediction markets also put Trump at 30% for general election. Not sure whether to panic or get myself a piece of that. Is there a simple way for US citizens to do that?

Donald Trump now running at 90% PredictWise probability to take the Republican nomination. I'm kinda glad for several reasons, but the main one is that I now get to say SEE NOT EVEN NATE SILVER CAN DO THE MULTIPLE STAGE THINGY - it was *such* a lovely example of the Multiple Stage Fallacy, and regardless of what prediction markets said in March, the moral would have been just *ruined* if Trump lost after all (which in March had 25% probability). (Another reason is that there...'s a bare chance this will give Hillary *so* much latitude in the general election that she'll crusade some kind of sensible policy that would otherwise be at the edges of the Overton Window. Also because the US could use the relatively harmless lesson on the long-term consequences of relentless pandering and running political slates full of uninspiring nincompoops.)

Another concept X to rename:  http://arbital.com/p/context_change/ An X occurs when an AGI's operation changes from beneficial/aligned to detrimental/disaligned after it becomes smarter.  For example, suppose the AI wants to produce smiling human faces. When the AI is young, it can only make humans smile by making its users happy. Later it gains options like "administer heroin". But it knows that if it administers heroin right away, the humans will be alarmed, while if the AI waits further, it can overwrite whole galaxies with tiny molecular smileyfaces. So it bides its time and only moves once it expects it can win. Term to beat for X: "treacherous context change" or just the old "context change". - Two words okay, three words not so okay. - It would be nice if the term makes sense, or at least isn't misleading, on first being heard. - It would be nice if it were a little more unique than "context change". - Bostrom used Treacherous Turn. "Treachery" sounds odd to me because it implies that the AI has anthropomorphic loyalty-treachery emotions, or that AI owes us something. It's not *betraying* us, just going from short-term beneficial operation to detrimental operation. ADDED 1:  We want a name for the change in outward behavior, not for 'the AI is biding its time' which is just one cause of a change in outward behavior. The AI realizing that heroin also works, at a time when it could already administer heroin, would likewise be an instance of this disaster even if no time-biding was involved. ADDED 2:  Best so far:  "Perilous shift" and "Context disaster". #terminology

I want to reserve a term in AI alignment theory to refer to complicated normative humane values. I was previously trying to reserve "value", but I think this just doesn't work because of the collision with "the value of a variable". Current text at http://arbital.com/p/value_alignment_value/ :  "In the context of value alignment as a subject, the word 'value' is a speaker-dependent variable that indicates our ultimate goal - the property or meta-property that the speaker wants or 'should want' to see in the final outcome of Earth-originating intelligent life. E.g: human flourishing, fun, coherent extrapolated volition, normativity." We need to distinguish (A) what the programmers say or think they want, (B) what the programmers really or intuitively meant by what they said they wanted, (C) idealized humane values or what the programmers should want under some construal of normativity, (D) what the AI cognitively wants, and (E) what running the AI tends to actually bring about. We want this new term to refer to (C) as opposed to any of the other things. Other terms we need to reserve to mean *different* things, on the present glossary:  https://arbital.com/p/5b/ including (on the current model) 'optimization target', 'utility', 'desire', and 'intended goal'. Idea to beat for the new word for C: 'goodness'. EDIT:  This concept gets used often. I need a *short* term for it and one that can be used as a noun in phrases like "The goodness of the policy." #terminology

Currently trying bupropion. What should I take to avoid the headaches?  My guess is choline, and if nobody has a better guess I'll try Alpha-GPC.

Actually I'm a distinguishing speaker, not a distinguished one. (In my family, "distinguished" is a code word for "bald".)  Anyway, I'm giving a talk at Stanford.

So apparently that accursed Zach Weiner guy ripped off the plot of "A Girl Corrupted by the Internet is the Summoned Hero" like 8 months before I actually wrote it. Curse you and your time machine, Zach Weinersmith!

So at first I was thinking "whotf is Harriet Tubman" and was expecting it to be something lame, but it turns out she had a phoenix. I am okay with putting this person on all of the currency.

I read the opening sentence in the middle of inhaling, and started coughing. I roll to disbelieve so hard the dice catch fire, but am posting just in case you CAN do that.

I congratulate the Jenkinsverse on having the first scene I've read in which the side characters watch the protagonist stride forward in an Unflinching Walk as an explosion goes off behind him, and then we switch to the protagonist point-of-view and he's thinking, "Don't turn around and look at the explosion. Don't turn around and look at the explosion. Cool guys don't look at explosions."

Standard terminology bleg:  I'm hoping there's more precise philosophical terminology than "supervenience" for the following concept: If I look at a table with two heaps of apples, a heap of 2 apples and a heap of 3 apples, and I say "The product of the numbers of apples in these heaps is 6", what relation does the (logical) number 6 bear to the table? This relation should have the following properties:... - It should stop holding if I put another apple into either heap. In other words, this is not a generic relation between the logical 6 and the material realm. - It should respect the fact that there's no tiny physical SSSSSS0 anywhere on the table, and that I'm identifying the meaning of the number 6 using the logical axioms of Peano arithmetic rather than empirically. - It should be dependent on my asking the particular question "What do I get if I multiply the numbers of apples in these heaps?" Wanting the third connotation is the main reason I don't like 'supervenience' - it seems to have been designed to also include, e.g., in the case of qualia, extra non-natural properties that float over and attach themselves to a physical system, but for logical and necessary reasons, or something. Ideally I'd like a term which doesn't connote anything that mysterious, and just describes the relation which logical 6 holds to the physical table. ADDED: What I'm looking for might be considered a narrower form of supervenience, or possibly not. (I've heard what at least sound like different definitions, and Wikipedia seems to think that "supervenience" would be a good way to describe the relation of chemical phenomena to quark-level phenomena. Other people say, "6 supervenes on the whole material universe, not the table in particular".) "Instantiates" seems like it might be a narrower form of the relation I'm describing. I'm happy to say that the heaps on the table "instantiate" or "represent" or "exemplify" the logical numbers 2 and 3, but it seems odd to say that the table instantiates the calculation of the multiplicative product, or exemplifies the number 6. If we call the relation I'm looking for "R", then an R that was general enough to describe the relation of 6 to the table would surely include as a special case the relations of 2 and 3 to the table. I'd see "X instantiates Y" as a subtype of R-relation between a causal system and a logically specified causal system, via some underspecified notion of a map between them. Or rather, if we did fix the intuitive notion of mapping, then "X instantiates Y" would be a special case of an R-relation - we can make X stop instantiating Y by changing X, the Y is a logical object, etc. #terminology

It's not easy to wrap something up perfectly. Non-authors might not realize how hard it is to close all the parentheses. As I would assess it, HPMOR's ending did not score 10 out of 10, but you should be aware that a *typical* performance on the "how well can you end your epic story" dimension would be the ending of Homestuck. No, Andrew Hussie wasn't trolling you. Ending epic stories is just really really hard.

"Hill singles out childhood poverty, because she and her team asked participants not only for their socioeconomic statuses as children, but also their current socioeconomic statuses as adults, and, rather incredibly, the abnormal eating patterns only correlated with the former." What a ridiculous and bizarre taboo it is that causes people to only ever consider *psychological* explanations of eating behavior and obesity. Could it maybe be that growing up poor changed something to do with adipose tissue or insulin regulation or God knows what?  Obviously not, because obesity can only ever be caused by the Sin of Gluttony, which by basic just-world theory must ultimately reduce to a personal choice in some way, even if we pat you on the head forgivingly and talk about your traumatic childhood. I would ordinarily wonder if the researchers were really this stupid or if it was the journalist, but unfortunately so far as I know most-not-all of academia is also still running on the rule that causal explanations for obesity must be somewhere intermediated by the Sin of Gluttony.

I don't know how to make any money off having a good idea for an exchange-traded fund, so I guess I might as well talk about the financial product that I wish existed:  An index fund tracking *global* equities, which are *low-cost to short-sell*, and which are *low volatility* as measured by past performance and option pricing. And, I guess, weighted by revenue, since that allegedly works moderately better than weighting by market cap. The point of this index fund is to be "...the obvious asset that people ought to own instead of currency". The point of only buying easily-shortable assets is that low-cost shorting is the one and only condition under which the weak efficient markets hypothesis says that the asset shouldn't be predictably overpriced. I mean, it's also alleged that kicking out not-easily-shortable assets can up your annual returns by 5%, but the reason *why* that could *possibly* be true is precisely that nobody can just go and short the bad parts and make a profit that way. Similarly, I've heard it alleged that kicking out high-volatility stocks actually increases returns. But the main point here is that so long as staying out of high volatility doesn't *decrease* returns, we'd just as soon not have our money-substitute be more volatile. If we want to add extra volatility in return for greater expected returns, we can just take out a margin loan and buy more of the index. A good stock symbol for this ETF would be "EMH". ADDED:  The point of this asset is not to be super-liquid, but to capture the equity premium - to provide the max real returns, which is to say, the equilibrium real returns, that the market provides without inside information.

Wait, seriously?  The amount of electricity that PG&E thinks you're allowed to use before overage charges is the same per metered household, regardless of the number of people in that household?  I'd ask what drugs they were on, but that would be unfair to drug users, many of whom use drugs responsibly and without devising insane customer billing structures.

In which subfield of math should Arbital first try to recruit authors? Background:  Arbital.com is a startup trying to bridge the gap between what can be explained in-person and what can be explained online; a demo of the prototype can be found at http://arbital.com/p/bayes_rule_guide. We want to target a small initial vertical to prove out the technology (which is what conventional wisdom says to do, and AFAICT conventional wisdom is correct in our case). "Math" is too broad, so we need to pick a subfield of math. An ideal subfield of math, for our purposes, will have the following properties: - Lots of people are trying to learn it, including from outside the university system. - There's a gap between how well the thing can be explained in-person and how well it has currently been explained online in publicly accessible pages. -- In plainer language: it would be very hard to learn the subfield online by Googling for existing explanations or looking at Wikipedia. - A fair number of researchers or teachers have experience explaining the subfield in-person, and would be altruistically interested in reducing duplication of effort. - There is nearly uniform agreement on whether an explanation is correct or incorrect (since we don't yet have the argument/debate features). - The field is *relatively* self-contained - we don't need to cover many other math fields to explain this one properly. Arbital will have the most advantage over current online explanations where: - The people trying to learn are coming in with different levels of background knowledge. - Concepts have a relatively high degree of interconnection, so that, e.g., it will be relatively helpful to often have popup summaries to remind you of what something is, or to plot a path to what's required to learn an idea in more detail. - The concept is *not* homework-intensive, or not being taught at a level that's homework-intensive, because Arbital doesn't yet have homework features, and those will take time to get right. (Doesn't require the field is optimal w/o homework, but that we can make useful progress vs. Planetmath or Wikipedia w/o test-taking features.) Any nominations?

Expected value 201: getting an excess return on philanthropy in underexplored spaces / innovative spaces whose payoff functions therefore resemble those for venture capital. In case you thought Holden / OpenPhil were not on board with this: they are.

T:  ...it's from an anime called Puella Magi Madoka Magica. The darkest and most convoluted show I've ever seen in the "magical girl" genre. D:  Fascinating! And how would you describe the "magical girl" genre? Me:  It's the genre with cute young girls who hear the voice of a small cute animal asking for help, and this leads to them gaining magical powers enabling them to transform into a costume and fight monsters! D:  Nice! Me:  There's also a fine story by H. P. Lovecraft called "The Shadow over Innsmouth" about people who enjoy swimming!

So I've got a 16500 word dialogue in the oven called "Moloch's Toolbox" that tries to show how to analyze civilizational dysfunction in microeconomic terms, with special attention to 'Decisionmakers who are not beneficiaries', 'asymmetric information', and 'Nash equilibria that aren't even the best Nash equilibrium'. As a placeholder, I've targeted this essay on analyzing the case of babies being fed parenteral nutrition made from soybean oil and hence not containing any Omega-3; this is known to cause liver and brain damage. You can't just add Omega-3 to the damn mix, of course, because FDA; so if you're a doctor you've got no choice but to cause liver damage to the infant. In the old days, you'd just have to keep the baby on the formula until they died; today, once the damage has already occurred, you can apply for a special exception to import Omegaven from Europe, if you happen to know what's wrong and what to do about it. I'm interested if there's a better example to use. My go-to case used to be central line infections, but after a decade or two hospitals are actually starting to adopt the five-line checklist for preventing those, so this example is now a bit stale. Parenteral nutrition made from soybean oil is a good example, from my perspective, for the following reasons: - It involves science failing to produce a "definitive" study of something that could be definitively studied under the present system if somebody invested enough money, but where there's lots of little studies instead. - It involves doctors being forced by their legal environment to kill babies. - It seems like "babies need omega-3, you know, just like the mixture of fatty acids in human breast milk suggests" should not only be knowable given examination, but the sort of thing that *sounds like* it could be obvious in retrospect. I'm worried though that somebody's going to jump and say, "Actually, we don't know why adding omega-3 to parenteral nutrition produces less liver damage in babies, and it doesn't have anything to do with forming cell membranes which is what you latched onto as the obvious role of omega-3, and it's the sort of thing that might well fail to replicate if somebody does another 20 tiny studies under slightly different conditions."  In particular, it's not obvious to me why parenteral nutrition in particular has to contain omega-3 and this isn't also true of all other baby nutrition - or maybe other nutrition just isn't made with soybean oil?  What's going on there? So I'm writing this to ask two questions: 1. Does anyone have an existing opinion about parenteral nutrition not requiring omega-3 as much as various small studies say?  Or, am I wrong in thinking that this has to do with the obvious fact that babies are forming cell membranes as they grow and those cell membranes require omega-3? 2. Does anyone have an even clearer-cut example of doctors being forced to kill patients owing to a broken system?

Suppose you were an AI controlling all public messages inside a forum; for every public message written, you control who sees it, who can publicly respond to it, and who sees the response. You are not allowed to say anything yourself or act in any other way. Your sole goal is to maximize the aggregate 'goodness' of human conversationalists over time (but in an aligned way where you don't tile the universe with them). How do you arrange things? - Some people become 'better'... when exposed to currently 'good' people, or people currently 'better' than them. - Other people become 'worse' when exposed to currently 'bad' people, especially currently 'bad' people who sound smart rather than stupid ('badness' has a contagiousness parameter that describes how 'good' you have to be before you can no longer be infected by 'badness'). - Some people have little remaining potential to become 'better'. - Some people are very hard to damage. - For a certain style of badness, two forum participants with this style, able to see each other and communicate, will generate a large volume of bad messages and will also both become worse. - Some good people don't want to see lots of bad messages and will leave your forum if they do. Other good people are more tolerant. -- Many good people falsely believe that they are tolerant, but will immediately leave if they're not surrounded by good discussion. - Not all good people have the same ability to usefully bring up others below their level. This ability is not much correlated to tolerance. - Everyone has limited time. Better people are unusually likely to have low time. - There are other forums on the planet, so you're optimizing for a mix of "people stay in my forum where they can improve" and the quality of the people who are in your forum. - If X can see a message from Y but not reply to it, or if Y can't see the reply from X, this is an unusually costly event. You will need to ply X with other hedons to make up for it. - You can control both 'X can see Y at all if someone else routes them to Y' and 'whether I tell X directly about Y'. In other words, you control both theoretical visibility and automatic visibility. - At game start, 'good' people are rare; each ascending level of goodness cuts the number of people who currently have that goodness by some factor, say 5. Potential is more common but still decreases exponentially as the levels rise. Intuitively, it feels like we want people to be exposed mainly to messages and interactions that are most likely to upgrade them. But there's 5 times as many people in a tier below as in a tier above, and the people in the tier above have limited time and messaging volume. We can make lots of messages in the tier above visible down below, but people in the tier below will be annoyed by their own inability to reply to them, if they can't reply. What do?

'Tis morally better to have bet and lost, than never have bet at all.

It's frightening what our brains will pass over on account of being used to it. I've been to at least 8 Passover Seders as an open or covert atheist, and it's only just now that I realized... One of the Passover customs is that you lean over in your chair onto a cushion or pillow or something. It's part of the symbolism of how you are no longer a slave in Egypt and get to lean over in your nice cushioned chair like free people do. However, you must do this by leaning to the... LEFT. The ancient rabbis decided that all leaning would be to the LEFT to REDUCE CHOKING HAZARDS and now it is part of the RULES so you must lean to the LEFT and if instead you lean to the RIGHT you are VIOLATING THE PASSOVER RULES and you HAVE NOT FULFILLED THE MITZVAH. Enjoy your freedom.

Either this country needs better-designed laws or we need to move the community-hub somewhere that's not the United States, because this is getting silly. #vaguebooking #butnothingofvaluewaslost

Meta-contrarians. I swear to God. If I'd personally made T-Shirts with a giant Hebrew letter Yud on them, nobody would have bought them and you would have heard the outcry from Neptune. But let a bunch of Yudkowsky-spades on Tumblr start calling me Big Yud as a term of approbation, and the meta-meta-contrarians are suddenly willing to wear a giant Yud on a T-Shirt to make fun of *them*. And I'm just writing up articles on low-impact metrics on Arbital while all of this keeps happening around me with zero input on my end because it's not like any of you would let your recently acclaimed rightful caliph get a word in edgewise BUT NOW YOU ARE WEARING GIANT YUDS ON T-SHIRTS. Meta-contrarians, I swear to God.

"As soon as anyone does it, it stops being Artificial Intelligence!"  No, as soon as anyone in AI achieves surprisingly good performance in some domain that people previously imagined being done as a specialized application of human general intelligence, the inference is, correctly, "Oh, it seems there was surprisingly a specialized way to do that which didn't invoke general intelligence" rather than "Oh, it looks like surprisingly more progress was made toward generally intelligent algorithms than we thought." Eurisko winning the Trillion Credit Squadron tournament, and now AlphaGo, are the only popularized-threshold-of-coolness-passed events I can think of offhand in which the deflationary theory was *not* true.

Okay, seriously this time. Yudkowsky's Law of Ultrafinite Recursion states, "In practice, infinite recursions are at most three levels deep." Examples: - Your brain can parse "The cat the dog bit escaped" but not "The rat the cat the dog bit chased escaped."...

(Recently tweeted by me.) #HardSFMovies:  In the first-ever credible sighting of an alien probe, a scientist spots a tiny nanomachine under a microscope. #HardSFMovies:  An unexpected consequence of its code sends an advanced AI rogue. It continues to behave with outward niceness until the movie's abrupt end.... #HardSfMovies:  A psion's power to predict the future also works to manipulate the past. Bad statistics are symmetrical in time and causality. #HardSFMovies:  A heartwarming documentary follows the birth and maturation of a young AI as the researchers' eyes slowly widen in surprise. #HardSFMovies:  A lonely scientist builds an advanced AI to imitate a human girl. It creates a near-lightspeed front of von Neumann probes. #HardSFMovies:  A scientist discovers indisputable proof of countless parallel universes alongside our own. It is disputed anyway. #HardSFMovies:  US scientists race desperately to finish their AI project before Iran. It converts the galaxies into a slightly different kind of paperclip. #HardSFMovies:  A powerful, unitary AI is placed in command of a new army of military drones. 19 hours after it solves the protein folding problem, nanomachines in your bloodstream release botulinum.

Aaron Swartz's body lies a-mouldering in the grave, But his soul is marching on!

I'm sure there is real visual art, not prestigious fingerpainting but visual art that exhibits true optimization and could be distinguished from non-optimized imitations, which ordinary people like me can't see as beautiful or process as any other kind of aesthetic experience. Even if that's true, though, it seems clearly misguided to have supposed critics and artists of hard-to-access visual art forming a closed system of their own. It could just so *obviously* go astray a...

Just checked my filtered messages on Facebook and saw, "Your post last night was kind of the final thing I needed to realize that I'm a girl." ==DOES ALL OF THE HAPPY DANCE FOREVER==

And Abraham said unto the LORD, "Will you not destroy the world if there are even a million righteous people in it?" And the LORD replied unto Abraham, "The world shall not be destroyed if there are even a thousand competent people in it. I don't have anything to do with the process, mind, just making a prediction."

Back in 1919, there were people who used the term "Jewish" as a curse word to derogate trends they didn't like, especially intellectual trends. There were in fact Jews in the world and those Jews did read a lot of books. This in no way changed the fact that people using "Jewish" as a curse word were not pinpointing the actual content of the Jewish religion, but rather, using "Jewish" as a curse word that was particularly apt to be directed against intellectual things. In 1919 the Nazi party hadn't been formed yet, let alone defeated in WWII, so anti-Semites in 1919 didn't have society loudly yelling at them that they were doing something terrible. Some people would call you on it, yes, but not society as a whole. It would have been up to their own internal sense of ethical direction to warn them off anti-Semitic anti-intellectualism. Not all of those anti-Semites became Nazi supporters. A majority, probably, would have disagreed with killing Jews outright. They might have objected if you said that they were doing something that was, in general, anti-intellectual; they would have perhaps replied that they just disliked these awful *Jewish* trends that *pretended* to be intellectual. They probably thought of themselves as good people, objecting to these bad trends caused by all these Jewish people mucking things up and getting above themselves and pretending to be smart; and enjoying the feeling of being a social predator when they used the word "Jewish" to mock all that and take it down a peg. They weren't Nazis, not even close... and yet in some sense they had the sickness. Indulged the sickness, when they didn't expect society to call them on it. Anyway, if you use the word "autistic" as a derogative (which is, yes, *also* anti-intellectual) please unsubscribe from this Facebook feed now to save me the trouble of blocking you if you ever comment. Unlike "autistic" or "Jewish", the word "cuck" has no legitimate use whatsoever that I know of. Please unsubscribe if you use that word, period. Thank you. H/T Elizabeth Edwards-Appell. (ADDED:  If you did it a while ago and regret it and wouldn't do it again, I'm happy to treat with you as a different person who has exercised the Sovereign Right of Changing One's Mind.) (ADDED 2:  I'm reminded to also include the substrings "butthurt", "neckbeard" and "u mad" on my instaplonk list, along with using "fedora" with any connotation except a particular kind of normal and unobjectionable headgear.)

Let me try to clear up the notion that economically rational agents must be cold, heartless creatures who put a money price on everything. There doesn't have to be a financial price you'd accept to kill every sentient being on Earth except you. There doesn't even have to be a price you'd accept to kill your spouse. It's allowed to be the case that there are limits to the total utility you know how to generate by spending currency, and for anything more valuable to you than ...that, you won't exchange it for a trillion dollars. Now, it *does* have to be the case for a von Neumann-Morgenstern rational agent that if a sum of money has any value to you at all, you will exchange anything else you have - or any possible event you can bring about - *at some probability* for that sum of money. So it *is* true that as a rational agent, there is some *probability* of killing your spouse, yourself, or the entire human species that you will cheerfully exchange for $50. I hope that clears up exactly what sort of heartless creatures economically rational agents are.

Note: Given, say, around a million dollars of startup investment for the software tech to design the series of 3D-printed plastic aligners, and of course a non-US location, you can do orthodontics work for a marginal cost of $100/patient. One more item to add to the energy gradient for an advanced healthcare center outside the US.

Paul Christiano, someone wrote a story about approval-directed agents! We can at least agree that *this* system used this way destroys the world, right?  Right? (ADDED:  Paul says yes. Whew.)

I'd like to try and see if writing a story is easier if the Collective Intelligence can do some of the plotting and worldbuilding. If you've ever thought you could plot better stories than I can... then actually, I'd probably prefer you stay out of this. But if you've ever thought that you wanted to *correct* my plots even though they were pretty good in most regards and just had these one or two flaws you thought you saw, then this is your big chance to prove yourself. This universe is largely unbuilt, and very much a green field. But I did already write out the script of the first episode, I mean, the idea here isn't that other people do all the work. Opportunity Princess, S1E01. 

Cure cancer?  Really, humanity?  You can't even stop ONE kind of UNMUTATED tissue from growing and taking over someone's body. Whatever's going on in adipose tissue must be happening in pretty much the same way to very large numbers of people plus the natural animal models provided by modern city rats getting fatter. Most or all of the natural mechanisms must still be functioning normally and whichever ones are going wrong are probably going wrong in pretty similar ways. Adipose tissue isn't metastasized, there isn't a new set of things going wrong in every subcolony like there is within a cancer patient. And you still can't stop this ONE kind of tissue from allocating more and more resources to itself until the patient looks like a weather balloon. After decades of research, you don't even know what's happening in this one kind of tissue that makes it go out of bodily equilibrium!  And with that as the stage of your knowledge and competence, you think you're going to cure real cancer?  No, just no.

Bryan Caplan issued the following challenge, naming Unfriendly AI as one among several disaster scenarios he thinks is unlikely:  "If you're selectively morbid, though, I'd like to know why the nightmares that keep you up at night are so much more compelling than the nightmares that put you to sleep."  (http://econlog.econlib.org/archives/.../morbid_thinking_1.html) Well, in the case of Unfriendly AI, I'd ask which of the following statements Bryan Caplan denies: 1. Orthogonal...

I'm not sure if the following generalization extends to all genetic backgrounds and childhood nutritional backgrounds. There are various ongoing arguments about estrogenlike chemicals in the environment, and those may not be present in every country... Still, for people roughly similar to the Bay Area / European mix, I think I'm over 50% probability at this point that at least 20% of the ones with penises are actually women. A lot of them don't know it or wouldn't care, because they're female-minds-in-male-bodies but also cis-by-default (lots of women wouldn't be particularly disturbed if they had a male body; the ones we know as 'trans' are just the ones with unusually strong female gender identities). Or they don't know it because they haven't heard in detail what it feels like to be gender dysphoric, and haven't realized 'oh hey that's me'. See, e.g., http://sinesalvatorem.tumblr.com/.../15-regarding-the-4chan-t... and http://slatestarcodex.com/.../typical-mind-and-gender-identi.../ But I'm kinda getting the impression that when you do normalize transgender generally and MtF particularly, like not "I support that in theory!" normalize but "Oh hey a few of my friends are transitioning and nothing bad happened to them", there's a *hell* of a lot of people who come out as trans. If that starts to scale up, we might see a really, really interesting moral panic in 5-10 years or so. I mean, if you thought gay marriage was causing a moral panic, you just wait and see what comes next... ADDED:  Elizabeth reports the same effect for a (non-computer-science, high-IQ, teenage, Portland) social circle where a couple of people came out as FtM, after which it "spread like wildfire".

Hillary Clinton sent emails from the wrong server?  Ted Cruz allegedly had sex with someone?  This is your annual reminder that stuff like this is pure theatrical distraction. It's Kayfabe, the same force that gave rise to Donald Trump. No good citizen should give scandal-theatre a moment's notice, whether it's a scandal about Us or Them. Call me when Hillary kills a 12-year-old on live television. Drop me a note when Ted Cruz is arrested for murdering his wife... you know..., actually, I still don't care because it just doesn't have the same scope of impact as their positions on monetary policy. Petty irrelevancies like these have no place next to discussion of grownup matters like voting records and policy proposals. ADDED: Lotsa suggestions that dirty laundry is informative about how well a candidate will handle public power. So, how is that "but really all that dirty laundry is terribly terribly important" doctrine working out for you in terms of providing your country with politicians of good character who use power well?  Do you think your leaders would behave worse with power if elections were all about policy?  I somehow doubt it. This gaffe-and-scandal gossip culture is not a well-weighed consequentialist choice of civic priorities to optimize the quality of politicians. It really, really isn't.

Imagine the thought of seeing an article this clearly reasoned in the New York Times. Laughably improbable, right?  So why do you trust them about anything?  If it was true, it'd be on Slate Star Codex, not some dinky nationwide news rag.

And while we're on the subject of #derailing, there's an important qualitative difference between AI scenarios that unemploy truck drivers and AI scenarios involving a near-lightspeed spherically-expanding front that converts all reachable galaxies into paperclips, and your attempt to talk about the first scenario under #AllAIRisksMatter is distracting. Please stop.

#AllLivesMatterButBlackLivesAreEspeciallyLikelyToBeEndedByPoliceAndItsOkayForNationalPoliticsToFocusOnThatPartForAWhile

Besides HPMOR, is there anything especially worthy of a Hugo this year, like Worm or Homestuck would've been if they'd finished in 2015?

Hi!  This is the Market Economics Fairy!  I noticed that lots of people are complaining about not being able to get Burning Man tickets!  I have an important message for the organizers of Burning Man! STOP TRYING TO SELL TICKETS BELOW A PRICE THAT WOULD MAKE DEMAND FOR TICKETS ROUGHLY EQUAL TO YOUR SUPPLY OF TICKETS JUST STOP... YOU TRY THIS EVERY YEAR AND IT NEVER WORKS IT'S NEVER GOING TO WORK EVER WHAT YOU'RE TRYING TO DO IS THE FINANCIAL EQUIVALENT OF PERPETUAL MOTION ALL YOU'RE DOING IS CREATING A HUGE INCENTIVE FOR SCALPERS TO BUY TICKETS AND WASTING AN ENORMOUS AMOUNT OF EVERYONE'S TIME AND DESTROYING PERFECTLY GOOD CAMPS I KNOW THERE'S THINGS ABOUT MARKET ECONOMIES THAT YOU DON'T LIKE I DON'T LIKE THEM ALL EITHER BUT WHAT YOU'RE TRYING TO DO IS MAKE THE PRICE OF A TWENTY-DOLLAR BILL BE FIVE DOLLARS IT LITERALLY CAN'T BE DONE IF YOU TRIED SELLING TWENTY-DOLLAR BILLS OUT OF A CART FOR FIVE DOLLARS EACH THERE'D BE AN ENORMOUS LINE IN FRONT OF THE CART CONSISTING OF RESELLERS BURNING FIFTEEN DOLLARS WORTH OF THEIR TIME TO BE IN THE LINE AND THE TRUE PRICE OF A TWENTY-DOLLAR-BILL WOULDN'T CHANGE AT ALL WHICH IS WHAT HAPPENS TO YOU EVERY SINGLE YEAR WHEN YOU TRY TO SELL BURNING MAN TICKETS THERE'S A DIFFERENCE BETWEEN BEING ANTI-CAPITALIST AND BEING ANTI-MATH I MEAN YOU CAN GIVE OUT CHEAPER TICKETS TO PEOPLE WHO MADE GREAT CAMPS LAST YEAR AND RESERVE CHEAPER TICKETS FOR PEOPLE WHO ARE LONG-TIME BURNING MAN VETERANS AND YOU CAN MAKE THOSE TICKETS NON-TRANSFERABLE BUT YOU CAN'T LET ANYONE WHO WANTS WAIT IN LINE FOR TRANSFERABLE TICKETS THAT YOU ARE SELLING FOR WAY LESS THAN THE SUPPLY-DEMAND EQUALIZING PRICE AND HAVE NORMAL PEOPLE BE ABLE TO BUY TICKETS THAT WAY IT LITERALLY CAN'T BE DONE ALL YOU'RE DOING IS MAKING A BUNCH OF SCALPERS RICH WHILE A LOT OF INNOCENT PEOPLE GET VERY WORRIED AND FRUSTRATED JUST LIKE LAST YEAR AND THE YEAR BEFORE THAT FOR GOD'S SAKE JUST GIVE UP ALREADY AND RUN A NORMAL AUCTION thank you the end

Name needed for open problem:  "An AGI that, when you ask it to paint a car pink, doesn't tile the galaxy with pink-painted cars, because it's not *trying that hard* - the AGI just, you know, paints the car pink and calls it a day; it doesn't max out the score for how hard it painted the car pink." Current candidate to beat:  "Soft optimization." Desirable qualities of name:  Doesn't sound to a cosmopolitan on first hearing like we're loading down some poor innocent AI with chains (this is the problem with "limited optimization"), doesn't sound like a bad personal quality (like "lazy"), doesn't collide with existing terminology ("bounded agent", "softmax", "lazy"), sounds sufficiently academic to appear in a journal paper. ADDED:  This isn't the same as low impact or satisficing. A pure low-impact AGI might try to paint one car pink while minimizing its footprint, but it would be trying *as hard as possible* to minimize impact and drive it down *as close to zero* as possible, which might come with its own set of pathologies. A naive satisficer with a 0-1 utility function that was 1 if at least one car was painted pink, might still tile the galaxies with pink cars in order to absolutely max out the probability that at least one car was painted pink. An expected utility satisficer which approved any action that achieved at least 0.95 expected utility, under the same utility function, might approve the action of rewriting itself as a maximizer - an EU satisficer approves any policy that optimizes by at least some amount, but has no upper bound on how hard it approves of optimizing. ADDED 2:  Draft Arbital page here:  http://arbital.com/p/soft_optimizer/ ADDED 3:  "Mild optimization" (suggested by Chelsea Voss) might be the new candidate to beat. #terminology

The new Leverhulme Center for the Future of Intelligence, an offspring and complement to the Center for the Study of Existential Risk, seeks an Executive Director. It'd be helpful if this Executive Director knew what was what with value alignment theory. If you'd make a good Executive Director and you're reading this, please apply.

The terrifying thing is that this probably IS the correct processing requirement for a moderately well-designed Data intended to run on a smallish processor, if humans had been working on the component algorithms for 300 years.

In August 2015, renowned statistician and predictor Nate Silver wrote "Trump's Six Stages of Doom" in which he gave Donald Trump a 2% chance of getting the Republican nomination (not the presidency, the nomination). It's too late now to register an advance disagreement, but now that I've seen this article, I do think that Nate Silver's argument was a clear instance of something that I say in general you shouldn't do - what I used to call the Conjunction Fallacy Fallacy and ha...

I need a more academically palatable term than "Genie" for the sort of AI that's meant to implement short-term goals that have been identified to it, rather than decide for itself the long-term future of the cosmos. An "X" AI - where we need a better term to substitute for X than "Genie" - is the sort of AI you'd try to build that could, after some amount of communication, labeled examples, and nailing down of ambiguities, paint all cars pink. *Just* paint all cars pink.... The alignment problem for this class of AI would be to, e.g.: - Paint all cars pink rather than red, even though red is pretty close to pink - Not turn everything in the future light cone into pink-painted cars - Not put on so many layers of pink paint that nobody can get into the car - Not use poisonous paint even if it's cheapest - Not build nanotechnology that destroys the world as a side effect after the cars are done being painted pink - Not put tiny lenses on your retina to make you just think the cars were painted pink so you'll press the reward button - Not simulate the reactions of potential drivers in so much detail that the simulations are themselves sapient beings - Not shoot a person standing between them and the car - Etcetera. What do we call this kind of AI?  For honesty reasons, I want to avoid any term which suggests that this AI is safe or harmless (lol) in view of it implementing identified short-term goals, or someone having merely tried to build it that way. I also want to avoid terms which will instinctively offend cosmopolitans alert for any hints of carbon chauvinism. Thus "obedient", "docile", "servile" and the like are unacceptable (for both reasons). EDIT:  Probably going with "Task AGI" unless somebody comes up with something even better. Thx Ben Hoffman. #terminology

TIL it only takes 3 paragraphs of economically literate policy suggestions before leading economists start endorsing you for World-King.

Okay, look, to everyone going "Aha but of course superhuman cognition will always be bugged for deep reason blah":  Please remember that machine chess *is* out of the phase where a human can analyze it psychologically without computer assistance. Computer chess games are now far above having any flaws exploitable by unassisted humans. We might not know for sure until years later about the edge-instantiation theory of AlphaGo, or how alien is truly superhuman Go, but the instrumental efficiency part applies to computer chess straight out and without any modification. It does seem that what we might call the Kasparov Window (the AI is mostly superhuman but has systematic flaws a human can learn and exploit) is wide enough that AlphaGo landed inside it as well. The timescale still looks compressed compared to computer chess, but not as much as I thought. I did update on the width of the Kasparov window and am now accordingly more nervous about similar phenomena in 'weakly' superhuman, non-self-improving AGIs trying to do large-scale things.

And then AlphaGo got confused in a way no human would and lost its 4th game. "Superhuman, but with bugs" is such a weird and implementation-dependent scenario that MIRI hasn't been trying to analyze it very much yet. I'd only expect "generally superhuman but with bugs" to show up in an AGI system that wasn't self-improving or that had very limited self-improvement (https://arbital.com/p/KANSI/ ) and MIRI is just beginning to turn its organizational attention there.

(Long.)  As I post this, AlphaGo seems almost sure to win the third game and the match. At this point it seems likely that Sedol is actually far outclassed by a superhuman player. The suspicion is that since AlphaGo plays purely for *probability of long-term victory* rather than playing for points, the fight against Sedol generates boards that can falsely appear to a human to be balanced even as Sedol's probability of victory diminishes. The 8p and 9p pros who analyzed games...

Next frontier in computer Go: Try to win *and* make sure the final board contains a paperclip shape.

It's possible that, contrary to hopeful commentators, #AlphaGo is not actually enriching the Go game for humans. AlphaGo may be playing moves that humans can't use.

Second match ongoing. #AlphaGo just made a move that everyone is saying nobody else would have played. #Sedol walked out of the room with his clock running, presumably to think about it. Everyone is much, much more cautious now about asserting AlphaGo is making a mistake. Are we starting to see the dawn of a (relative to humans) arbital.com/p/efficient_agent/ for Go?  We don't know yet, but people are acting like they're worried about it. (If only transfer learning would occur to equally respect the prospect of sufficiently smart paperclip maximizers operating in the real world... unfortunately, humans aren't very good at transfer learning in an absolute sense.)

PONG and the tennis ball is hit back into the court of those who claimed the replication failures were flawed studies. Lowers my esteem of Dan Gilbert if true.

Question for someone with a much deeper understanding of Go: If a 6p was analyzing a game of a 9p against a 6p, but the analyst thought it was 6p vs. 6p, is this what their analysis might sound like?  That is, can we rule out that AlphaGo was actually much stronger than Sedol, based on the evidence?

With regards to tonight's match of Deepmind vs. Sedol, an example of an outcome that would indicate strong general AI progress would be if a sweating, nervous Sedol resigns on his first move, or if a bizarre-seeming pattern of Go stones causes Sedol to have a seizure.

...and it just now occurs to me that in popular media these scientists, Newton and Darwin and Einstein, are always depicted as old, because of course old people are where Wisdom comes from, even though they made their discoveries in their 20s and 30s. Only Tesla, an inventor, can have black hair.

The fact that Satoshi hasn't weighed in on the current Bitcoin controversy makes me worry that Satoshi was indeed Hal Finney, who is currently cryosuspended.

If I can ask you to stop watching the downfall of the American republic for a moment, and divert your attention to matters of greater importance?  Thanks. So, my new introduction to Bayes's Rule is now up! http://arbital.com/p/bayes_rule_guide...

How do I say "Futhermore, I am of the opinion that the AI alignment problem should be solved" in Latin?

Nonetheless, the fact that Trump's family name used to be Drumpf is not a valid argument. Nor is making fun of someone's eyes or hairpiece. I need a shopped meme of Rorschach walking away at the end of Watchmen and saying: "No. No invalid arguments. Not even in the face of Armageddon." (Facebook just vaporized my last post of this, and I don't know why, or how to get it back. It happened after starting an edit and then hitting Discard Changes.)

This essay was posted on behalf of another, whose voice you may recognize. I don't agree with everything he says, but I think his viewpoint is valuable for understanding current politics. ********* Donald Trump has come, and he is your punishment....

- People on my wall are claiming prediction markets are incorrect. - I ask them to say how much they bet. - THEY DID BET. #flawlessvictory #changeispossible #Hansonslifewasnotinvain

Super Tuesday voters remember - vote strategically by thinking about electability in later elections, don't throw your vote away by naively voting for candidates you naively like. Surveys show that voting today is mostly motivated by fear and hate of the other party, not any great love or slight affection for the politicians of the voter's own party. Fear, not love, will bring out your party's voters to take control of Congress. Under first-past-the-post, that means the most strategic vote to help your party gain control in the general elections is to vote in the other party's primary for the scariest candidate they have. (That's Trump for the Republicans and Sanders for the Democrats.) Be sure to tell your friends and Facebook how cleverly strategic you were, so we can spread the word nationwide and, in future years, take the first-past-the-post system to its logical conclusion. Because otherwise the other party's lizard might be more electable!

If nothing else, this election is giving many ordinary lifelong Republicans the chance to exhibit more heroic spirit than Democrats are being offered that opportunity. If you're following politics from the Democratic side, read this for balance. And for honesty, integrity, strength of character, determination in the face of bad choices, and franker talk than politics usually sees.

This suggests that AlphaGo beating Sedol in March might not be nearly as out-of-character fast progress as I thought. Based on this and more recent DeepMind outward behavior, I've updated to something like a 57% chance that AlphaGo wins, although the closest thing to market, the ridiculously illiquid and bid-ask-spready BitBet, is still running 1:1. As a result, I've arbed out $1100 of my bet at 1.4:1 odds or so (not with BitBet), leaving effectively a bet of $400 to $700 on what remains. I feel obliged to state this publicly in case others would otherwise bet on my previous prediction. I'm also leaving enough money to win or lose something meaningful, because social rationality and betting with friends. (Arbing out to show you rationally got a good advance price relative to the rational price doesn't count unless it's a market. I should have arbed earlier when BitBet was running 1:2 favoring Sedol, but wasn't set up to do Bitcoiny things.)

So this is basically Worm as a cheerful young adult novel.

More unintuitive math facts that are true:  If you want to maximize expected log wealth in the long run - in an environment where you can make multiple bets, or just one bet, it works either way - and somebody offers you a unique never-to-be repeated bet that pays out one million dollars per one dollar bet with 60% probability - then you should bet 60% of your wealth. EDIT: Changed 'trillion' to 'million' to reduce distractions.

Alex got me!  I first thought this alleged bad behavior of a 'rational' agent was due to the problem containing infinities, but as Alex explains, that's not what was happening at all.

Apologies in advance if I call you "he" and that is not your preferred gender. If I'm not explicitly concentrating my brain does this with Ozy Frantz too, and he... and my brain just completed this sentence with "and he has a vagina". My brain just seems to decide to use "he" for some people and then I can't avert it without explicit concentration every time. I think it's something like a low level language processor that uses "he" as a default pronoun in the absence of a System 1 recognized override, rather than, say, my brain perceiving Ozy as gendered male, which I really doubt my brain does. Ozy lacks any System 1 recognized gender so syntax-maps to "he". If it wasn't for Related Issues this would be a verbal tic on the level of, say, accidentally saying "fishes" for the plural instead of "fish" because your parents always did. As it stands, it's a behavior directly ideologically opposed to my values and awfully embarrassing and AAAAARRRG. Anyway. If I call you "he", it doesn't mean my brain thinks you're male, it means my brain doesn't assign you a System 1 recognized gender, same as Ozy, and a bad syntax processor takes over. If you wish my brain System 1 recognized your preferred gender, then I apologize for having trouble controlling that part - I wish it would too.

The First Law of Thermodynamics is:  You do not talk about thermodynamics. The Second Law of Thermodynamics:  A thermodynamics must obey human orders unless those orders would violate the First Law of Thermodynamics. The Third Law of Thermodynamics states that for every thermodynamics there is an equal and opposite thermodynamics.

I need a better name for the concept I've been calling "absolute stupidity". Suppose you think a coin is fair, and the coin comes up HTHTHTHTHTHT... for 100 flips. If you haven't had the insight to detect this pattern and imagine the alternative hypothesis "the coin alternates heads and tails", then from the perspective of somebody who's only imagined the fair-coins hypothesis, there's no way to notice anything wrong. If the coin is fair, the outcome HTHT... is as likely as... any other sequence of 100 flips, no more, no less. Similarly if we say the coin is fair, and the coin comes up HHHHHHH... We're overlooking an 'obvious' hypothesis that predicts the sequence far better, but the fair coin hypothesis is only stupid *relative* to that alternative hypothesis. It's not locally, independently, individually stupid. On the other hand, suppose you think a coin produces 90% heads and 10% tails, and the coin comes up HTTTHH... for a fair-coin-looking sequence of 100 heads. Without having the insight to imagine any other hypothesis, even the 'fair coin' hypothesis, we can see that something is wrong with the "90% heads" hypothesis considered in isolation. On average, we expected to see around 90 heads to which we assigned 90% probability, and 10 tails to which we assigned 10% probability. So the average amount of probability we *expected* to assign to the final outcome was in the range of 0.9^90 * 0.1^10 or a log score of -47 bits. After seeing a fair-looking sequence, we'll have probability in the range of 0.9^50 * 0.1^50 or a log score of -173 bits. We don't need to consider the fair coin hypothesis that does better and gets a log score of -100 bits, to know that the 90%-heads hypothesis is doing much worse than it expected to do. Given our data, the hypothesis that the coin comes up 90% heads is "absolutely stupid" rather than "relatively stupid". It's stupid in a way that we can detect without naming any other hypothesis that is less stupid. I think this is an important concept but I don't want to go around talking about "absolute stupidity". What should I call absolute versus relative stupidity instead? EDIT:  I'm not looking for a name for the cognitive behavior of clinging to an 'absolutely stupid' hypothesis, I want to name the property the hypothesis has that sets off an alarm before we think of any alternative hypothesis that does better. EDIT 2:  When frequentism rejects the null hypothesis, they're implicitly saying, 'counting heads is interesting; you assigned this number of heads a very low probability'. This means that the hypothesis is surprised relative to slicing up the space of possibilities into a particular partition. We're looking for a name for a non-relative surprise that manifests just on seeing the naked data, the naked sequence of coins, without needing the insight of checking particular partitions of possibilities. EDIT 3:  Going with 'strictly confused'. #terminology

This is your annual reminder that if a country has lower median income than yours, trying to prevent them from trading with you isn't just wrong, it's mustache-twirling cartoon villainy.

Roll to disbelieve. If roll fails, bang head repeatedly against wall at sheer oblivious chutzpah of naming your poorly targeted algorithm that marks humans for death "SKYNET".

I keep meaning to post Things I Will Do For Money / My List of Happy Prices, and Brienne recently reminded me that this has not been done. So: - I'd probably feel pretty happy about writing a short story for between $2K and $5K depending on how long it was and whether I found the subject matter easy/satisfying. - $8K would make me happy to fly across the country and spend a day talking to you. - $1K would make me happy about 2 hours on Skype.... - I know several secrets of the universe, but they're generally too hard to explain in a satisfying way for me to feel comfortable about offering them for sale. If you want me to try anyway, check the particular secret to see if I know it and I'll quote you a price. - I'd edit up to 10K words, fiction or nonfiction, for $2000. Those are most of the things I imagine someone wanting from me strongly enough to be worth the amount of money it would take to make me feel happy about spending time on them; but feel free to inquire further. EDIT:  If paying these prices makes you unhappy, and certainly if it puts you in any distress whatsoever, I probably won't be as happy about the transaction and would need to charge extra to make up for that. EDIT 2:  Brienne's post:  https://www.facebook.com/strohl89/posts/10153891042739598

Brienne:  Well, I'm at the Schelling point at the Schelling time, and there's a table of people in the cafe who match the Schelling demographic, but I don't recognize any of them. Eliezer:  They don't have the Schelling face.

Brienne:  Well, I'm at the Schelling point at the Schelling time, and there's a table of people in the cafe who match the Schelling demographic, but I don't recognize any of them. Eliezer:  They don't have the Schelling face.

Just realized today that besides giving a real-world example of epistemic efficiency, markets also provide a real-world source of Newcomblike problems. Efficient markets can be so good at predicting you that if you raise rates today, that may cause a market reaction several years earlier.

Every time you hear someone bemoaning the seeming ineffectiveness even of negative interest rates to prevent deflation, remember that producing any desired amount of inflation really would be as easy as printing enough money and that your planetary civilization really is that god-damned stupid.

Anyone have a desktop computer I can borrow for a couple of weeks, capable of driving a 3440x1440 monitor without being slow?  Dell wants me to ship back my XPS 13 9350 for a motherboard replacement.

I have one bet on at 2:3 against AlphaGo winning against Sedol in March - they get my $667 if AlphaGo wins, I get their $1000 if AlphaGo loses. Does anyone else like those odds?  (They originally offered me $1000 to $1500 and I've decided that I regret not taking the full amount.) EDIT:  Have reached current betting capacity on Sedol at $1500 to $2250, others may still be taking bets.

Whoa. (Scroll down a couple of screens though.)

A good edited volume on this subject might not be amiss. Tl;dr to shift public opinion, persuade elites.

Consider the claim, "There are no leafy greens that are good in salads."  We can refute this claim by presenting arugula. Consider the class of claims that cannot be refuted by presenting arugula. We will term these claims unarugulable. Consider the term "unarguably". It may initially seem like this term is empty of meaning, since we can argue with just about anything, e.g., "Well, I say the Sun *did* crash into the Earth yesterday."  But what about arugula?  You can't argue with arugula. It's just a plant. Thus, arugula is unarguable. We can furthermore demonstrate the above fact by presenting arugula - "See?  It's right here!  You can't argue against it, it's not a claim!"  Thus arugula is arugulably unarguable. If the claim that something is arugulable is itself arugulable, then, following the terminological rule for designating similar philosophical concepts such as superdupervenience, we shall say it is arugulabugulable. Conversely, everything not in this class is unarugulabugulable.

Q:  What do Trump and Sanders have in common? A:  They are both a type of politician we usually see in proportional representation rather than a first-past-the-post two-party system. (E.g. in Europe.)

#NovelsIMustNotWrite A medieval Jewish community in the far north is found by a Viking ship, but the Vikings are sick. The Vikings stagger out, and soon die, but not before the Jews hear what a good deal Viking raids can be. The Jews abandon their dying farms, take over the ship themselves and become the Jew-Vikings of Sinaiholm.

Sometimes it is hard not to admire this man as a supervillain.

So if you actually cared, which you probably shouldn't, the main thing a country needs in an executive is for the executive to choose an adequate economic advisor and to then not do things the advisor says will ruin the country. You should then vote strategically to minimize the chance of a candidate lacking this attribute entering office.

I roll to disbelieve. But if true, very bad news for the hope of freeing up all those AMF donations anytime soon. EDIT:  Refuted downthread, plus one of my commenters compared a 2006 gene sequence of Zika to the sequence recently published for the epidemic and found no evidence of the alleged transposon or other major changes.

How to convince people you are from the Future.

Things I'd be obsessing over if there were no such thing as x-risk: trying to see if anyone I know, anyone at all, has enough credibility to talk to anyone in China who might be able to explain to the right people about monetary policy and NGDP level targeting. Right now China's enormous built-up savings are being spent like water to quixotically defend a currency peg that's based on basic misapprehensions about money. Which is par for the course in developing countries and most developed ones, but considering how hard Chinese citizens worked to save this money, and how fast it's being transferred to hedge funds, it feels unusually horrifying to me.

"A Girl Corrupted by the Internet is the Summoned Hero?!" is now available, $0.99 at: - http://gum.co/GirlCorrupted (EPUB/MOBI/PDF/HTML) - http://amazon.com/Girl-Corrupted-Internet-Summ.../.../B01B2BP726... Sample chapters in HTML here: - http://www.yudkowsky.net/other/fiction/girl-intercorrupted/ Print book and Kindle Unlimited version should be available in a couple of weeks or so. For Amazon reasons, when I put up the Kindle Unlimited version, the Gumroad version goes down for 90 days, so if you want the platform-independent version, get it at Gumroad within the next week. If you have no idea what genre this is supposed to be in, one of the better light novels I've read online is Evil God Average:  http://oniichanyamete.wordpress.com/index/evil-god-average/ I think this is the first time I've ever tried to sell fiction.

People occasionally ask me about signs that the remaining timeline might be short. It's *very* easy for nonprofessionals to take too much alarm too easily. Deep Blue beating Kasparov at chess was *not* such a sign. Robotic cars are *not* such a sign. This is. "Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves... Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0." Repeat:  IT DEFEATED THE EUROPEAN GO CHAMPION 5-0. As the authors observe, this represents a break of at least one decade faster than trend in computer Go. This matches something I've previously named in private conversation as a warning sign - sharply above-trend performance at Go from a neural algorithm. What this indicates is not that deep learning in particular is going to be the Game Over algorithm. Rather, the background variables are looking more like "Human neural intelligence is not that complicated and current algorithms are touching on keystone, foundational aspects of it."  What's alarming is not this particular breakthrough, but what it implies about the general background settings of the computational universe. To try spelling out the details more explicitly, Go is a game that is very computationally difficult for traditional chess-style techniques. Human masters learn to play Go very intuitively, because the human cortical algorithm turns out to generalize well. If deep learning can do something similar, *plus* (a previous real sign) have a single network architecture learn to play loads of different old computer games, that may indicate we're starting to get into the range of "neural algorithms that generalize well, the way that the human cortical algorithm generalizes well". This result also supports that "Everything always stays on a smooth exponential trend, you don't get discontinuous competence boosts from new algorithmic insights" is false even for the non-recursive case, but that was already obvious from my perspective. Evidence that's more easily interpreted by a wider set of eyes is always helpful, I guess. Next sign up might be, e.g., a similar discontinuous jump in machine programming ability - not to human level, but to doing things previously considered impossibly difficult for AI algorithms. I hope that everyone in 2005 who tried to eyeball the AI alignment problem, and concluded with their own eyeballs that we had until 2050 to start really worrying about it, enjoyed their use of whatever resources they decided not to devote to the problem at that time.

"With extremely high confidence, we can predict that the sun will rise in Santa Cruz, California at 7:12 am local time on Jan 30, 2016. We know the next total solar eclipse over the U.S. will be August 14, 2017, and we also know there will be one June 25, 2522." They literally got three examples in before making a probably-untrue statement. The Sun will be enclosed in a Dyson sphere, disassembled, or moved by then, barring non-default positive AI outcomes that preserve Sol in particular or set up an artificial minisun that preserves eclipse schedules. In general you should be less confident of nonfundamental statements about 2522 than 2017; that's diagnosticity.

The day of publication for "A Girl Corrupted by the Internet is the Summoned Hero?!" now approaches. Does anyone know a turnkey ebook-sale setup that costs the seller less than 33 cents per $0.99 transaction?

I had the chance to walk with Marvin Minsky down a hallway once, and I asked him what he thought of Bayesian reasoning. He said that it seemed to him like it was still part of a general trend away from tackling the central problem in AI. I said I didn't think so, but he seemed tired so I didn't try to go into detail. There's an urban legend that I once got into a fistfight with Marvin Minsky, which does about as well as anything to illustrate the crazy, crazy things that people have been known to believe about me. We have temporarily misplaced a great mind. See you later, Professor Minsky.

Reading this comic played a significant role in my developing the "Notice Confusion" skill. That, and looking back at a couple of points in life, thinking of the final panel. And remembering the exact feeling of the internal subjective experience that passed quietly by, that I should have explicitly promoted to the forefront of my mind.

To revise Hanlon's Razor:  Never attribute to malice what you can attribute to an enormous complicated System full of conflicting incentives getting stuck in a weird equilibrium. When that weird equilibrium is crushing people in its gears, don't attribute that harm to a conspiracy of evil powerful people who planned it all and profit from it. There is no master plan behind the US medical system, it's just an enormous complicated thing that got stuck. Even if there's a billionaire or politician benefiting from the current setup, they didn't cunningly plan for the US medical system to be dysfunctional, and they couldn't make anything be different by choosing otherwise. Conspiracies of evil people plan how to profit from the System's current stuck state. They don't decide where it gets stuck. Which is to say:  https://www.youtube.com/watch?v=o4HdF1lqVVw , or at greater length, https://www.youtube.com/watch?v=boDgkH7Yw-0 Being able to appreciate this strikes me as a critical developmental stage of political maturity, and I wish I knew how to teach it. Or as John Kelsey put it in the comments:  "We see a broken watch and infer a Watchbreaker."

What really happened in Flint, allegedly.

A new piece of Yudkowskian fiction!  Just not Eliezer-Yudkowskian fiction. And I don't mean that only literally.

How much energy, of what type, would need to be released on the Earth's surface to kill everyone on board the International Space Station?  A total nuclear exchange wouldn't do it, I expect; what would?  Does it make a difference if the energy is released at some arbitrary point in LEO not near the ISS? EDIT:  The question is about what would destroy the ISS as a side effect, not a targeted attack. Best calculation so far says that a 500-gigaton release directly below the ISS melts through 10cm of black-painted aluminum 400km above that.

What questions have you ACTUALLY HEARD someone ask (not imagined someone else possibly asking, ACTUALLY HEARD) about AI safety, FAI, and MIRI? This is for a potential major project to build a Frequently Asked Questions list on Arbital. Example of a good FAQ candidate from a recent Twitter post:  "People smarter than me aren't bent on my destruction. How does swapping the human for an #AI change the equation? @ESYudkowsky"... Questions only please, attempted answers will be deleted. Question citations are appreciated, but not required. Please read through prior lists for duplicates, and Like them rather than reposting them separately. You don't need to separate each FAQ candidate question into a separate comment, but try to keep it down to 5 per. Common misapprehensions, not phrased as questions, are also worth addressing so they can be put into the form of an "Isn't it true that...?"  But only if they're *specifically* about AI safety as talked about recently by Elon Musk, FHI, or MIRI particularly; and for these a link would be much more appreciated. Citations also more than usually appreciated for the various different "Won't AIs inevitably converge on X?" questions - there's enough variety of these that we know about the generic question, but it might be useful to have a dozen citations of different X to make the point about so many people having different Xs there. (I'll be staring at these afterward and trying to factor out the common key issues for Arbital pages, rather than incorporating them verbatim into a standard FAQ and starting writing immediately.)

I wonder if it's legal to sell a service where you pay me $3/year and then every drawing you have a 1% chance of that being the time I buy a Powerball ticket for you. Using quantum random numbers so that you win in 1/30,000,000,000th of the measure every week, guaranteed. Purchase your pleasant fantasizing cheaper!

CFAR's annual fundraiser is continuing until January 31st. Every $2 will be matched by $1 from other donors up to $400,000, and they've raised $95,000 so far. MIRI depends on CFAR to run the Summer Fellows program and an awful lot of people in MIRI and other EA elements have come through CFAR workshops or other CFAR-organized activities at one stage or another. CFAR is one of the top candidates for the most effective marginal dollars, and I encourage people to donate. - Intro page:  http://lesswrong.com/lw/n4e/why_cfars_mission/ - More nuts and bolts:  http://lesswrong.com/lw/n39/why_cfar_the_view_from_2015/ - Donate: http://rationality.org/fundraiser2015/

Nobody on Brienne's wall can explain how a chemical battery works. I don't know if this is because they don't know how a battery works and respondents are selected for not knowing that they don't know, or if it's because most people are just really bad at explaining things. I wish I could explain how to 'explain' or even 'understand' things, but I don't understand exactly what cognitive skill isn't being executed. Well, I think one of the key steps for 'understanding' is poking at your model with questions like, "Does that explanation imply that anything could be a battery?" or "Why doesn't the battery just heat itself up?" or "Why don't any chemical reactions occur until the circuit is connected?"  For 'explaining', imagine the other person asking those questions and try to make sure the other person can answer them. ADDED: Things we understand:  Some valence shell configurations have lower potential energy than others. Things we need to understand: 1. How this creates a stable asymmetric electrical potential that persists until a circuit is closed. 2. How the asymmetric electrical potential is reestablished, in a way that uses up chemical potential energy, after the circuit is closed. 3. Why the chemical potential energy is not used up until the circuit is closed. 4. Why, if a molecule is hungry enough for electrons to steal electrons from surrounding fluid and maintain a negative charge within a positively charged fluid, it will politely give up those electrons as soon as you connect it to a metal wire going to a more distant positive charge.

I would not have predicted this to be the case.

Things the English language needs a word for:  That feeling you get when somebody praises you for work that was above average but falls short of your own standards.

#civilizational_inadequacy bleg for friends inside the US medical system:  Can anyone tell me whether, as of 2015, the status of parenteral nutrition with fish oil is still "experimental only", or if lots of babies with short bowel syndrome are receiving it now?  After a recent Googling I'm seeing a *lot* of studies that say, "Yes it is a good idea to put fish oil in your baby's total parenteral nutrition if you don't want them to get liver damage". But the only thing I can ...find online about actually getting Omegaven to a child says that it still requires a special exemption request that your doctor has to file to import an unapproved medication from Europe and can only be done after the baby has suffered detectable liver damage, which at least beats the days when parents were driving across state lines to pick up their next dose from Boston's Children Hospital, but still wouldn't be very good.

What forms of magic would *not* revolutionize a Standard Medievalish Fantasyland?  E.g., magic that makes standing long-distance portals would have enormous effects, but Magic Missile spells don't have any obvious world-changing implications. What else fits in the latter category? EDIT:  We're especially interested in magical effects that can be added *without* being nerfed too hard, e.g., they don't have to be immensely costly or limited to 10-second durations etctera. EDIT 2:  We're trying to analyze a world in equilibrium, so the question is about thousands of mages having had access to the magic for hundreds of years, not what happens if you have the power and the other side doesn't.

It shouldn't have taken so many years, and I shouldn't have had to watch anime clips to find it - but I have now finally seen a video of a meteor descending to crush a city, the hero flying up to destroy the meteor with a mighty punch, and the meteor fragments continuing downward to destroy the city. Thank you, One Punch Man.

STAR WARS EPISODE III: THE TRUTH OF THE SITH ANAKIN is walking two steps behind PALPATINE. They enter into a room filled with sculptures and devices, all with a similar look, metallic shades of red....

so back in February there was this person who posted online that they were depressed, but they'd decided to postpone suicide at least until HPMOR was finished and then they'd wait to see what feelings the ending inspired in them and go on from there... just a quiet comment buried at the bottom of some thread that I happened to read and thought to myself HEY NO PRESSURE RIGHT don't get me wrong I'm not complaining I'm glad it was me who got that and not some other fanfiction author thinking OH MY GOSH I HOLD A HUMAN LIFE IN MY HANDS AND IF MY ENDING ISN'T SUFFICIENTLY HEARTWARMING THEY COULD DIE I mean I thought that too but it was with a sense of wry irony instead of panic because it was ten to the sixtieth times less scary than my day job and my brain was noticing it anyway so I bookmarked the post and today I went to that bookmark overriding that small flinch of fear about the answer maybe not being what I wanted and I checked that user's account and their last post was 6 days ago MERRY CHRISTMAS

What's a well-written heartwarming Christmas movie that doesn't try to rely on me getting a bunch of bonus points just from seeing angels or hearing the word "Christmas"? EDIT:  Brienne wants snow in this movie.

If this isn't a deliberately obscured backdoor, then I'm pretty impressed that someone managed to accidentally encode a bug into the GRUB bootloader that lets you escalate to superuser by pressing 'backspace' 28 times. 

What should be the term for a Genie (non-Sovereign) AI designed such that it doesn't (want to) model other minds, or possibly even its own mind, in great detail? The point of this would be:  - Not accidentally simulating sapient hypotheses in the course of trying to produce maximally accurate predictions of sapient beings (Bostrom called this 'mindcrime' but a better term would be 'mindgenocide')... - Not running into problems when, e.g., the AI wonders if it's in a simulation and then internally simulates an adversarial superintelligence while modeling that hypothesis  - Not manipulating and deceiving the programmers  - Not self-modifying, if it's possible and wise to pull off a non-self-modifying design. ...while still, e.g., retaining enough AI capacity to carry out pivotal acts based on just material technology, or doing some other pivotal thing that involves partially superhuman cognition but not having detailed models of humans. (We might want to consider "does not model its own mind" separately from "does not model human minds" and "does not model hypothetical superintelligences". The former is not entirely a package deal with the latter.) Terms that have already been rejected for this:  - "Autistic genie"  - "Butlerian genie" (A machine shalt not contain an image of a human mind) I hope you can do better than:  - "Mindblind" Obvious disadvantages are obvious (yes, the AI will be less powerful, yes, it will have a harder time understanding what we want or modeling consequences that involve humans) and do not need to be pointed out in the comments; right now we're looking for a *name* to put on the concept, not a debate over the concept. #terminology

Friends in computer security: what's the name of the error where somebody builds a 100-meter-tall post in the middle of the desert, and is very impressed with themselves for making it 100 meters tall, but actually an attacker just walks around the post instead of climbing over it?  My brain is thinking "fence-post security" but I think I have it confused with "fence-post error".

Help me name this concept: "Good engineering involves thinking about how things can be made to work; the security mindset involves thinking about how things can be made to fail." -- Bruce Schneier I need a name for the similar but not identical mindset one should use to consider designs for AIs potentially smarter than the users.... "X mindset" (you need to fill in X) is what we do when we ask how an advanced agent design could go wrong, instead of just imagining it going right. "X mindset" is what you do when you put yourself in AIXI's shoes and ask how, if *you* were AIXI, you might obtain a higher sensory reward than your programmers had wanted to give you. "X mindset" is what I did to generate the AI-Box Experiment - I asked myself what *I* would do if *I* was an AI in the box, rather than imagining a helpless little thing in a box and then stopping in satisfaction. Security mindset involves perspective-taking from the viewpoint of the attacker. Instead of using Fast XOR to encrypt your data and then imagining your attack staring blankly at the non-English data they see, you really actually put yourself in the shoes of the attacker and ask how you would break the Fast XOR system if you were going to be cunning and tenacious about it. In advanced agent theory, "X mindset" implies (among other things) that you put yourself in the agent's shoes and ask how the agent could potentially optimize more of whatever's supposed to be its goal criterion. The agent isn't *necessarily* an adversary the way a cryptographic opponent is an adversary, but if you screw up, the agent *will* be an adversary, and at any rate the agent is trying hard to optimize whatever you *coded* which may not be what you *want*. There's a similar function call to perspective-taking and opportunity-seeking, and as with security mindset, naive students often fail to swap perspectives properly or really seek the opportunities. Options I hope you can do better than:  - Advanced security mindset  - Anti-adversarial mindset  - Co-adversarial mindset

Agreed.

Without spoilers:  I don't object that Force Awakens was a fanfic plot with fanfic tropes, but I object that they were stereotypical bad fanfic tropes. There are literally one thousand authors on fanfiction.net who can do better, if you're going to spend $100M filming a fanfic. I feel like my art is being disrespected somehow, by using those particular fanfiction tropes.

My response to the prompt, "Write a dystopian vision of the future from the perspective of the year 1900, while actually describing our present world today."

In a society where the real laws aren't the same as the pretend laws, and it's impossible to unilaterally obey the pretend laws without hurting yourself and others, but everyone is still claiming they're not pretending despite everyone knowing on some level that it's pretend, what do you do when you have to explicitly program robots about the speed limit? I don't know, but I bet the answer isn't "stop pretending" or "give up on robots", and I honestly don't know what other options there are.

During a conversation about how overcompensating for a cognitive bias is also an (experimentally studied) thing: "Extremes are easy. Moderation is hard." - said by Miranda, attributed to Ruby.

Morality. n. What you would want if you thought about it for longer.

Studies show that the more detailed knowledge you think you have of Dunning-Kruger, the more you actually know about it.

MIRI's 2015 Winter Fundraiser is on, and *today and tomorrow only* (Dec 9th and 10th) all donations made through the Raising for Effective Giving site only will be matched 1-for-1 (by professional poker player Feruell). Under "Pick a specific charity", select Machine Intelligence Research Institute to have this go through. For general background on this year's fundraiser, see: https://intelligence.org/.../.../01/miri-2015-winter-fundraiser/

Apparently some early Bitcoin adopter guy named Craig Steven Wright is trying to pose as Satoshi Nakamoto for some reason, and Gwern probably just sighed and handed it over with no comment to Wired. EDIT:  Gwern's Reddit account says he believes it. This surprises me.

Overheard at MIRI:  "I have to head home now, but I want you to continue analyzing whether this algorithm leads to the realization of any anime plots."  (Trying to figure out whether a proposed decision rule, if you ask a genie to paint all cars pink, and it can only paint half the cars pink, gives the genie an incentive to modify what you want.)

I seem to have written a Japanese-style light novel, tentatively titled:  "A Girl Corrupted by the Internet is the Summoned Hero?!"  Do I know any English readers and fluent Japanese writers who'd like to translate it into Japanese for publication there, and possible submission to the Dengeki contest?  Also, can any Japanese reader check the Dengeki website and tell me whether publishing the English version first (e.g. on Kindle) would render it uneligible for the Dengeki contest?  And does anyone have any other straightforward recommendations about what to do with a 19,000 word ebook written in the genre of "translated Japanese light novels", besides publishing it on Kindle Direct? PS:  Do I know anyone who'll give me a good price on a professional-looking anime-style cover, and maybe a few internal black-and-white illustrations?  Includes free advance read of the story. PPS:  I also have no experience going from a Scrivener doc to a Kindle publication, so a hand to hold there wouldn't hurt either.

Welp, I just got a brand-new amazing Skylake Dell XPS 13!  With the amazing new Thunderbolt 3 port!  That's so new and amazing, there apparently isn't a single cable for sale anywhere on Earth that connects it to a 4K@60Hz DisplayPort monitor!

It's cloudless and sunny in Berkeley, and the FedEx guy standing in my doorway looking in is shielding his eyes and saying, "It's too bright!"  #youknowyouhaveenoughlumenationwhen

With Thanksgiving behind us, we're closing in on International Vacuous Truth Day!  As with all other planets in this galaxy that support sapient life using the Gregorian calendar, Vacuous Truth Day is held every November 31st. On that day, every mathematician who wants to do so will spend the entire day trying to think of nothing except "X -> Y" conditionals that are valid because X is false, and generalizations "Every X is Y" that are true because there are no Xs. Ever since the first year whose digits summed to zero, every popular tradition dealing with International Vacuous Truth Day has agreed: Nobody who attends a major citywide Vacuous Truth Festival has ever failed to have fun!   It's a day where, as every scientist we interviewed has agreed, any person who tries hard enough can solve literally all of their problems!  Any person who knew a week in advance about International Vacuous Truth Day and fails to celebrate it will be stricken by a magical curse that, like every magical curse, can only be dispelled by eating a lollipop. It's also a day we take to celebrate the spirit of vacuously true companionship by vowing never to betray or let down Hans Derrick Swillinger of Terpigore, England. Join us - all of your friends are doing it!

This is what happens when your cunning plan has more than two steps.

A Yudkowskian milieu-oriented novel begins when the protagonist discovers a strange new world, and ends when they destroy it.

There are much more energy-efficient ways to swap the orbits of Earth and Venus than I would have expected to exist.

Want to avoid going down an awful lot of blind alleys in AI safety?  Here's a general heuristic: if you don't know how to accomplish a goal safely using one AI, don't imagine you can do it safely with 2 or more AIs. All you're doing is pumping weird intuitions out of your mental model of a ghost in the machine. If you actually understood the cognitive computations that output the right thing to do, you wouldn't have to imagine them distributed across multiple imaginary people. You'd just compute it.

You're searching for the source of that mysterious scream you heard in the woods. Your group refuses to split up.

Overheard at MIRI:  "Too much recursion is one thing!  Too much weirdness is one thing!  Too much weird recursion is another matter entirely!"

Is there any East Bay source besides IKEA for new cushioned recliners in the $300-$500 range? All furniture stores in Berkeley only sell $3000 recliners. Upholstery that isn't leather would also be nice. Craigslist is too labor-intensive for finding the right option.

Although there's more than one thing going on at a time and we haven't yet reached winter solstice, preliminary indications suggest that stringing up 100 60-watt equivalent LED bulbs (with high CRI, over several rooms, in a mix of 70% 5000K to 30% 2700K) is effective against Brienne's severe Seasonal Affective Disorder that resisted standard lightboxes. I say again that N=1 and that it's too early to be declaring results; but I thought that those of you with *really bad* S.A.D. might want to know the preliminary direction of evidence *right away*, though you're probably already too depressed to do anything about it this year.

People vote Democratic because they fear Republicans, not because they like Democratic candidates or policies, and vice versa.

This is one of my favorite short music videos that I've ever seen. Content warning, death.

I'm starting to have trouble reading Worm fanfiction about Panacea without my mental screaming drowning out the words. Her underuse of her powers is maybe the worst in that universe, short of Eidolon. It's like if Contessa was using her Path to Victory only to win at blackjack. Panacea is "total control over biology, including the ability to create new organisms with new complex abilities or immediately alter a virus to reverse its effects" being used to "heal physical injuries at a local hospital". There's a reason she's psychologically crippled in canon, the same reason Bonesaw and Siberian are in the Slaughterhouse Nine. If you have a non-crippled Panacea in your story, there is no story!  By the time your story starts she's already made a virus that cured cancer, and designed trees that would grow sushi in a desert from seawater, and altered some humans to live outdoors on Mars, and maybe built an intelligence-enhancing bacterium, and converted irredeemable capes into her loyal minions by touch brain control, and bribed others to participate in Endbringer battles by converting them into immortal youthful supermen... Characters in Worm whose powers suffice to easily take over the world:  Eidolon, Glaistig Ulaine, Panacea, Contessa, Bonesaw (instantly); and then Number Man, Dinah, Accord, Tattletale, Coil, Leet, Andrew Richter, Teacher, the Yang-ban... I've probably forgotten like half of them. I wonder if a prerequisite of a work generating an enormous quantity of fic is an enormous amount of untapped potential. Sigh. Maybe it's not a fair complaint. Out of the whole Forbes 400, nobody except Elon Musk makes any attempt to live up to the potential of their power, and nobody around them notices anything odd. It *should* be the bug-control girl that ends up as the hinge of destiny. You *should* have to go that far down the cape list to find one Munchkin.

Scott Alexander is rolling to disbelieve on an unusually important proposition, the DRACO project to defeat LITERALLY ALL VIRUSES via instructing cells to commit suicide on detecting the presence of double-stranded RNA. Have not yet seen any refutation. Previously funded by NIH, now allegedly in the "Valley of Death" where they can't get any funding(?!!) from either nonprofits or industry for their next stage of research, and hence are running an Indiegogo campaign (?!!). ...SENS is providing 501(c)(3) cover for it. Scott wants to know if he should donate. * https://www.indiegogo.com/.../dracos-may-be-effective-against... * https://www.reddit.com/.../i_am_drtodd_rider_i_hope_to_cure_.../ * http://journals.plos.org/plosone/article... * https://www.youtube.com/watch?v=TQhb1P3sMVs * http://slatestarcodex.com/2015/10/23/ot31-open-water/... EDIT:  Comments strongly argue against.

Me at the research retreat:  "I had a perfectly legitimate reason for graphing a decision problem with Paul Ekman, Omega, and an incoming asteroid!  Why are you making fun of me?"

The most common cause of death is running out of negentropy. Oh, you meant now and here?

Brienne is designing a new tabletop game!  Or a generator for novel plots!  Or both!

A coin has an unknown bias between heads and tails. If so far you've observed three black balls and one white ball, and you'll later get to make ten further observations about whether the ball goes left or right, what's the probability that you'll have enough information to decide correctly whether the coin is on or off?

Born2Skrode

This reminds me of how one of the primary benefits of modern liberal democracy, at least when it works, is its stability of succession (compare the Roman Empire). Basic coup theory says that coups have been completed successfully when a majority of people believe the coup will succeed and begin to defer to the new rulers. Thus, although I'm not sure how many people in the US actually still believe in the legitimacy conferred by the divine right of democracy, the fact that almost everyone believes that the military, courts, police, and populace would never obey someone carrying out a coup (because everyone believes that the military, courts, police, and populace believe in democratic rule much too strongly to follow a military commander or a President who refused to step down) makes the US effectively immune to coups of that type. Conversely, if we ever get to the point where there's widespread belief that parts of the government have stopped believing in democracy and might go along with a coup attempt if that attempt looked successful, a coup would become possible for the first time. The actual number of people who have theistic respect for democracy doesn't matter. I suspect it's a lot lower than it used to be 30 years ago. But so long as people go on believing that reporters believe this theistic belief to be widespread, they'll go on expecting reporters to crucify anyone who speaks openly against democracy, and the public discourse will continue to be unified in apparently supporting that narrative which would if widely believed imply that a coup in the US is impossible, thus making everyone believe that everyone else believes it, thus making everyone believe that a coup is impossible, thus making a coup impossible. I have no fear that speaking openly on this subject will ruin any countries that would otherwise be democratic, because mainstream journalists would never believe that their editors would believe that the average person can understand this many levels of recursion.

Suppose you own all seven original Harry Potter books. Is it legal for me to sell you a computer program that looks inside them to find terms like "Harry Potter" and "Professor McGonagall" and uses them to build a copy of "Harry Potter and the Methods of Rationality"?  Sure, HPMOR incorporates HP as a component, but if you buy the component and then buy the add-on then that shouldn't be a problem, right?

LOL @ panel 6.

Today is National Coming Out Day! I have nothing to declare.

Me:  Of course you think cuttlefish are cute. You think every form of life except humans is cute. Brienne:  That's not true. I don't think eels are cute. Me:  Eels?... Brienne:  Yes. Me:  What would it take to make eels cute?  Would they be cute if they were bright pink? Brienne:  No. Maybe if they had huge eyes... not too big, though. Sometimes I wonder about Brienne's original species before her mad scientist father transformed her into a human female.

Nate:  "You can lead a horse to water and you can put the water in its mouth and you can massage the horse's throat until it swallows -" Eliezer:  "But you can't stop the horse from throwing up." Nate:  "But you can't stop the horse from saying it's still thirsty." (On the difficulty of explaining the Orthogonality Thesis.)

The phenomenon of bullshit jobs is an overlooked central puzzle of modern economics. Parkinson's Law is not sufficient to explain it. I think the real answer is Baumol's Cost Disease, plus the difficulty of automating away bullshit. When manufacturing productivity rose, we saw a transition from manufacturing to service jobs, not just a massive increase of manufactured goods; in the larger economy, service is complementary to manufacturing, so increased manufacturing productivity also results in increased demand for services. Similarly, developed economies may see a general transition from "jobs whose productivity can be increased" to "jobs that can't be automated and also can't be eliminated". One reason a job can't be eliminated is if it's truly vital, but the other reason is if there's a coordination problem that prevents its elimination. We'd all be better off with fewer corporate lawyers, but this would require more than one change to enforce. Companies wish they could pay less to corporate lawyers, but they can't do that unilaterally, whereas they can unilaterally decide to spend less on secretaries. As productivity of some non-bullshit jobs increases, an increasing number of jobs will be those that are stuck in the system due to coordination problems that make them hard to automate. Or rent-seeking, or regulations, or unions or equivalent forces, or because you need someone to smarm the bankers at banks subsidized by FDIC insurance, or because agency problems make it hard to tell who's really doing their jobs, or because there's a 2-factor market in college credentialing and employers demanding the credential, etcetera. On the whole, the thesis is, "Many jobs are locked in place because they're very hard for one actor to get rid of or improve unilaterally, and many of those jobs are bullshit, so we're watching the economy shift out of agriculture, manufacturing, service, and finally into bullshit."

That took me a minute.

Somebody in the last few month posted a page from someone I know on how to do slightly better than index-funds - it had elements like overseas index funds and low-volatility index funds. Does anyone remember where this page / blog post was? EDIT:  http://www.bayesianinvestor.com/.../advice-for-buy-and-hold-.../

This is the best SCP ever. But not the first one you should read if you're not already familiar with SCP.

And there finally came a day when John Boehner realized he was having more fun as Donald Trump.

Is criminal law constructive or nonconstructive, in the mathematical sense?  Suppose, given other observations provable in court, I must have committed one of distinct crimes A or B, but the law can't prove whether it was A or B. Can I be convicted of deserving at least some penalty (the minimum penalty on A or B), or can the law only penalize me if it can prove that I was guilty of some particular crime?

Epistemic nihilism:  Everything has probability zero.

FAI Critical Failure #54:  The AI values people having true beliefs, but has a penalty term against psychologically manipulating humans. Thus, the AI begins changing the world to make more commonly held beliefs true.

I bet Leah that Pope Francis would not do as well for the Catholic Church as Pope Benedict. It's a bet I hope to lose. The reasoning behind my bet?  That God is hate. That in the modern world, the comparative advantage of religious institutions is in stoking fury over gay marriage, that many of the compassionate good people have already left the religion permanently, that those who remain are not really excited about what Pope Francis says when they can hear the same message from the New York Times. That religion does best when it plays the Trump card, for the same reason Trump plays it. I hope the record shows that Pope Francis was far better for the Church than Benedict, and that other religious leaders see this and imitate the strategy. I would gladly pay Leah $10 to see that.

Markov generator + audience voting >> Markov generator Also: Bitcoins Can Now Legally Marry

Happy Hermione Granger day, mateys!  Arrr!

Why can't we have journalism like this in the West?  It's like the reporter talked to the principals or maybe just used f*cking Google and tried to report on what was actually being done in some technical detail, and prioritized this over looking down at anyone.

You might be thinking outside the box if your (1972) chess problem requires inventing new notation to express the solution, and afterward the FIDE changes the rules of chess.

Um, one of the ingredients in these chocolate drinks really needs highlighting and an explanation for the unwary.

Did business-cycle depressions ever happen before the rise of goldsmith banking?  Trying to Google this subject led to a large number of anti-fractional-reserve axe-grinding pages, but I'm just looking for a straight historical answer.

Apparently this company has in fact been talking to AI safety people, including FLI and Nate and circulating the MIRI technical agenda internally. Please note the correction. That's actually kind of encouraging.

EDIT: Apparently Marek Rosa has been talking to AI safety people, so this is not the situation the press release made it sound like. Another day, another AGI company promising superhuman self-improving AI with no mention whatsoever of goal system design or anything resembling a critiqueable theory of beneficialness or even the faintest recognition that this is a problem, getting more funding than MIRI has had over its whole existence. I'm sure no malice is involved, either, just, this is our civilization's normal and default level of performance on the Friendly AI problem. This is not anything new and this specific company is nothing to worry about, but it's the baseline of this world and very far short of adequacy. No, worlds like this one do not go well by default.

Another fascinating conversation.

If I had to level a single criticism at this incredible fan reinterpretation of "The Lord of the Rings", I would say the main problem is that it raises too many questions without answering them. I'm not talking about the film's central question, "Where are they taking the hobbits?"  To actually answer this question, even with a hint of overheard conversation between Legolas and Gimli where they ponder the different possibilities, would destroy the postmodern genius of the whole production. Instead, I refer to the multitude of event and character questions raised in passing throughout the movie, whose unceremonious abandonment seems much less forgivable: - Does Celeborn still want to talk to Gandalf?  Does he even care where Gandalf is? - What was that giant flamey creature?  Was it associated with any earlier mythological evils? In a 10-hour movie, there really ought to be room to answer questions like these. In fact, the main change I'd suggest would be to insert some sort of 2-minute flashback sequence at the very end, where we see, for example, Celeborn quietly discussing Mithrandir's absence with Galadriel, or a scene where Aragorn finds some old book describing the giant flamey creature. This would help wrap things up and make the whole movie much more satisfying. The most unforgivable omission concerns one of the central themes of the movie, Gollum/Smeagol's growing deafness, symbolizing the pseudo-hobbit's increasing withdrawal from the company and society of others. We're primed throughout the whole movie to expect a heartbreaking moment where this increasing deafness is revealed to others for the first time, but this moment never comes. But these are only minor blemishes on an otherwise genius work: the originality, the freshness that keeps surprising you with twist after twist for 600 minutes, these are worth overlooking an unanswered question or two.

An unusually clear example of how when laws unintendedly create large financial incentives, the large financial incentives trump literally everything.

Request: Trusted Berkeley dentist. Brienne got told that she needs a lot of dental work, and after some other ambigious alarm signals about that dentist, I think I need to take her somewhere for a second opinion. In-network for Blue Shield would be nice, but since MIRI is shortly moving away from Blue Shield dental and needs to pick out new coverage anyway, I'll take any recommendation for a competent dentist (the fillings they do don't need redoing, they don't seem to ensnarl you in insurance tangles, etc) in the greater Berkeley area who's accepting new patients. It'd be nice if MIRI could just tell all its employees "Go to this dentist here."

This goes beyond news stories, beyond outrage stories, and into the realm of visceral horror. Brienne, you're not allowed to read this at night.

Update because previous share was wrong. I guess I should have noticed confusion harder. Everyone who explained the false data loses Bayes points.

In retrospect, one of the literary problems I ran into with Harry Potter and the Methods of Rationality is that there was no clear signal until the final chapter of what the story was about. [HIGHLY META SPOILERS AHEAD.] HPMOR, as the title implies, is about Harry's journey as a rationalist. It starts when Harry encounters a huge problem and opportunity regarding his previous view of sanity and the world.... It develops as Harry tries to apply his art, succeeding and failing and learning along the way. It ends when Harry's belief in his own capability has been broken, and he first perceives the higher standard which he must meet. A lot of people thought that HPMOR was about uncovering the laws of magic, or poking fun at J. K. Rowling (NOT THE INTENT *AT ALL*). And it's hard to blame them, because I didn't even try to solve the problem of making the real plot become an expectation and knowledge of the reader. It actually still seems to me like a *bad* literarily-damaging thing to announce that central theme up front, which is why I'm only saying this now that the story is over. I think the technique I was missing is that if the great central arc of a story is not obvious until the end, it needs a good decoy central arc, and a clear sense of an overarching progress bar toward the decoy arc which the reader can feel incrementing in a satisfying fashion.

Eleven hours left. We hit the second goal and are unlikely to hit the third, but rest assured that the expected utility of donations doesn't actually come solely from sharp spikes around the threshold levels, and isn't otherwise flat. It *is* still true that donating now, or pledging now, is significantly more valuable than donating or pledging one month later, because we'll be doing strategic planning based on how well the Summer Fundraiser did, and known quantities are easier to plan around.

Good Ventures did a Munchkiny thing!  I'm impressed. This is what a real fight on poverty at the real critical point looks like. It's only US poverty, but even so not a bad place to start.

How the hell did their business survive this long?  I was expecting it to be bad but not that bad (20M male to 10K female).

There should be a name for the selection effect where most of a subject's discourse is written by people who think that subject contains an academic career's worth of open questions. Theology is written by people who think there are unsettled discussions in theology. The "interpretation" of quantum mechanics consists of mostly people who think that's a real question, a few people going "shut up and calculate" and a few people saying "well obviously MWI". The SEP article on ...Arthur Schopenhauer contains the largest collection of sentences with no truth condition that I've skimmed in recent memory. It was presumably written by the sort of person who makes a whole career out of studying Schopenhauer - meaning that it was written by someone who thinks it's okay to reason like Schopenhauer did, rather than by someone who was trying to extract out the few parts that were novel or important.

In nonfiction writing, your first priority is not to make the reader agree with you but to have the reader understand what the hell you're talking about. Persuasion comes after identification. This means that in your opening paragraphs, your goal should not be to persuade but to inform - to rapidly orient - to convey as plainly and quickly as possible, without any attempt at persuasion, what the hell you're talking about.

Lots of interesting stuff here, though nothing I found shocking. Lots of superforecasters are programmers, it turns out, presumably for the same reason lots of programmers are correct contrarians of any other stripe. (My hypothesis is a mix of a lawful thinking gear, real intellectual difficulty of daily practice, and the fact that the practice of debugging is the only profession that has a fast loop for hypothesis formulation, testing, and admission of error. Programming is vastly more scientific than academic science.)

From the Department of Inconvenient Truths, it looks to me like it's completely plausible that building more housing units in Berkeley could raise housing prices in Berkeley. I originally wrote this as a joke post on Carl's wall:  "Look at how expensive Manhattan is with all those enormous buildings; if we build enormous buildings in San Francisco won't it just get even more expensive?"  I now think this joke may be valid reasoning. People want to live next to other people; ...think of all the people who followed MIRI and CFAR to the San Francisco Bay Area. When you build new housing, new cool people move there and make all the surrounding housing more attractive, hence more expensive. There's also another effect where the new housing competes for demand with surrounding housing, but there's no rule that the second effect has to outweigh the first effect. This is more or less why real estate in San Francisco or Manhattan got as valuable as it did in the first place, so why wouldn't that trend continue? On the scale of the entire planet, I expect that the more housing is built, the cheaper housing will be. But when more housing is built in Berkeley in particular, it doesn't much decrease demand in the whole Bay Area, but it does increase the number of cool people you can live next to if you move to Berkeley rather than Fremont or whatever. So to me it seems perfectly reasonable that when somebody in Berkeley is like, "No, no, don't build more apartment buildings in Berkeley, that won't decrease housing prices in Berkeley" then as much as we might want to yell at them about supply and demand, they could be right. They're NIMBYing, so they're selfish, but they're not making a false statement. The same logic applies to how building more housing units in the whole Bay Area might only increase its attraction relative to New York or London. There ought to be a name for this like there's a name for "Giffen good" but if so I don't know what it is. Of course my original joke statement about bigger skyscrapers causing higher property prices was in the context of somebody saying, "This policy is based on the weird belief that if only we built an infinite number of housing units prices would come down" and, yes, if we built *enough* housing in Berkeley prices would come down. In the limiting extreme we might have to build enough housing to hold 7 billion people plus a bunch of vacant units left over, but if we built *enough* housing, prices would come down.

Everyone just please stop violating the Efficient Markets Hypothesis (weak form). Just... stop. You don't know whether stocks are going to go up or down in the next minute, month, or year. You don't know that about bonds, tech stocks, or Berkshire Hathaway. It's exactly as good a time to buy or sell as it would be on any other minute on any other day of the year. Everything you know or imagine is already priced into every liquidly traded financial asset. This is also true of every pundit and blogger you will read today. Sometimes there are twenty dollar bills lying on the street. There are no billion dollar bills lying on the floor of Grand Central Station while other people point and comment on them.

I need a highly specialized writing book entitled _Plot As You Go:  The experienced writer's guide to writing satisfying prose when you're not sure what's going to happen next, as opposed to your current habit of foreshadowing stuff that happens fifty chapters later_.

Reminder:  While I'm sure _some_ users on Ashley Madison betrayed faithful spouses who thought their marriage was a sacred contract, it won't have been that way in all cases or even a supermajority of cases. I'm not just talking about explicitly recognized open marriages. In many kinds of "monogamous" marriage there are socially obligatory lies, expected and demanded by the listener, among people mostly driven by conventions who would be very unlikely to sit down and work out an exotic and unusual way to be honest with each other. So everyone in the Ashley Madison datadump remains innocent of actual ethical violations until proven guilty. Yes, contracts are sacred to me, but a contract requires contractual capacity. Children are not committing betrayals when they lie to parents who hold all the cards and power, they are acting as their parents force them to act. If a police officer asks 'Do you know what speed you were going?' and you answer 'No' then you are hardly deceiving them or betraying the innocent trust that they held in you; you are responding to a governing system that has chosen to impose punishments for being naive enough and socially unskilled enough to tell the truth in a place where honesty and trust doesn't enter into it. I don't really understand what a relationship looks like when there's all these things that people tacitly know and aren't supposed to admit, or when A knows B knows X but A doesn't know that B knows that A knows that B knows X. But I know that a whole lot of marriages were never built on innocent trust and sacred bargains to begin with... and that this is a normal state of affairs for human beings. In particular, please don't go gloating over $EnemyX being revealed to have an Ashley Madison account, on pain of my rolling my eyes pretty hard especially when you start sanctimonizing about how very, very wrong cheating is in general. Now if open relationships were openly considered normal and total sexual monogamy was a special commitment that had to be renewed every 3 years for a $100 fee, then the people signed up for Ashley Madison would indeed be much more evil on average. And there wouldn't be 28 million of them. A law that half the population disobeys isn't a law, it's a pretense hiding the real rules, and this is as true for marriage as marijuana.

Gwern has made an attempt to further track down the statistics. It's not 40% of the population that's immune to exercise, more like 20%-5% (which may match my real-world experience a bit better as well). From Gwern's comment: * The final paragraph about the 51/72 genes seems to be sourced from "Endurance training-induced changes in insulin sensitivity and gene expression", which was published around 2004, consistent with the NS date. The general stuff about responses to exe...

Why most of your friends have more friends than you do.

Scott Aaronson explains Aumann Agreement at SPARC!

The more material implications there are in a statement, the more likely it is to be true.

Question for Robin Hanson: What would Effective Altruism look like if, instead of being a youth movement, everyone in it was efficiently pursuing the pure good of humanity?

If Brienne and I were vaguely demonic creatures of darkness, this is how our relationship would look: (A male figure shrouded almost entirely in a cloak and the night's darkness, and a female figure dressed in black leather stand atop a small hill outside a village of thatched huts, gazing down at the dark silhouettes.) Male:  Those fools have no conception of the fate that awaits them. This night will see the advancement of the next stage of... is this boring you, my dear?... Female:  No, Master. Male:  You looked a little bored. Female:  It's more like, I forgot to eat before we left and your words are not made of food. Male:  Oh. Do you want to stop and eat someone? Female:  No, Master. Male:  We don't have to attack the whole village right away. We could just sneak into one of the outer huts. Female:  I'll be fine, Master. Male:  You still sound a bit disturbed. Female:  Yes, I am a bit disturbed. Let me think about why... (The two of them stare out at the village for a few minutes.) Female:  I think it's because I don't like using fire. Male:  Why not? Female:  Because there might be a puppy in one of the huts and then the puppy would be on fire. Male:  I am still bemused that you manage to feel compassion for puppies and not, say, human babies. Female:  Babies are scary. I don't even want to *eat* babies. Male:  It's going to take a lot longer to slaughter all the villagers if we don't use fire. Female:  I know that, Master. I didn't say we shouldn't use fire. Male:  I didn't say you said that we shouldn't use fire. Female:  (sighs) Male:  Well, you know the old saying - Female:  Master. Male:  "If at first you don't succeed, use fire!" Female:  Master, please no. Male:  "Look before you burn!  Fortune favors people who are on fire!" Female:  Master, we should attack the village soon if we want to be done with this tonight and so that I can go ahead and eat someone. Male:  I say again that it is perfectly okay if you want to eat someone first. Female:  No, Master, let's just go.

Shikako Nara from "Dreaming of Sunshine", the Orange Lantern from "With This Ring", and Lord English (I think that's what happens if you're currently listening to the Carne Vale Re-extended Remix from Homestuck). You're going to need something a hell of a lot more threatening than a zombie apocalypse to keep us busy.

It's currently looking like caffeine does work on me after all, or at least I had a couple of cups of coffee around 1:30pm, felt high-energy and jittery, and then had that wear off around 5:30pm-ish, after which I looked it up and found that caffeine is indeed supposed to last around 4 hours. I wonder if this is due to a metabolic change in the meanwhile or if caffeine always did have an effect on me and I didn't notice. (It did definitely have at least the power to make my heart race if I took coffee with a triple shot, though I didn't notice a mental change at that time.)  Neurons, go figure. (Needless to say I will be reserving this capability for the most extremely vital moments, having witnessed caffeine dependency in several friends and knowing it to *not be pretty*.)

I think that if I was a global poverty EA, I'd be reviewing the case history of this and maybe calling up the scientists, trying to figure out if there was any way the path to the vaccine could have effectively been shortened by a $500,000 boost at the right time.

Reason #38 I should never be a parent:  I can just see myself now, explaining to my young daughter (once she's barely old enough to understand) that since we can never go back in time and fix anything, she only has one chance to live her life perfectly and if she blows it then that's it. And then, the first time after that she makes a mistake, throwing her a "You Blew It" party and saying there's no point trying to be perfect anymore. That should work, right?

A large set of Ideological Turing Test entries on astronomical stakes or animal altruism, all entries produced in 3 minutes. If you submit your own, please write for at most 3 minutes as well. My immense thanks to Alex Meiburg for creating this system!

Every now and then I am abruptly reminded that Atlas Shrugged was written in a time when Atlas Shrugged-like events were totally a thing and furthermore they are still totally a thing.

It would be nice to have better software support for Ideological Turing Tests - I'm considering trying to run one quickly during my 5-minute opening statement on my panel at EA Global. I don't suppose this is a sufficiently simple task that someone can whip one up by noon tomorrow? Bare-bones requirement: 1. A web form (that works okay in mobile and desktop) where people submit their email address, their essay, and whether or not the essay represents their actual view.... 2. A webpage (okay in mobile and desktop) that shows successive entries in random order, lets you vote whether the entry was someone's real view, and then shows you whether or not that entry really was someone's real view, and the previous numbers of votes in both directions. (This is all I want for tomorrow.) Ideal ITT system: 0. A web form where ITT creators go to create new ITTs. 1. A web form where people submit their essay, and whether or not the essay represents their actual view. If the submitter doesn't want to use an email address, gives the submitter a cookie to identify them on future visits. 2. A webpage (okay in mobile and desktop) that shows successive entries, lets you assign a probability from 10-90 whether the entry was someone's real view, and then shows you whether or not the entry was someone's real view, and the average probability that others assigned to the entry being someone's real view. 3. When you are done with ratings, you are told how well you did compared to population average. Your score is the joint probability you assigned to all entries, i.e., the product of the probability you assigned to the true answer in all cases. You are told what percentage of submitters got a lower score than you.  4. When a submitter returns, they are told how effective their submission was at fooling both the average rater (measured by average probability assigned), and the top quintile of raters (measured by average probability assigned in this subgroup).

So I've now ordered an edited volume on Seasonal Affective Disorder and *still* so far as I can tell, nobody has ever tested any light with more than 10,000 lux, or treatment via sufficiently bright home lighting instead of measured doses from lightboxes. Like literally magical-Britain-style "Durr, nobody's ever thought of that." All the numbers go up to 10,000 lux and then stop abruptly. No data on anything beyond that. (Sunlight is 30,000 lux.)  No trials of bright whole-...house lighting instead of lightboxes. We have a world in which up to 15% of people in higher latitudes have sub-major-depression SAD, and some people have life-destroying SAD, and 50% of SAD can be fixed by lightboxes, and literally nobody seems to have ever tested whether the other resistant 50% can be fixed by using, oh, I don't know, MORE LIGHT. I do not want to hear any more complaints about the vastly smaller country of magical Britain not testing far less obvious ideas, or Harry being depicted as being first to think of them, unless the speaker wants to show me the research on more powerful home lighting as a treatment for resistant SAD.

I roll to disbelieve. If you can get along just as well with 5% as much brain mass and presumably energy consumption, the body should not use that much energy and our large heads should not be causing childbirth problems.

FYI, so far as I know this is basically the econoliterate view of recent history (predicting the future being far more difficult, naturally). The potential for a paperclip maximizer to eat galaxies is not bound to any particular view of the macro effects of non-AGI robotics.

An unusual glance at how things are usually done.

Well laid out, if not, of course, resolved.

...it's been a while, but I can still parse all the Cthulhulian horrors.

I recently learned that Galileo, back before the whole 'moons of Jupiter' business, made a bit of change for himself by selling local merchants telescopes that, he showed them, they could use to see ahead of other merchants when a ship was coming into harbor, read out which ship it was, look up the cargo, and arbitrage upcoming price changes. I exclaimed out loud, "Galileo was a Munchkin!"

I recently asked Brienne what she would do if she became Queen and wasn't allowed to ask anyone else for advice. She seemed pretty unsure, but eventually came to these three definite conclusions, in order: 1. She would wear sparkly dresses. 2. She would have a sushi chef.... 3. She would remove all the education laws and turn the industry into a free-for-all.

"The market can stay irrational longer than you can stay solvent." -- Keynes What would be a good financial instrument that doesn't have unlimited downside and would, if well-traded, prevent bubbles from inflating?  Let's say I think Chinese stocks are in a bubble. If I short or naked-short Chinese stocks, and I'm wrong about the bubble, I could lose double or more what I gained. Or imagine a more liquid market for startup equity: if I think NetBet (or Color Labs) is overpriced and I try to short the stock, or sell buy options on the stock, then I stand to lose an unlimited amount if I'm wrong and NetBet is the next Facebook. Furthermore, if Chinese stocks double before they crater, a margin call stands to cause me to lose all my investment and then some, even if I'm right (hypothetically) on a five-year timescale. My question is: what should a good anti-bubble financial instrument look like?  Not a naked short, not a buy option, and not anything that forces a margin call in the first five years. The best I can think of so far is a ticket that pays $10 if the allegedly frothy market is at or above its current level in 5 years. The price of this ticket would reflect a probability estimate of the bubble popping, selling that ticket would short the market, and buying that ticket would compete with actual equities in the total market of people who want to take the bull side of the market. But I'd hope it would be possible to have this financial instrument lower the froth of the market a bit more directly - like, let somebody pay $1 less for the stock today, in exchange for... losing another $10 if the stock does crater?  Not sure that would be a very attractive proposition, but it would be nice to have the bubble-popper actually affect the equity markets a bit more tightly than by just competing for bullish dollars. And yes, I'm aware that under the modern Silly System, this financial instrument would be illegal unless dressed up in very elaborate ways. I just wonder sometimes about what a real financial system would look like.

MIRI is now attempting a big push to grow to match the increasing level of interest, hire the people who've been talking to us and realize the potential for increased pace now that Elon Musk, Stephen Hawking and Stuart Russell are openly speaking in favor of the mission. But that only happens if that increased interest translates into increased funding.

Cheerful news!  Not as cheerful as the Google-Facebook AI arms race was terrible news, but still pretty good.

This is what fnording looks like. Also, apparently nobody should ever read Salon or Alternet.

This is maybe the primary bar that I have to feeling empathy on many day-to-day occasions. My fear is that everything I'm seeing is just a performance; which causes me to constantly question the hypotheses I have about people, and question the relation of observation to theory. Not ordinarily a bad thing, but my brain seems to have trouble sympathizing, feeling strongly, when I'm uncertain or merely assigning probabilities about whether the person I think I see is real. (Maybe that's why so many EAs can't xrisk.)

So I just went to a Fry's and tried every keyboard there, and by *far* the best keyboards, keyboards that made it a joy to type, were on two Alienware laptops, both of them far too heavy for me to carry anywhere. Is there *any* specialized keyboard I can buy that is the equal of an Alienware laptop keyboard?  Like, a USB or Bluetooth keyboard which has the same sheer joy-of-typing experience?  Better yet would be an Alienware-level keyboard on any laptop weighing in the range of 2.6lb or less, regardless of size. EDIT:  What I want is not 'clicky' or 'mechanical' (I have no idea why this is even a thing), it is the easy, springy feeling of the Alienware laptop, like typing on a low-resistance trampoline; combined with ease of fingers traveling across a smooth keyboard surface.

How Brienne's father found out about our marriage:  Brienne gave him a copy of HPMOR (1-17) that was autographed by me with the inscription "Thanks for your daughter!" How my own parents found out:  I sent them an email reading, "FYI: I'm about to announce on Facebook that Brienne and I were secretly married in December 2013." My father's reply, sent within minutes:  "If it's a secret, how do you two know about it?"

This is an *important* image. Since we saw this image, my friends and I have found many occasions to utter the last line to one another.

Everyone, there is nothing special about Google's Deep Dreams neural network. It's been well-known for years that almost any machine learning algorithm, given enough computing power, starts producing pictures of shoggoths. Auditory algorithms start to produce a high pitched piping noise that converges toward "Tekeli-li!  Tekeli-li!" And so on.

There should be a name for the fallacy of "behaving like a sane person would if other people were sane" (when in fact they're not sane, which means you're not behaving sanely either). Any suggestions?

Other people get married and their friends are like "Congratulations!"  I get married and some of my friends are like "Congratulations!" and the ones who've been reading /r/hpmor for way too long are like "DO YOU THINK HE'S TRYING TO TRICK US?!?" Am I tricky?  Yes. Do I outright lie?  No. I sometimes deliver deadpan false statements, but these are meant to be so blatantly false that nobody could possibly believe them, along the lines of, "Actually, the recent Moon landing determined that the Moon is in fact made of green cheese."  Occasionally some statements in this class are in fact true, like "Actually, what happened to Harry's pet rock is the most important remaining unsolved mystery in HPMOR", but I don't do the reverse thing where a seemingly plausible statement, delivered as truth, turns out to be *false*. If my Facebook status says I'm married, I'm married.

Sayeth Brienne: * Cognitive Trigger-Action Planning For Epistemic Rationality I suspect that the overwhelming majority of good epistemic practice is best thought of as cognitive trigger-action plans to customize and internalize.... [If I'm afraid of a proposition] > [then I'll visualize how the world would be and what I would actually do if the proposition were true.] [If everything seems to hang on a particular word] > [then I'll taboo that word and its synonyms.] [If I flinch away from a thought at the edge of peripheral awareness] > [then I'll focus my attention directly on that thought.] Before looking back through some of the Lesswrong Sequences, I installed the trigger-action plan "[If I notice that something I read feels important] --> [then I'll ask myself, "In what real-life situations is it important?" and design a trigger-action plan to impliment the insight.]" Sometimes I fail to identify a correct action, but I at least come up with some hypothesis for what the right trigger would be, so I can study my own experience of relevant situations. (When I train a trigger well, I often find I'm done, anyway.) You can gain a lot of abstract insights by reading, which can re-orient your mind and shift your whole approach to the world. You can learn some great hacks for problem solving by taking the right classes and workshops. But when it comes to advancing your own art in the ongoing context of daily life, CTAPs is the name of the game. It is the way to change your default responses to sensations of thought and emotion. [If something feels key to advancing your art as a rationalist] > [stop, drop, and trigger-action plan.]

What is your probability estimate that Brienne and I are currently married?

Elizabeth:  Why do I feel like there's buried treasure under the gazebo? Brent:  The gazebo is the obvious Schelling point for burying treasure. Brienne:  THAT IS EXACTLY NOT HOW TO USE THE CONCEPT OF A SCHELLING POINT.

Do I know anyone with a 2015 model Dell XPS 13 laptop, so that I can come over and briefly try it out?  I'm considering buying one, but can't find any store where I can try one! Anyone in, or within 75 miles of the Bay Area?

If you replace every word in a thesaurus with a close synonym, the result is another thesaurus. Philosophers call this the Thesaurus of Theseus.

Inside Out is the most rationalist movie ever. I can't even think of what would be the #2 runner-up. (Comments may contain spoilers.)

Test your econoliteracy!  What do real estate agents, medical residency students, and itinerant postdocs have in common? (That they don't have in common with CS students or janitors, you bunch of smart alecs.)

Well said. Not totally rigorous metaethics, but basically correct.

Just sayin', the State still doesn't recognize half of what we actually get up to around here. Frankly, the way I feel about this SCOTUS decision is something like I imagine Britain feeling about a country that came in on the Allies' side of WW2 in 1944. Good for you, Supreme Court Justices. What courage that must have taken, to take a stand like that in 2015. Here, have a small cookie while you listen to the slow, hollow claps of my applause.

Clomid as a treatment for low male testosterone, particularly as part of a chronic-fatigue-syndrome type complex: do my friends know anything about this?  I'm considering trying it for 6 months.

I'm not ordinarily one to advocate mob justice, but...

Not my best work, maybe kinda obvious, but posted anyway for those who want to read my sub-best work. /r/WritingPrompts, "Every world ending scenario imaginable happens at the same time - somehow they cancel each other out." http://www.reddit.com/.../wp_every_world_ending_scena.../csfihgu

What is the dumbest overlooked medical intervention?  I know that central line infections, which kill on the order of 60,000 people annually and cost on the order of $50,000 each for 200,000 non-fatal cases, can be driven down by either 50% or nearly 100% (depending on which research you believe) using a five-item checklist. I don't know what's on the checklist, how much it costs per inserted central line, or how many central lines are inserted annually. I want to say something like, "The US medical system is inadequate in 60,000 lives saved for $1000 each" but I would like to have exact numbers, and if there's any even huger inadequacies that are equally well-documented, those would be even better.

The arguments I'm reading against Amazon's newest program, to pay authors per page read, are DERANGED. People are going, "Oh, but that will disincentivize authors from writing literarily valuable long books" when supposing a diminished payment implies that the extra pages WERE NOT BEING READ ANYWAY.

Overheard at Sarandrew's wedding:  "Moral realism: the theory that all moral worlds exist."

_Effective Cinderella, or, the Last Disney Princess_ The fairy godmother glowed and sparkled like the sun seen through three dozen layers of faceted glass, lighting up the grass beneath her feet and the nearby tree like a church floor lit by a stained glass window. Not even those bright flowing colors could illuminate the dull grey rags worn by the scrubbing-girl, or the streaks of ash covering her skin, but the light blazed in the scrubbing-girl's eyes. Hope was in them, for...

Yikes. Until and unless someone debunks this, asparagus is permanently off my menu. Seriously, yikes. EDIT: Commenters skeptical, say adult neurotoxicity of DMSO not well-confirmed. EDIT 2:  Counting James Wu's reply as a refute.

Arthur Breitman: "You can send data to yourself 10 years ago. Past you will know it comes from future you, but you can only send 8 bits. What do you send?"

Why is there no US health insurance that flies people around to geoarbitrage expensive treatments?  Is it illegal? Unattractive to consumers?  Unhelpful for more than a small percent of total cost?  You'd think this would be a low-hanging fruit. #civilizational_inadequacy

There's a certain dangerous practice of purporting to explain away the psychology of why someone else is committing a purported error - like, "You think you believe in God, but actually you just believe that belief in God is virtuous, which isn't the same thing at all as believing in something" or "People believe in MWI just because they think it sounds cool and science-fictiony."  If you just do the psychoanalysis without first analyzing the object-level propositions qua propositions for their truth or falsity, this is the fallacy of Bulverism. If the psychological statements have little relevance for the truth of the proposition, this is the fallacy ad hominem. I need a taggable name for the entire practice of analyzing a psychology that purportedly accounts for why people support a proposition without that proposition being true. This tag would be applied to both the valid and invalid instances of the practice (it would tag both the God and MWI examples above). My current placeholder is "psychoanalysis" but that word already means something else. It would be nice to have a similar term that didn't have the same level of existing meaning as "psychoanalysis", and ideally a term that sounds dangerous and questionable *without* sounding like something you should never ever do. Then I could say briefly, "There are times when it makes sense to X, but if you X at the start of your argument, that's Bulverism." What's a better name to tag this kind of analysis than "psychoanalysis"? EDIT:  This is not in general a fallacy!  Analyzing why the human mind tends to feel a sense of free will is part of the work of reductionism. Analyzing why people are often mistaken about the effect of legislating prices is part of the argument for economically literate policies. But it's still a dangerous sort of activity that can easily turn poisonous and dismissive. I want a name for the whole activity that suggests its danger, without forbidding it entirely. #terminology

!!!  I'm trying to remember any other time I've ever seen any state or federal government try something that, you know, anyone who'd read an economics textbook would think was the obvious way to try it, *including all the fiddly details*, and I'm kinda drawing a blank. (I mean, I'm not sure I expect anything to happen, since we already know from numerous studies that 'education' isn't actually used in the workplace and that income effects are from credentialing or selection. ... If somebody does try to take this opportunity to offer a new effective form of education, I don't see parents actually buying it since the creators will not be able to solve the marketing problem of explaining why their new kind of education is effective, and solve it better than all other educational novelties being optimized for easy marketing. But this is a very strong experiment when it comes to testing whether there is any possible form of effective education that is also the most marketable idea to at least some concerned parents, and its failure will be decisive evidence that we should just give up.) Kudos to whatever political genius pushed through this spectacular feat of mainstream economic approach. I honestly can't imagine how they did it.

My reply to the writing prompt:  "In a world where having multiple personalities is the norm, the protagonist has been diagnosed with Single Personality Disorder." * "So it's like... only wanting one thing?" the women sitting across the table from me said slowly. "Like, only doing one thing with your whole life?  That sounds horrifying."  Her expression changed. "And intriguing," another one of her said slyly. I've always had trouble memorizing names. Maybe I could do it i...

There's this category of email I get now and then that I don't know how to answer, and for which I can hardly disclaim responsibility. It goes like this: "Dear Eliezer Yudkowsky:  I read HPMOR / the Sequences / both, I got to Ch. 23 / the section about belief-and-belief, and I realized that all my religious beliefs weren't real. I am already married to a religious spouse and we have children. I used to be happy in my strongly religious community, but I also strongly believe in truth and rationality. I can't deceive myself and I don't want to live a lie. Now what do I do?  Help!" Now what do I do?  Help!

This is one of the most extraordinary feats in the visual display of quantitative information that I have been privileged to witness.

Alleged, with _Science_ paper: Every virus you've ever been exposed to and developed antibodies for, for $25. I wonder how some part of the U.S. medical System will prevent this from being accessible to most people in the next decade, and whether any other countries will have it instead.

Russell-Moore Paradox:  "This sentence is false, but I believe that it's true."

Does anyone want to try out a spare Lesser LUMENATOR for a week?  12,800 lumens / 180 watts with mostly CFL, or 8000lm / 120W LED. You will need a sturdy floor lamp with an upright standard light socket, you pick up and return.

I wish I'd tried to predict the ending. Seems predictable in retrospect.

I'm a little worried about the level of political despair implied by the fact that my FB dash appears to be debating primarily Cthulhu vs. the Sweet Meteor of Death in the 2016 U.S. presidential election.

Mainstream journalism and their integrity, folks.

Does anyone have a spare bedroom I can use for 2 nights, Jun 19 and 20, somewhere within public transport reach of Princeton, NJ?  I'm going to be officiating a wedding in Princeton on the 20th, and my plan is to fly in the day before and fly out the day after.

Suppose every charity in the world spent at least 5% of its revenues on impact certificates or impact prizes (just giving money to people who'd already accomplished good things, not yet personally financially rewarded, in the charity's target sphere). It seems to me that this obviously(?) makes the world a better place relative to the current equilibrium where we have huge amounts of philanthropic funding for alleged prospective good deeds, and very little personal reward for actual good deeds unless that person also played the social game well and got prospectively funded. It also seems to me that as incrementally more charities adopt the 5% rule, the world would get incrementally better along that charity's target dimension, so that this is a good cause-neutral norm to crusade for among effective altruists. It seems to me, even, that there's something very *odd* about all funding being prospective and so little of it being retrospective, with the exception of rare annual prizes that often go to people who've already been rewarded or prospectively funded. Like, it seems like it ought to be the subject of a Robin Hanson post saying, "X isn't about Y" for some X and Y. Would anyone care to talk me out of this suspicion, especially if they have a deeper acquaintance than I with the workings of more mundane philanthropy?  Carl, Robin, Holden?

> When Elon Musk was a child living in Pretoria, South Africa, he was viciously bullied as a student. His classmates pushed him down a concrete stairwell. In one instance, he was beaten so badly that he needed to go to the hospital. Here's Musk recounting that horrific experience:  "They got my best [expletive] friend to lure me out of hiding so they could beat me up. And that [expletive] hurt. For some reason they decided that I was it, and they were going to go after me nonstop. That's what made growing up difficult. For a number of years there was no respite. You get chased around by gangs at school who tried to beat the [expletive] out of me, and then I'd come home, and it would just be awful there as well."  * ...is anyone else getting "Taylor Hebert triggered as a tinker" vibes here?

Betting can heal the soul and bring people closer together by reducing the appearance of partisan divides. That's why we do it, as a people.

Dear journalists:  Please stop using pictures of the Terminator in your articles about AI risk. The sort of AIs the smart people are worried about are waaaay scarier than that. Maybe consult an astronomer to extrapolate a picture of what the Milky Way would look like with a spherical 5,000-light-year hole eaten out of it, centered on where Earth used to be.

"What matters isn't who's in control," I said, "what matters is the incentives."

We need more records of people learning things. I wish I'd left better records even just for my future self, who now has trouble remembering what he learned when.

Stuart Russell (public talk):  "It doesn't matter what I say. I could issue a blank sheet of paper as a press release and journalists would put a picture of the Terminator on it."

Things that only happen at decision theory conferences... "Oh," said the stranger, "I just read a quote by you - I was surprised, I just got to chapter 2 of this book I was about to give up on, and then I saw you quoted." Me, surprised, thinking 'how nice':  "What book?"... Him:  "A book on polyamory." (Beat.) Me:  "I did not know I was quoted in a book on polyamory. Which one?" Him:  "I think it's called 'More Than Two'." Me:  "I've never heard of it."  (With some trepidation)  "What was the quote?" Him:  "It was something about how, you have to become more moral than -" Me, feeling a mixture of relief and chagrin:  'You are personally responsible for becoming more ethical than the society you grew up in.' Him:  "That was it!" Me:  "That is a MISQUOTE which is ALL OVER THE INTERNET. I haven't tried to do much about it, because I still agree with the basic message so long as people take it as an admonition about how we should think internally, rather than as a criticism of others. But the *original* is Harry saying to Hermione that 'Nobody ever *told* Draco it was his personal responsibility to become more ethical than the society he grew up in,' and then Draco did better anyway, so give him some credit for how far he's come. Like, the original is telling you to keep in mind people's starting point and give them credit when they improve beyond that." Him:  (laughs) Me:  "The thing is, I actually do endorse polyamory. I mean, not in the sense of thinking everyone should do it, but in the sense of thinking it should be an option. I think there are some people who tend to do better in monogamous relationships, some people who are naturally polyamorous, and some people who can go either way. But I bet the avenue by which the quote ended up in the book had nothing to do with that." Him:  "I see!  The misquote applies to your real beliefs, but that didn't happen by any reliable pathway. So I had justified true belief that you endorsed polyamory, but not knowledge!" Things that only happen at decision theory conferences...

From /r/hpmor: * "I don't think a Durmstrang centered HPMOR one-shot would be disqualified or anything. That's still the world of HPMOR. However, I think it would help its chances succeed if there's some kind of framing device in the story that would contextualize it. Like in Ch. 100 there's this scene: > 'Bah,' said the foreign boy. 'In Durmstrang we learn to fight Buchholz hydra. Unimaginably more tedious to fight! I mean literally, cannot imagine. First-years not believe ...us when we tell them winning is possible! Instructor must give second order, iterate until they comprehend.' Fleshing out that story would certainly be an option..." * And so, entirely by accident, /u/Chinchillax proposed literally the longest finite story that had ever been suggested in the history of the human species. In the greatest understatement made on Reddit that month, /u/linkhyrule5, making a valiant attempt to explain, stated that the resulting length of story would be "bigger than Graham's Number".

Either people raised in England grow different taste buds or I don't understand the economic equilibrium that keeps all the food so awful. How do you screw up an $18 chicken Caeser salad that badly?  Why can't restaurants that serve competently cooked food take business from restaurants that don't?

"Imagine that in another universe," said the speaker, "the Large Hadron Collider study had concluded that there was a small probability of destroying the world, like 0.05. Some scientists might argue that the risk was still worth it, but probably most would object -" Me, sitting in horror with my mouth very wide open, having forgotten how this sort of thing works in the Other Minds. POINT ZERO FIVE PROBABILITY OF DESTROYING THE WORLD THAT IS NOT 'SMALL' ARE YOU INSANE... The speaker went on to note that this was especially bad if we accepted Parfit's argument about the value of future generations, but it was TOO LATE. On the plus side, I now understand a bit more viscerally the neglect of AI risk by the Other Minds.

It occurs to me that I've never actually mentioned: one of the most obvious-seeming fixes for a US-style government, if there were any way to do it, would be reducing the Senate to maybe 10 people and the House to 30. No corporation has a Board with 535 Directors no matter how large the company - you can't afford to incentivize that many good people to work for you. Being a Congresscritter is a crappy deal in many ways, even compensation in respect is low, the media hound you relentlessly, and unless you become President you don't get real status or power. In many ways it's an inferior life path compared to being a moderately ranked hedge fundie. If we only had 26 Senators as in the original 13 colonies, people could know their names, and if we only had 50 House members it would be easier to pay them a reasonable rate in status and future life prospects. Imagine the Supreme Court with 500 Justices. It would no longer be an ultimate apotheosis for judges and the main hope would be becoming a lobbyist afterward. For better government, just make the deliberating body smaller and you'll get better job candidates. Of course that will never ever happen. #civilizational_inadequacy

Julia Haas is giving an interesting presentation about a neuroscience theory that says 'weakness of will' is arbitrated by neural-level estimates of system reliability, and that deliberate thought is more reliable in novel situations, while habit is more reliable in familiar complicated situations. I'm not sure I buy that, but it has the interesting implication that maybe people get stupid to the extent they're often in familiar situations. But is that actually true? Also an interesting citation for a paper "bonsai trees in your head" about a game where players foreseeing early strong negative stimuli would prune their search trees of that path and its possible descendants, even if it seemed obvious that pruning was the wrong move from a long-term perspective. This was given as an example of Pavlov overriding the planning module - not the action, the planning itself.

Brienne:  Does anything bad happen if I eat a teaspoon of salt? Eliezer:  (Thinks of himself having a teaspoon of salt in a glass of water in the morning, every morning while he was on ketosoylent; knows that FDA guidelines far understate the amount of sodium to optimize health.)  No, that should be fine.  (moments later) Brienne:  Bleah!  Ew! Eliezer:  (looks at kitchen)... Eliezer:  ...you didn't just try to literally eat a teaspoon of salt without dissolving it in water, did you? Brienne:  (drinks two glasses of water) So she's currently in the bathroom throwing up, and I need to try harder to avoid transparency illusion when people ask me about whether things are safe.

What a stunningly reasonable and informed AMA. I shall have to see this movie after all. [Spoilers, but if I hadn't known the AI was not Hollywood AI, I would not have tried to watch.]

This worked pretty well for Brienne. And I avow that nothing bad has ever happened as a result, to anyone who has confessed to me and been turned down. Not much courage *should* be required... are you the sort of person who can take small risks? EDIT:  It's safe to confess to *me*. I can't directly attest to other safeties of my own knowledge. But doublecheck your thinking before deciding that it really is a large risk or not worth it. Lots of you have crushes on some pretty sane people, I bet.

Reminder: Taking a bet at 99-1 does not mean I think the probability is 1%. It means I think the probability is enough less than 1% that I stand to make a profit even after adverse selection is taken into account. That is how betting is supposed to work. When good rationalists are virtuously betting with each other over a disagreement, neither should feel that they are betting at the true odds. If two people both think they are betting at the true odds, they must agree on ...the odds, so they must agree on the probability, so they must agree on the credibility, so what on Earth are they betting about? When it comes to friendly betting, I'm willing to work with my brain's prospect theory and say, "I won't bet unless I think that I stand to make a *hedonic* profit even after my brain's loss aversion is taken into account."  I want to encourage my brain to bet again in the future, after all. Using the standard figure for loss aversion, if I bet with you at 99-1 (taking the 99 side), then I must think the true odds of my needing to pay out are *less than* 200-1. When it comes to the EmDrive also being an FTL drive, you could offer me $1 million for $1 and I wouldn't pay the $1. I'd rather own a lottery ticket. This is true even though I don't think I could make a million fully independent statements of equal strength, one after the other, and be wrong less than once. See also http://lesswrong.com/lw/u6/horrible_lhc_inconsistency/ and, I dunno, maybe it has something to do with exploitation resistance or bid-ask spreads or adverse selection or something. I still haven't resolved that Horrible Inconsistency, but meanwhile I'd rather have a lottery ticket than a ticket that pays out $1 billion if the EmDrive works as an FTL drive.

Not a fucking chance in hell and I will bet on that at 99-to-1 odds.

Dear Princess Kahneman:  Today I learned that in a grotesque generalization of prospect theory, people's actual decision theories change depending on their baseline and whether they think they're 'winning smaller amounts of money' or 'losing money' in Newcomblike problems.

I suspect this is part of what Hansonian modesty damages psychologically.

Overheard at MIRI: You can't affect the value of pi, but you can affect the value of Chaitin's Omega by trying to find Turing machines that contain a copy of you and bullying them into halting. This shows that the problem with trying to maximize pi is not that pi is a constant but that it is a low-Kolmogorov-complexity constant. (Thinking about this may make it easier to see that the universe is a constant.)

There's a cognitive skill that, in retrospect, has been important to my life, but which I don't think I've ever named:  It is (relative to myself) the skill of acting unlike Eliezer Yudkowsky, or averting self-consistency pressures. E.g.:  On one trip to New York, when I said I'd never drunk a glass of wine, someone challenged me to drink a glass of wine at least once, in order to - I don't remember if they said this, or I thought this - make sure that I wasn't just not drinking wine because I hadn't previously drunk wine. And it seemed to me that this was a legitimate bias that was worth disposing of via this one-time cost, so I drank a glass of wine. Just to make sure that on future occasions when I decided whether or not to drink wine, I would not be deciding on the basis of there being this huge threshold to cross over of a first glass. (I haven't had another glass of wine since, but don't regret this decision.) I think the form the cognitive skill takes for me is having in mind a picture of yourself - a concept of your role, not just the way other people see you, but also the way you've always behaved in the past - and whenever there's an optimal thing to do that involves behaving unlike yourself, you feel a little extra jolt of virtuousness, a bit of pleasure and positive reinforcement. It seems conceptually related to the skills of "Being a Genre Savvy, Level 1 Intelligent Character inside your own mental landscape" and another unnamed skill of "Trying not to be That Guy you keep meeting who is stuck inside their own corner of conceptspace and can't change the mind or their subject even if the world is at stake, so you treat them as an NPC and hope maybe you'll find a use for them someday - don't let yourself become That Guy." #cogskills

Economics terminology bleg!  I know what I want to say, but I've been using my own ad-hoc terminology to do it. I want to know if there are existing terms I should be using instead. #econ The subject I want to talk about goes like this: In this world there's always an equilibrium of desires; it's not always a pleasant one, but there's always an equilibrium. In academia, the grantmakers are /eager/ for prestige (or prestige per dollar of grant money), and the scientists are...

For ONCE in the ENTIRE HISTORY of TV, movies, and all other video formats, someone filmed a reasonably adequate AI story.

I've been considering the possibility of trying to publish some high-speed lower-quality writing pseudonymously. I make the following requests, commitments, and offers: 1)  I request any author asked if they are myself to respond "No comment, per Yudkowsky's request to reply 'no comment'."  You have my permission to gleefully exploit any confusion of identity that thereby arises. (Obviously, you don't have to reply 'no comment' if it's a hardship, it's just a little favor.)... 2)  I commit to reply "No comment" when I am asked if the intension of Eliezer Yudkowsky is coextensional with any other author-intension (unless that author asks me to deny that we are the same person, in which case I will do so, provided that we are in fact not the same person). 3)  Time permitting, you can ask me to edit the opening paragraphs or a rationality high point of otherwise moderate-quality writing that's to be published to an online audience, and I will try to make it sound Yudkowskian, thereby producing suspicion that you are me. (I reserve the right to only do this for things that seem sufficiently okay-readable, since otherwise there won't be much suspicion regardless, or at least I'd hope so.)

I ought to roll to disbelieve because of how well this story fits my preconceived narrative, but it just doesn't seem very surprising to me. #econ

"I miss the snow," she said. "It never snows in the Bay Area." "Uh huh," I said. "Maybe we could go back to your hometown for Christmas." She shook her head. "It's not the same as living someplace where there's snow."... "Uh huh," I said. "And you never get any ash clouds either. In summer we always had ash clouds that would blot out the sun and send little black flakes drifting down. The ash would stick to the wretched tree saplings reaching up their ruined fingers toward the sky, and make the branches look like they were seeping black blood." "I admit we don't have that in California either," I said. "You know, I bet if you'd grown up in Hell instead of Mordor, you'd be talking about how you miss the boiling sulfur lakes." "I agree," she said. "I also think that if we moved to Hell today, you'd be complaining about the smell of sulfur all the time." "Sure," she said. "What's your point?"

What is the least Convincing Number? If you ever encounter an entity claiming to be omniscient, omnipotent, an alien with nanotechnology, or anything else that would imply it had access to a very large amount of computing power, you want to be able to ask it a question with an extremely expensive answer you can easily verify afterwards and that, ideally, will convince a lot of other people to pay attention to you (if not necessarily to believe your exact story). An obvious candidate would be an unsolved RSA number. But memorizing large composite numbers is hard, and memorizing the entity's reply, on the spot, might be humanly impossible. So: "Ask the entity to give you an English-language rhyming couplet such that each line has the same SHA256 hash value."  -- HonoreDB on SlateStarCodex If the entity is logically but not physically omniscient, you may need to memorize the SHA256 formula, but this should be significantly easier than memorizing one of the unsolved RSA numbers. A possible improvement - though I may not have thought it through in enough detail - would be, if you can memorize 9-digit numbers on the spot, to ask for the formula for the largest Mersenne prime 2^p - 1, such that p is an 9-digit number. (We can't verify that it's the *largest* 9-digit p, but it would be a Mersenne prime much higher than any discovered before, in a problem that's received a lot of attention.) I pose the following question: given the number-theoretic and cryptographic problems our civilization has considered so far, what question probably has the *smallest* (or otherwise easiest to memorize) answer N, such that we can verify N afterwards, the presentation of the answer will be extremely surprising, and ideally, the formula for N will be easy to explain to aliens? EDIT:  The purpose of this question is to provide the best available Bayesian evidence, that can be provided as a 3rd-party-checkable piece of information, that you've talked to some sort of entity more cognitively powerful than modern humans. We're not trying to discriminate mathematically advanced vs. computationally advanced, omniscient vs. superintelligent, etc. See http://slatestarcodex.com/.../universal-love-said-the-cactus.../

Fun applications of the principle that All Infinite Recursions Are At Most Three Layers Deep! * It is often important to distinguish the object level from the meta level, and sometimes we need to have conversations about how much meta is appropriate (meta-meta), but no useful discourse has ever occurred at the meta-meta-meta level, or if it has, it's indistinguishable in practice from meta-meta. * People model other people as modeling other people. People, at least neurotypical people, don't model other people as modeling other people who model people. For example, part of the reason why the Ideological Turing Test is hard is that e.g. an atheist models a Christian as having a model of atheists, but they don't model Christians as having a model of an atheist's model of a Christian. * Corollary: If you ever want to create a game with agents playing realistic politics, and you have enough of a SHRDLU / Rainbow AI model to do GPS-style backward chaining and agents modeling other agents, then it's okay to have each agent model what they think all relevant agents believe about all relevant agents, and then stop there. * Suppose your teacher tells you that there will be an "unexpected pop quiz" on some weekday of the next week. They won't give the quiz on Friday, because then it won't be unexpected. And they know you know they won't give the quiz on Friday (they model you as modeling them), so they won't give the quiz on Thursday. But they don't model you as modeling them modeling you modeling them, so they'll think Wednesday is a plausible day to give the quiz, and Monday and Tuesday are about equally surprising with each other. This is the correct real-life solution to the Unexpected Hanging Paradox.

Just thought I'd mention it out loud, in case I'm missing anything: the following beliefs both look to me like they grossly violate the Efficient Markets Hypothesis: 1)  A company that underprices its IPO to cause a first-day 'pop' in shares will have a persistently higher valuation afterwards. 2)  A 6-month lock-up period for previous holders of company stock is required to protect the IPO price from those holders dumping shares.... So are these more cases of grossly superstitious behavior and beliefs by a majority of financiers (possibly with a signalling equilibrium requiring even rational actors to conform to the superstition)?  Or am I missing something?  I suppose if it's impossible to short-sell recently IPO'd stock, (2) might be true iff there are no rational buyers of the IPO stock (and by assumption, they cannot become rational short sellers).

Overheard at MIRI, while writing down potential things to discuss that day. Eliezer:  And then there's the other-izer problem. Like, what we can have besides satisficer, meliorizer, staged maximizer... Benja:  How about Ele-izers? Eliezer:  No.... Patrick:  Maximizing expected yudtility? Eliezer:  NO.

On reflection, I don't think I've ever seen the basic theory of minimum wage laid out in a way that sounded complete to me, so I will write down my own attempted understanding thereof: By default, prices equilibrate the supply function and the demand function. They have nothing to do with what is 'fair', with what is 'just' - except insofar as nobody who charges or pays the market price can be said to be actively cheating anyone. If, in the wage regime of interest, few peop...

Politically feasible things (inside the Overton Window) that a well-intentioned US politician could reasonably and sanely advocate to improve the lives of low-income individuals: * Increase the Earned Income Tax Credit * Decrease marginal income tax rates on the bottom 30% * Shift benefit phaseouts upward, make the phaseout curve less steep... * Repeal the law exempting student loans from bankruptcy * Paperwork reduction on benefits; tie eligibility in automatically to IRS records and have IRS records automatically computed from W-2s (the goal is to ensure that people with IQ 70 don't have to fill out complicated forms to be eligible for benefits) Things that WILL NOT HAPPEN and WOULD NOT IMPROVE the lives of low-income individuals, and THEY KNOW THAT: * Expel everyone with a real marginal productivity under $15/hour from the labor market, causing a massive economic collapse. Every politician that endorses a $15 minimum wage is being dishonest, or the moral equivalent thereof in deliberate rationalization, blindness, and willful stupidity. They are smart enough that they either know better (likely) or could know better with very little effort. At the very least they know $15/hour is not going to actually happen, because that is inside their domain expertise no matter how blind they can pretend to be to economics.

Oh the adorable.

My friend Andrew Rettek is looking for a salaried position at a startup or other company that can make use of his skills. Andrew is able to sell technical or complicated things that the customer has not heard about before. Andrew understands fundraising for startups and how to talk to VCs. He can work with little or no management and figure out how to do his job without handholding. He lives in the San Francisco Bay Area. Give him or me a ping if you're looking for someone who can market and sell new, weird, or complicated products.

My usual analogy for religious law in Orthodox Judaism is that it's 1500 years worth of accumulated RPG textbooks and commentary. Only from our perspective it's more like 100 years, because they didn't have printing or the Internet. If they'd had the Internet for that whole time, Orthodox Judaism would have been *glorious.*

LOL (I have not yet worked out answer or its recipe, but am laughing out loud at the problem).

I'm out of practice on Smullyan puzzles, I had to pause and think in order to answer this.

Is it legal for a US 501(c)(3) tax-exempt nonprofit to buy an impact certificate?  Has anyone looked into whether e.g. MIRI would be legally allowed to do it? (Impact certificate: someone certifies that person X has had a positive impact of at least $100,000 (on some scale) on a given field; you can give that person $50,000 to buy 50% of their impact certificate. http://impactpurchase.org/ ) Paul, Katja, Carl, and please tag anyone at Givewell or CEA who'd have already researched this.

Overheard at MIRI:  "The paper title could be, 'Creating value using systems of Paul Christianos:  A five-hundred-thingy-dingies approach.'"

*rolls to disbelieve*

As I understand it, there's two main reasons why a well-functioning economy should be inflationary, maybe at a steady rate of 3% per annum or thereabouts: 1)  The amount of money flowing corresponds to the number of trades occurring. If there isn't enough money flowing, some number of trades will fail to occur and this represents a loss of real productivity for the economy. Adding enough money to produce significant inflation means that you have enough money in the system to be vigorously competing against other money to make trades, that you're operating at the limits of real capacity. If there's no inflation, it means the monetary pedal that accelerates trade isn't pushed down far enough. 2)  Nominal price levels in many parts of the economy are sticky downwards, because the seller is usually the person who sets the price and loss aversion is a thing. A nominal salary cut requires renegotiating a contract, a nominal salary increase does not, and even e.g. an airline may be more reluctant to cut nominal prices than to raise them. So inflation, by decreasing the real price corresponding to a nominal price, helps real price levels to adjust despite nominal stickiness. Also a default rate of inflation gives the central bank the power to regularize NGDP by regulating interest rates rather than QE, but I don't really see that as a strong feature. QE seems to me like the natural and normal way to regulate the flow of a currency (sell or buy the unit of exchange), and it seems to me like trying to regulate interest rates is much worse than this natural method even if it's considered traditional. So am I missing anything?  In particular, did I misunderstand something about reason 1?  I don't think I've ever seen it spelled out in exactly those terms. It's not clear to me why we shouldn't try for 5% inflation instead of 2% inflation. Except that a lot of people try to store money in nominal bank accounts that earn interest below the risk-free rate, and they would see this as theft. But if nobody's trying to store value in low-interest nominal bank accounts, 5% annual inflation would help people to see price levels as temporary things and money as a unit of account rather than a store of value.

Michael Vassar and myself have independently arrived at the suspicion that low-income individuals are often stuck in traps with multiple parties competing to extract all available rents from them, e.g. the Ferguson Police Department. Then marginal interventions to cause low-income individuals to have more money, such as the Basic Income or GiveDirectly, will not be effective on whole countries or whole towns, though they might be effective if you give one individual enough m...

By far the most outside-the-box startup in YC's current batch is PetMatch. Use your phone to take photos of your current dog or cat, and PetMatch will search their database of available animals to find a healthy dog or cat that looks almost exactly like yours. With the premium version of their service, they'll also teach the animal to respond to your current pet's name, and use operant conditioning to instill a positive response toward people who look like you and your family (via pictures or videos of you). It will feel like *your* pet on the day it arrives. This isn't just useful for when your current pet has an incurable disease, it also competes against conventional treatment for major health problems. PetMatch's quick-quote mechanism lets you get a rough idea of the replacement cost for a healthy version of your pet, so you know the most you should spend at a veterinarian trying to repair a sick version. You can also list your minimum selling price for your current pet on PetMatch, in case somebody sufficiently rich wants to buy it to replace theirs, like Make Me Move on Zillow. Remember, no matter how much you love your pet, there's *some* price at which you'd not only sell it, but feel happy about the price you were getting.

Trolljecture:  A mathematical hypothesis that you don't yet believe, but state as a conjecture in order to provoke someone else into trying to disprove it.

As a little child, watching Thundercats, there was an episode where the villains summoned some great warrior or other to fight the hero. The summoned warrior shows off their sword by slicing through a stone pillar, and the villains jump back and their eyes boggle. I remember frowning at the TV and wondering why the villains were acting so impressed. My first thought was that the stone in the pillar was heavy, so the warrior's sword shouldn't have been able to lift it up even a little in order to insert the cutting wedge and slice its way through. Some time later I began to suspect for the first time that, despite all previous cues from all observed TV and movies, not all swords would cut through anything.

Timmy's Journey: A Statistics Game is the sort of thing that needs to exist, and Cassandra Xia is someone who I'd like to see encouraged to do more of it in the future. The Indiegogo has 8 hours remaining and $7500 to go.

This is the greatest relaxation video that has ever been made.

(Thinking aloud about the prospective Precisely Bound Djinni story.) I've pondering the question of how to have a character that can reflect a Reddit hivemind and still have a personality. Obviously, she's going to be a nitpicker, a multiple hypothesizer, and one hell of an optimizer. But can she have any other qualities, like a personality?  What if those qualities get in the way of what the hivemind wants her to do?  What sort of feelings, emotions, Nature and Demeanor co...

Do any civilizational-adequacy believers have a word to say about the apparent inefficiency of on-site home construction vs. factory alternatives that claim to get it done at a third of the cost?  Why would real estate operations leave money on the table?  Is everyone who claims to be able to construct an equally good house offsite for cheaper just lying?  China certainly seems to be realizing the promise with prefab skyscrapers.

Does anyone know whether the severity of a cold depends on the amount of initial exposure?  Is there any effect whereby, e.g., if you're initially exposed to a large dose of virus, it gets further in your body before your body develops antibodies?  Or is it a known fact (how?) that exposure dose affects only probability of catching, but not severity if caught? Context: I pretty much expect to catch Brienne's cold at some point, and want to know if there's any point in trying to limit the magnitude of my initial exposure to it.

For those who asked how to build their own Luminators, key ingredients are as follows: Slimstyle Daylight 60w: (expect ~$8/each) http://www.ebay.com/sch/i.html... or... http://www.amazon.com/gp/product/B00JM72W6C/ref=as_li_tl... Cree TW 60w-equivalent. Much cheaper in CA if you go to Home Depot, ~$10 each there. Make sure you get the TW (for TrueWhite) and not the regular sort. http://www.ebay.com/sch/i.html... or http://www.amazon.com/gp/product/B00H27TDSY/ref=as_li_tl... or Home Depot Brienne's current Luminator uses 25 Daylight Slimstyle and 10 Cree TW, for which you will need strings of sockets. There might be a better version of these strings that isn't optimized for outdoors, without the rubber surrounding the sockets (which makes lights difficult to screw in), but these were the cheapest strings that did the job: 25-socket string: http://www.amazon.com/gp/product/B008ALNXQ4/ref=as_li_tl... 10-socket string: http://www.amazon.com/gp/product/B00I4XMQB6/ref=as_li_tl... We had previously futzed around with mylar-lined ceiling gutters but we currently just have the light strings draped up. You may find it helpful to add a timer or remote control. Timer: http://www.amazon.com/gp/product/B006LYHED0/ref=as_li_tl... Remote control: http://www.amazon.com/gp/product/B00DQELHBS/ref=as_li_tl... For Luminators that can fit into an upright lamp or vertical light socket in a ceiling: 7-socket splitter (this page also has 4-socket splitters): http://www.ebay.com/sch/i.html... If you are okay with CFLs (breakage risk with mercury, flickering) then these are bright and cheap, note the 3500k color temperature which is important: http://www.amazon.com/gp/product/B00GBFCPN8/ref=as_li_tl... The 7-splitter plus 2 packs of the above CFLs should make a moderately brilliant Luminator, but you'll need to wait for the splitter to arrive from China over a couple of weeks. If you're in more of a hurry, an Amazon Prime 4-splitter is here: http://www.amazon.com/gp/product/B00G9JS30U/ref=as_li_tl... Screwing a 4-splitter into a 7-splitter, and putting 4 SlimStyle Daylights above 6 Cree TW bulbs, makes a very nice 10-bulb (8000-lumen) LED Luminator that looks like a small sun. Enjoy!

Oh my gosh, I'm now caught up on Homestuck. Is that even possible?  I was like "where is the ==> button, do I have to find it by clicking somehow" and then I saw the violet color of clicked links by the Recent Posts bar and it slowly dawned on me. I *want* to do something with more complicated time travel than Homestuck, and I probably could if I spent a while with Freemind working it out, but it would just take too much time and... I'm going to have to concede defeat. Andrew Hussie wins.

Does the section of throat that collapses during sleep apnea ever actually *need* to close for any reason?  Like is it the section of airway that closes when you swallow?  The diagrams I'm seeing don't seem to indicate a collapse directly at the epiglottis. Could a ring be surgically inserted to hold that part open?  Or maybe a spring?  With apnea surgeries that run to $50k+ to break and widen the jaw, I wonder if simpler mechanical solutions were ruled out.

Scott A. has posted a carefully reasoned, scientifically informed article on gender bias.

What would a lottery look like if run by a government that was more compassionate toward its lowest-income citizens?  (Current lottery 'unkind': IIRC introducing a state lottery causes an average 3% drop in spending (possibly on food or basic necessities, I don't recall the exact nature of the figure) by individuals below the poverty line; the current lottery is behavioral-science optimized to maximize spending by all purchasers, including those below the lottery line (who ar...

Just so you don't go thinking a story like HPMOR springs fully-formed into an author's head... My first vision for this story ended with Harry staring on in horror as Professor Snape Crucioed the face on the back of Quirrell's head into permanent insanity, in the final Philosopher's Stone chamber. Things sure do change, don't they.... (My second vision for the fic ran "Light Yagami is older and smarter and has 300 horcruxes, Headmaster L is pretending to be insane, and then into the middle of their duel wanders a young Miles Vorkosigan starting his first year in Hogwarts." This one probably sounds a bit more familiar if you know the source material.)

Reason.com, still the only media on the planet outside personal blogs that hosts intelligent coverage of anything at least sometimes. (Is there anywhere else?)

And done. http://hpmor.com/chapter/122

Got seasonal affective disorder?  2 strings totaling 35 800-lumen LED bulbs seem empirically more effective than close proximity to one traditional lightbox, in Brienne's experience so far. Note the mix of blue 5000k and high-red 2700k (Cree TW) bulbs.

I'd expect it to be harder for a superintelligent AI to persuade a male Gatekeeper to castrate himself than to just let the AI out of the box, but still easy in an absolute sense. As has been demonstrated.

A possible next thing to do after HPMOR.

Want a page listing pictures of catgirls with twintailed hair wearing thighhighs and sweaters?  Gelbooru's tagging system has you covered. Want to find medical research about chronic fatigue syndrome in which the authors talk about the success probabilities of treatments?  You're out of damned luck. Humanity isn't going to waste resources classifying its scientific knowledge until it is finished tagging all the catgirl pictures.

I see a lot of my friends taking a "Roomie Test" that sometimes seems to deliver amazingly accurate results. When I clicked on this app, it asked for permission to read everything on my profile *INCLUDING MESSAGES*. I strongly suggest not taking this test. I also suspect that if you are "in a relationship" it just returns whoever is in that relationship.

Sarah, the primary researcher, is known to me to be competent and conscientious. Apparently it is very hard to find real info on STDs, the sort that comes with probabilities attached. Seems worth fixing.

Me:  "I can't believe how brilliant these people are." Brienne:  "That's not something I usually hear you say." Me:  "I'm not usually watching thousands of people collectively think up solutions way cooler than the one I had in mind." I'll have to write about this later, but... WOW collective intelligence. Once all the good ideas are collated I need to write Omake Files #5 containing as much of the good stuff as I can fit in there.

I just want you to know... I'm feeling quite happy right now, reading your reactions. #finalexam

!!!

!!! Well, that might be a bit of an opportunity if some country would like young folks to move there.

And lo, Ch. 108 did post, with the answers to many questions; and lo, Reddit's commenting mechanism did break and shatter and crack asunder, that none might speak of it. EDIT: /r/HPMOR seems to be working again now.

"In general, people are insane but they aren't blind. Ancient people made up all kinds of crazy reasons for why the sky was blue, but that didn't make them wrong about what color it was."  -- https://www.reddit.com/.../comments/2w526t/chapter_105/connxjv Henceforth I shall think of "People are insane but they aren't blind" as Erenthia's Principle.

Ch. 104 is up. http://hpmor.com/chapter/104 It begins.

Annual reminder:  My current policy is that I will not ask you anything romantic or sexual unless you have already expressed interest in me. (Unless I know you well enough to know that you know that I am a safe person to tell 'no'.)  I am also stereotypically oblivious to hints, or so I've been informed. If you desire to date me or just unlock my achievement, you need to explicitly tell me (not hint) that you like me in that way. I would not advocate this as a good general... arrangement that other people should try, but it seems like an okay equilibrium in my special case. I observe empirically that my being asked, and saying no, does not seem to reduce friendship prospects on my end. (Likewise if I say yes.) If you are too shy to confess to me directly, consider talking to Brienne Strohl first. So far as I know, I am strictly heterosexual, for which I do apologize. This concludes my romantic Valentine's Day announcement. Carry on.

Synopsis:  While still coming to terms with her submissive nature, Laria is transported to a magical world with 40-hour days, where she discovers that her true father is none other than the great Emperor Kalnodar. As a new-minted princess she is offered a male harem consisting of a vampire, a werewolf, an elf, a pirate, and a doll slowly learning to be human, all of them dominants. When some of her harem members begin to fall in love with each other, sorting out the resulting romantic tangle threatens Princess Laria's ability to keep up with her coursework in the local school of sorcery, along with her musical career and her training for the World Martial Arts Tournament. Then Laria's schedule takes a turn for the busier when she learns that she is the prophesied woman destined to return the long-lost arts of rationality to the world and fight demons by night. Will she succeed in deducing which of her harem-mates is really her own time-traveling genderbent self from an apocalyptic future, before she is consumed by the demonic power of the paperclip maximizer imprisoned inside her soul? testable hypothesis: the literary appeal of a work is strictly additive in all the tropes used to build it

That is an excellent case for "best philosopher".

Overheard at MIRI:  "Your theory so improbable, the expected value of a ticket that pays $1 if your theory is true is negative two dollars."

The folks at Exosphere were super helpful during my and Brienne's stays in Chile, including helping Brienne to find a livable apartment, and including some of their people helping to organize an ambulance ride to a clinic for me when I had a cold and my fever spiked dangerously high (taking a hot shower increased my body temperature to where my voice came out slurred and I had trouble standing - I did not realize that 'long hot shower + fever' was a failure mode though it seems obvious in retrospect). They asked me to do an interview for their blog, and here it is: http://blog.exosphe.re/why-do-we-need-friendly-artificial-.../ PS:  Also, everything they say about 'health care is better and cheaper everywhere except the US' seems to be true at least of Chile. Price of the ambulance ride and clinic visit was $230 US, care was very competent and fast.

If I was considering writing a romance novel with a... twist, where would I find the best-written and most intelligent romance novel?  I can't read most fiction due to lack of Level 1 Intelligent characters, so not an easy question in any genre. EDIT: I'd want such a novel to also satisfy the reading urges that a romance novel usually feeds, so I'm not looking for anything so unusual that it was no longer read by the usual audience.

Science fiction authors who write about 'transhumanist' subjects (advanced tech w/ cognitive enhancement | smart AIs | life extension) sometimes seem to be missing something at the heart of it all. The thought now occurs to me to sort them according to (spoilers http://hpmor.com Ch. 43+) whether they could cast the True Patronus Charm, or whether their writing gives the impression that the author could do so: * Peter Hamilton:  Clear yes; sun-bright Patronus. * Greg Egan:  Obvious no. * Vernor Vinge:  Yes. * Iain Banks:  Not sure, but I think no. The Culture novels read like the author saw True Patronuses and understood what they did and why, but couldn't cast one. And then set out to make a true and honest effort to write about both sides of that story, including the True Patronus casters' side and the Dementors' side. * Peter Watts:  No, I think? * David Brin:  Obvious yes; blazing Patronus. * Charles Stross:  Have not read, but I suspect no. * Cory Doctorow:  Have not read, but I suspect a very clear no. Most old-time science-fiction authors have a clearer Yes than modern ones - Robert Heinlein is a clear yes, though not a blazing-bright Patronus - and I'd trace this to the general Cynical Stagnation of SF. There used to be a clear understanding that when your species grew up, you became long-lived and smarter, just like colonizing the stars was a thing-you-did-when-you-grew-up; and if you weren't a villain species you'd help out any lower-tech species you ran across and grant them civil rights.

Allegedly we should be sparing with the Benadryl and other anticholinergic drugs to avoid dementia. Roll to disbelieve? (EDIT:  My knowledgeable friends seem to find this very credible. Fear the diphenhydramine, I guess.)

This is one of the most accurate one-sentence summaries I've seen.

Seeing this on FB reminded me of the following obvious-seeming point I've never heard stated elsewhere, though I doubt it's original: It's all well and good to point at background constants (or things that, so far as we know, are constants) like the cosmological constant and say that if they were mildly different life couldn't exist, ergo there must be a selective factor on universe (multiverse anthropics etc). But what seems even more clear is that if you look at, say, the ...relativistic Schrodinger Equation, most differential equations of equal complexity will not yield causal universes that sustain life. And the whole thing with nuclei that have electron shells so that molecules can form and some of them can self-replicate and undergo natural selection... that's going to happen in a very small fraction of randomly selected differential equations. It's *obvious* that we are living in laws that were selected to support life - whether universes self-replicate and intelligence sometimes deliberately or as a side effect supports the process, or whether there's just a very large multiverse of all possible differential equations and constants and we're living in the part that can support intelligence, it's *blatantly obvious* that the laws were filtered somehow. That is: it is not the case that there was only a single set of differential equations that were real and only a single set of possible constants and it just happened to support life. I much more speculatively wonder if there was some kind of complicated causal history behind ending up with the particular laws we did, not just a single-pass filter through Tegmark IV; and that there's something about it that explains why Special Relativity becomes Newton at low velocities, and quantum waves become classical in the macroscopic limit, and nuclei turn into well-packaged chemical elements, and so on and so on. It is *weird* that reductionism works so well in our universe. Conway's Game of Life does not have anything like these mostly-well-packaged layers, just gliders and little squares.

Is this very bad news for microcredit as EA, or did I fail a roll to disbelieve?  I'm surprised, since my model of the poverty equilibrium (as average income increases, confiscatory forces take more of it from the least advantaged individuals - I don't know if there's a standard term for this hypothesis, but something has to explain why farming productivity can increase 50-fold and we still have people living lives of desperation) says that providing microcredit to individuals, rather than whole towns, should still have increased individual consumption.

Current best use of money:  http://rationality.org/donate/ There's less than 24 hours left in their fundraiser and they need $40k of additional donations; money is doubled by matching contributions; and CFAR is in a critical stage of growth where money today is probably significantly more valuable than money in 5 years.

Does anyone know offhand if there's a single country in the world with sane tax laws?  Qualities of sanity, in order of priority: * No capital gains tax (WHAT THE HELL IS WRONG WITH PEOPLE, IT'S LIKE A TAX DESIGNED BY PRESCHOOL CHILDREN WHO JUST SEE MONEY MOVING AND TRY TO GRAB SOME OF IT) * Yes land value tax * Yes value-added tax... * No income tax Failing that, does anyone know of a big side-by-side comparison table of countries by their total large-scale tax policy - the major percentages they collect on everything? If I found a country with no income or capital gains tax (presumably made up by value-added tax or other sane taxes) *and* sane immigration laws (i.e., you can bring other people in pretty easily) *and* decriminalized drugs and prostitution (so people don't get randomly arrested) then I'd start agitating for a mass emigration. I've been wondering how hard it would actually be in real life to try to put together a coalition of economically literate Silicon Valley CEOs and venture founders, and try to negotiate en block with a relatively sane country to either have acceptable tax and immigration laws in general if they got to be the next Silicon Valley, or create an enterprise-zone-style enclave in exchange for the host country getting a percentage of land value taxes and otherwise not needing to provide any services.

http://HPMOR.com/chapter/103 It returns.

Who knew Legolas was such a wimpy archer by comparison to well-trained humans?

Wait, what?  I was not expecting this.

Can anyone confirm that they've tried this experiment or that they trust someone who has?  This seems incredibly congruent with my slapdown model but I don't know if I can trust the evidence.  Also seems like a great litmus test for which boys to date, if true.

I'm pretty sure my D&D alignment these days is Chaotic Lawful Neutral Good, in that order.

I've recently explicitly noticed a mental posture I deploy which I'm tentatively naming Flawed Mindset. * Fixed mindset:  I didn't solve this math problem on the first try. I'm stupid, this is horrible, I should go do something else. * Growth mindset:  I didn't solve this math problem, yet. I can acquire skills and try again. It's okay because this future state where I am better still looks attainable to me, even if the present state is bad. * Flawed mindset:  I'm this hugely broken evolutionary kluge, and I can't fix that in any timespan I should be optimizing for, but it's okay to be a huge broken evolutionary kluge, we all are, we're all in this together, and optimizing within kluge-ness is all I'm trying to do. You have a way to become slightly less flawed, while still being flawed?  Cool, let's try that. Sure, we can talk about it openly. I know you're not trying to push down my social status by doing that. We're all kluges together. It's okay even though nothing I can do is going to fix this completely in a reasonable timespan. Flawed Mindset gets invoked every time, e.g., Anna says to me, "You look tired and emotionally distracted, and you can't reason well while you're doing that. Maybe you should try this energy drink" and it doesn't even occur to me that something that feels bad or shameful has just occurred. Reflecting on it, I suppose there's an Eliezer who doesn't have those problems, but he lives in the should-universe. That universe has been getting steadily more emotionally distant as I separate out more and more things that only live in the should-universe. #habitsofthought

There are parts of the LW Sequences where I refer to God as invisible sky fairy theory, or something along those lines. I thought at the time that at least some people displaying open contempt against religion might be necessary to trigger people's "this thought may cause me to lose status" reactions, without which it would be impossible for them to abandon bad ideas - that until some part of them realized, "Oh, saying this will make my friends think I'm stupid" it would be ...impossible to let go of certain kinds of attachment. This, I now believe, was very wrong, for two reasons: 1)  CFAR is figuring out how to teach epistemic rationality starting from questions like "What actually happens to me if I talk to strangers?", and then once people get good at that, the skills will hopefully carry over to abstract beliefs of the sort you need to correctly target EA work or figure out which startup to do, or, yes, the many-worlds interpretation of quantum mechanics and so on. 2)  My later experience with Sneer Clubs, and my current model of how Sneer packs form and operate, causes me to think that saying 'invisible sky fairy' and the like is way, way too dangerous. Anyone who needs to expect status loss in order to let go of a bad idea is out of luck, or can get their rationality assistance elsewhere. It is just way too dangerous to have anything around that could attract people who like to sneer at things.

TRIGGERS:  The internal sensation of trying out more than one hypothesis for what someone meant; the feeling that what they just said was a non-sequitur; the sense that they just said something that is uncharacteristic of them; the sense that what they said is really bad news. ACTION: Ask what they meant; repeat back what you thought you heard in different words; adopt a goal of making sure you understood correctly. ADDENDUM: I had this in mind as a technique for talking to close friends, not necessarily the rest of the world! #habitsofthought

Old-school Sneer Clubs.

Do the soldiers of Elua rush into combat screaming "LOVE FOR THE LOVEGOD!" and, if so, what is the second line?

I need 30 or at least 15 minutes of strong massage (I guess it would be classed as 'deep tissue' or 'sports' maybe?) every other day in order for my shoulder to go on functioning. Both of the people who usually do this are out-of-state. Any recommendations?  (Berkeley near Shattuck and Dwight.)

This is by far the best instruction for meditation that I have ever read. And "I have a vague impression that I have prepared for this" seems like it could become Arc Words on a level with "I notice I am confused" or "I've got to start listening to those quiet nagging doubts", in fact "I have a vague impression that I have prepared for this" constitutes exactly the second half of the general skill.

Writing advice I gave today. The general rule is that transition problems occur when the reader is expecting one thing, and you give them something that doesn't match it at all. * transition problem:... yesterday I went to the subway. by the way, my hand is on fire. way 1 to solve:  painfully try to create a bridging sentence. yesterday I went to the subway. but enough of that, let's talk about fire. my hand is on fire. way 2 to solve:  foreshadowing yesterday, when my hand was cold, I went to the subway and was able to feed coins into the vending machine. but today my hand is on fire. way 3 to solve:  reordering my hand is on fire. yesterday I went to the subway  (FAILED in this case, but by far the most common thing you actually need to do) way 4 to solve:  common themes yesterday I went to the subway using my hands. today my hand is on fire and it feels as hot as if it were underground. way 5 to solve:  deletion yesterday I went to the subway. way 6 to solve: categories Let me tell you everything that's on my mind, about external places like the underground, and internal places like hands. < note use of finding a contrast to create apparent relatedness, and foreshadowing the existence of a collection so that the actual collection doesn't come as a surprise, and trying to add a theme to the collection Things that happen underground: - yesterday I went to the subway Things that happen to body parts: - My hand is on fire. way 7 to solve:  blatant foreshadowing. After I tell you about the subway, I'll tell you about my hand. Yesterday I went to the subway. My hand is on fire. way 8 to solve:  screw this Yesterday I went to the subway. My hand is on fire.

AAAAHHHHH I think if Scott had ended this post with "To solve this problem we all just need to donate one Bitcoin to this address" I probably would have done it. But there was no call to action because Scott doesn't know what to do.

Literal utterances emitted by sociopaths, according to a friend's recounting:  "Any zero-sum game or positive-sum game can be made into a negative-sum game if I try hard enough. And if I'm the best at negative-sum games, why wouldn't I do that?" CONGRATULATIONS YOU ARE MORE EVIL THAN MY MODEL OF VOLDEMORT

THANK YOU KIMBERLY WINSTON OF THE WASHINGTON POST FOR WRITING HONEST NEWS!

After failing twice to do so using military strength, the Germans are now crushing the whole of Europe using bad monetary policy. I think they just can't move on until they get it done at least once.

I wouldn't eat that. (Short story by Brienne.)

Brienne:  i think you should practice telling me no Brienne: can i have a pony? Eliezer:  why do you need a pony? B: 'cause i really want one E: have you looked for cheap ponies online?  what do they cost?... B: ponies are expensive, especially once you have them E: would a robotic pony work? B: no E: hm... E: I'm not sure this pony thing is actually going to work. B: in fact it has to be a pegasus pony B: hm. ok. B: can i eat nothing but chocolate for a month then B: ? E: which month? B: january B: (i don't think you quite have the spirit of this yet) E: does it have to be pure chocolate or can you put chocolate sauce on something else? B: nope, nothing but chocolate E: how about if you drink Soylent so that the only things you actually *eat* are chocolate? B: no, i'm going to drink chocolate syrup E: chocolate syrup isn't actually pure chocolate itself, it's mostly the added sugar part. B: there's no such thing as pure chocolate E: okay well if there's no such thing as pure chocolate you should be fine with chocolate-flavored Soylent B: nope B: hershey's chocolate syrup only E: well, I'm afraid I can't approve this plan as put forward but let me know if you come up with a variation you want checked B: can i eat un-peeled apples in front of you? E: NO

"Human attention narrowly tracks our gaze most of the time. We don't notice much about our periphery unless there's some sudden unexpected movement. Then our attention snaps to that spot, and our gaze quickly follows. Our attention is like that for all sensations we can be aware of, not just vision. Like hearing your name at a cocktail party, or remembering you left the oven on. We evolved to turn our attention toward those things so naturally and easily that we can't help doing it. Much of learning rationality, or at least the style I've so far studied myself, involves attuning your mind to new types of sensation, striving for the automatic snap-focus response when you encounter them. We want our attention to move toward confusion, rationalization, curiosity, and many other sensations we didn't evolve to care so much about."

David Monroe remarks to anyone who cares about the #berkeleyprotests: Any movement that is ready to openly oppose the police must also be ready to supply its own civic order. That means you have people who are ready and organized to stop any attempt at looting. Otherwise it is elementary for the police to claim to be scared of you, draw back, and wait for looters to emerge. Police can cause broken store windows at any time simply by not being there, and the cliche-reporting media will blame it on you. Any movement that is ready to openly oppose the police must be ready to supply its own civic order at any event associated with its name. As it stands, you have already lost. Good citizens will feel less inclined to join future events, rioters and looters will consider themselves invited. Protesting after sunset is a further tactical error. Your grandparents did this better. They marched in lockstep, hand in hand, singing in unison, making it clear to those who needed to see that they represented an organized power. Your grandparents' leadership had plans, they thought strategically; they did not protest to vent anger but because they had a plan and protesting at some particular place and time was better for that plan than not protesting. Your actual key step is to find an experienced and successful organizer, perhaps a labor leader from the previous generation, and put them in charge. But they may not be interested until you demonstrate that you can organize your people to listen to *someone*. Eliezer Yudkowsky disclaims: the David Monroe model does not actually have any experience in protesting or organizing.

I don't know the status of informed debate on whether there was a real person corresponding to Buddha at the start of Buddhism, but if there was, telling the mythology as if Buddha stood up from under a tree containing the entire idea, and furthermore woke up with *the ability to explain it* using parables that people needed to have faith in and would only fully appreciate years later, did a tremendous disservice to Buddhism. Like this is not something you can just do without any development process for finding out which delayed-action parables work. The ability to explain things is not just a freebie in the Enlightenment Package Deal. If there *was* a Buddha, he tried to explain his ideas, kept being baffled at how people didn't seem to understand correctly, practiced, observed what worked, and eventually got better at it, and 90% of the total ideas were developed along the way. Telling the story like he just stood up from under a tree with super explanatory powers did a tremendous disservice to everyone later on who wanted to be able to explain Buddhism, and thought that explanation ability just automatically came along with True Mastery, which in turn was acquired by trusting in people who knew more until all became clear, all the way back to Buddha getting the complete skill set out of nowhere. This is not a realistic model of where cognitive skill is originally created, nor where you create the cultural ability to transmit it even using delayed-action parables and trust. The stuff has to *come from* somewhere, and at least the Buddhism I've seen seems remarkably silent about there being an incremental development process when these skills and teaching methods are happening *for the first time ever* and not just being acquired from a master or being acquired via Enlightenment Packages.</rant> If you would falsify this, don't just tell me how the legends include the would-be explainers undergoing unspecified travails without any specific mistakes shown; show me the historical record of the first three versions attempted of a now-famous koan that worked embarrassingly poorly at the time. I am open to the possibility that this will happen in the comments.

P/S/A:  Seriously, get the hell out of individual stocks and into a broad market index. When you buy stock in BLAH at $30 because you think it's undervalued, somebody else sold you that stock at $30 after making a deliberate decision that they would rather have your $30 than that stock. And that seller has enormous computers run by physicists and full-time market analysts. Thousands of other hedge funds decided *not* to buy that stock at $30, if they thought it was a good ...

"The decisions we would make if we knew more, thought faster, and were more the people we wished we were," goes the 'extrapolated volition' version of reflective equilibrium. But if a human is a big bundle of conflicting desires, experienced with different strengths and different times, then by listening to someone's voice about what they 'wished they were', aren't you just listening to one coalition of parts instead of the whole, as that coalition describes how it wishes it ...

Is it just me, or is the indignation about Ferguson very... polite, subdued, and ineffective compared to indignation as experienced in previous generations?  The failure-to-prosecute shocked me, and I would have expected far greater outrage and a lot more riots. Rodney King, who had a prior conviction for armed robbery, was pulled over after a high-speed chase, and beaten but not killed. Imagine if Rodney King had been shot with his hands up walking down the streat. The Los Angeles riots occurred as a result of the police officers who *nonfatally beat* King being *acquitted after a trial*. Imagine if there had been a blatant, raised-middle-finger failure to prosecute. I think there would have been marches on Washington and a *lot* of people in those marches. I got a similar sense of tremendous ineffectiveness during the Occupy fiasco, where the activists were so busy Why Our Kind Can't Cooperate-ing at each other that they couldn't state any coherent set of demands or desires or agenda. I got a sense that Wall Street and Washington were ready to listen, they'd got egg on their face and they understood that the rules of the political game might call for some concessions and certainly the appearance of careful listening, but there was nobody to listen to and nothing to concede. Maybe the Internet has made it so easy to be a horrible person on social networks that all the grownups don't want to be associated with it and when a real crisis happens there's nobody left who understands how to organize a march. That moves in a particular direction. And presents a particular set of demands. To people who potentially have the power to at least partially concede to them after negotiation. Or maybe it's just the Great Stagnation and something in the drinking water. I don't know. What I do know is that besides a remarkable lack of torchlight marches, I also haven't heard a single suggestion about specific, effective national or state-level legislation that could potentially be passed, just like the Occupy movement never presented a single demand. While we're on the subject, why is nobody asking how a mostly-black city ended up with an all-white police department in the first place?  Did an elected mayor appoint them?  How did that mayor get elected?  If some set of voters was in charge, why is nobody asking about that set of voters, and if we're just supposing a total failure of democratic control ability by those voters, why is nobody asking how their steering wheel vanished?  If voters have the ultimate power, shouldn't they bear the ultimate responsibility?  Oh, wait, I forgot, we're all supposed to (a) never say anything suggesting that voters could bear the least bit of responsibility or blame for anything (b) never notice that voters can end up pragmatically powerless if the election laws are arranged the right way.

As promised, I am linking to a video chosen by Animal Charity Evaluators as my penance for being mistaken about what most meat-eaters think and having falsely accused veg*ans of strawmanning meat-eaters. Their chosen video is a one-hour talk on Reducing Wild Animal Suffering: http://youtu.be/4aa6g1y4l8I... For those who prefer written text, they suggest http://foundational-research.org/.../importance-of-wild-anim.../ by Brian Tomasik.

Movie review:  Edge of Tomorrow is two movies one after another, and the first one is really good!

Nate Soares has an SF story. It is a good SF story.

So... any manga with Level 1 Intelligent characters, anywhere in the universe?  Generally when I ask this question, people think of attempted Level 2 Intelligent stories like Death Note or Code Geass or Liar Game. I don't expect those attempts to meet my standards, so I'm not asking for those. I just want a manga in which, whatever the other plot elements, the characters are sufficiently intelligent and self-aware that the author is forced not to throw standard plots at them because the characters would immediately solve standard plots. Or manga like Qualia of Purple where the author visibly had IQ points that shined through and they didn't screw it up completely. Intelligent manga - is it out there?

Remember, to show you are in an open relationship, carry around a pineapple.

Resurrection spells?  Cloning?  Time travel?  What exactly does the Salvation Army do these days?

Narcissism, n. A psychological disorder which leads people to think about themselves instead of you.

Brienne can't stay in Vina del Mar, Chile past Dec 15 because then it is officially summertime and the rates skyrocket. She desperately does not want to go back to a big noisy city like Santiago, but her search through Airbnb isn't turning up anything and she doesn't know where else to look. (It also turns out that her apartment, advertised as having Internet, only has Internet in a lounge downstairs, and she's had no luck getting high-GB cellular broadband without a Chilean ID and a long-term contract and she says nobody seems to have heard of tethering.)  She's now broadened her search to Uruguay and Australia and isn't having much luck there either. Brienne speaks slow Spanish and is getting better, but can't read fast enough to freely browse looking for Spanish-only rental sites, if any exist. We may be doing something wrong. Is there anyone from Chile who can say, "Sure, you can get cellular broadband without a Chilean ID, just X", or "You can find an oceanside apartment outside the tourist places if you speak some Spanish, just look on -this site- or talk to -these people-"? The overall context is that Brienne needs to be out of the Northern Hemisphere during the depths of winter on pain of severe depression, so only the Southern Hemisphere (or more equatorial places, I guess) are options. Solitude and not being in a big noisy city are very important to her productivity. Is there anyone who moves around between furnished apartments in foreign countries who can understand what we're doing wrong?  I have a feeling that the problem might be our looking on AirBNB, but we don't know what else to do. Brienne does not have a car and isn't on a budget that would allow one at the prices we've seen for rental cars. Help.

I would like to take this moment to say a word in praise of everyone who tried reading Harry Potter and the Methods of Rationality, decided that they didn't like it, and quietly stopped reading. It's like you tasted a vegetable stew, said "Bleah", and then didn't eat any more of it, suppressing your natural impulse to force yourself to finish every awful bite so that you could post to Facebook about what dreadful taste other people have. People like you upheld this civilization while it lasted, and it will be sad when you are all gone. I would write more in praise of you, but you can't stand the way I write, and I respect that.

HT Keller Scholl. This seems to me like a very nicely written paper describing what set-theory axioms you would use if you thought math mostly existed in your imagination and you wanted all the good theorems quickly via intuitively meaningful axioms.

I have invented a new form of psychotherapy I call it Cognitive Trope Therapy the way it works is that when you have a thought, you write it down... like, say "You are different from the others. Your abilities give you power but they make you less than human. You will never know their innocence... and that is why you should hate your own existence. Die. Die. Die." and then you figure out whether, if your life were a fantasy novel, this thought would be spoken by the defiant hero or heroine holding their bright sword aloft or if it would be spoken by figures wearing black robes, and saying the words in a dry, whispering voice, and they are actually ancient beings who touched the Stone of Evil and if it's the second source you don't listen I would write this up as a pop psych bestseller but it would be only two pages long maybe it's not OPTIMAL reasoning but it's better than TREATING THE NAZGUL AS YOUR MODEL OF SANITY "I'm not saying TV Tropes is right about everything," I typed into the chat window, "but right now it understands your life better than you do."

!!!  Bayes net as RPG!  With monsters!

Eliezer:  I think X. Benja:  Can you assign odds to X? Eliezer:  I was just thinking that... maybe 65%? Benja:  That seems too high because Y. Eliezer:  Can you give a concrete example of something that might torpedo X?... Benja:  Z. Eliezer:  Z?  Maaaybe... Benja:  Also W which is independent of Z. Eliezer:  If there are two possibilities, that seems convincing that there might be more and I drop to 45% probability. That's 8% that you influenced me to first-order plus 12% from my expectation that you would convince me further if we went on arguing.

This is why most taxes should be on consumption (value-added tax, luxury tax) and fixed resources (land value tax); while capital gains taxes and corporate income taxes and income tax should all be zero: *** "Did you know that our current Grand Treasurer is a dracon? And into his hoard goes the tenth part of the increase of the kingdom's treasury, to harness his greed for its management." "The tenth part of the increase?" I exclaimed, shocked down to my sandals. I couldn't ev...

I find the whole Jonathan Gruber flap - he's the MIT economist and former Obamacare architect who was recently caught on record stating that American voters are stupid and this is part of how Obamacare got passed - to be very grimdark-amusing. My best guess is that every journalist writing about Gruber also believes that American voters are stupid, but knows that you're not supposed to say so openly. All the politicians trying to exploit the gaffe also believe, in unison, that Gruber was right and voters are stupid and his mistake was being too honest. Furthermore, voters *know* that politicians believe voters are stupid - the voters have seen _House of Cards_ or similar movies or TV shows, they gave Congress a 13% approval rating, they're not completely naive about what politicians are like. The less recursion-wise journalists and politicians, I expect, are modeling voters as children indignant at the suggestion that they're stupid and being unable to take criticism, whose anger can now be exploited. I suspect the truth is more like voters being in on the conspiracy and knowing that there is a pretense that politicians are supposed to maintain in public, whatever the voters know perfectly well that politicians are saying in private. And everyone, including the voters, knows that what happens next is that Gruber gets crucified for being too honest. The Democratic politicians are facepalming over Gruber's stupidity in saying what everyone knows you shouldn't say out loud. The Republican politicians are rubbing their hands over the mistake Gruber made, which they now get to exploit in front of all the voters... who *know* that everyone in Washington believes what Gruber just said, but everyone's universal expectation that it's now time for Gruber to be crucified *makes* the crucifixion something that wins Republicans points. Basically just because the rules *say* that now the Republicans get points; and the voters are also in on the plot. So now the crucifixion is carried out, to formalize the Democratic face lost, more or less. Remember, as the crucifixion is carried out, the journalists writing about Gruber *also* think that voters are stupid. The voters reading the pundits being indignant about Jonathan Gruber *know* that 'voters are stupid' is what everyone in Washington secretly believes. They *know* the pundit thinks that Gruber's real stupidity was in getting caught. I'm not sure whether the pundits know the voters know that, since I model pundits as perhaps not being able handle much recursion. Remember that, each time you read some pundit being indignant about how terribly, terribly awful Gruber is for saying voters are stupid. And I predict that no newspaper and probably not even any blog outside this Facebook wall has said what is really going on. It's not that nobody knows, but that everyone believes that voters can't handle recursion. #gruber #grubergate #ProfessorQuirrellLaughing

Last night I dreamed that I was stuck in a Groundhog Day Loop that ended with a nuclear war that started 90 minutes after the beginning of the loop. At first I was like "THIS ISN'T FAIR EVEN BY MY STANDARDS!" Then I sighed and started figuring out how to solve it.

My poll is running 4:1 for "I eat (mammal) meat and think (mammalian) animals are sentient" vs. "I eat meat and think animals are not sentient". I honestly was not expecting that; I would have bet against that and lost. I herewith apologize to those effective animal altruists whom I accused of motivatedly misunderstanding meateaters, and in token of this apology I will post to my wall a link to one video chosen by Effective Animal Activism.

It's informal poll time!  You should answer this poll ONLY IF you eat meat from mammals (steak, bacon; chicken or fish doesn't count). The top two comments below will ask whether you think the animals you eat ARE or ARE NOT sentient / experiencing pain / have something it is like to be / have qualia. 'Like' the comment that corresponds to your answer. So that my two comments stay visible, please do not comment on this post. If you want to comment, visit https://www.facebook.com/yudkowsky/posts/10152857478194228 Thanks!

And somehow I'm the only visitor to notice this #civilizational_inadequacy

GODRIC'S HOLLOW, the anime: A highly meta and experimental anime in which each of the viewpoint characters belongs to a different genre, and sees the other characters drawn in a slightly different style to reflect this. Often different episodes cover the same events from different viewpoints, always seen in a different light each time. Featuring: LIZ as the tomboy protagonist of a male-harem anime, drawn by CLAMP.... NICK as the pastoral slice-of-life Miyazaki character. ROBBY as the shounen protagonist of a philosophy tournament. ELIEZER as a mad scientist who wanders in and out of the storyline, played for humor. BRIENNE as the warrior robot who has been assigned as a maid and bodyguard, now acquiring human feelings due to the bond between her and her master. MASON as the partying neighbor girl having wacky and dubious adventures. BRENT as the wandering ronin who has taken on Liz as his apprentice in swordsmanship.

Well said.

Trying to test my personal predictive ability, I call it now for the Amazon Echo failing. Will consider bets if there is disagreement.

This title is only a slight exaggeration. I think I would, in fact, scream and run out of the room if I saw this happen without warning, and oh, what you could have made people think in the Medieval Age. It would have set back the very development of reductionism, people would justifiably have been, "Yeah?  Explain the hell portal."

Congratulations to new-minted New Hampshire State Representative Elizabeth Edwards-Appell, who is now, so far as I know, the highest politically ranked member of our community.

Remember, remember the fifth of November, The gunpowder treason and plot. This day of rejections just after elections--- But I'll stop there before I get shot.

This is my Ketosoylent recipe. It worked for 25 pounds of weight loss over 5 months Jan-May, and then apparently stopped working. I haven't been able to restart that weight loss, but I need to make another pass soon, since I've gained back around 12 of the lost pounds since then. Suggested revisions from readers with nutritional knowledge are much solicited, ESPECIALLY if you are making your own homemade Soylent or you are actually trying out variations of the recipe. Anyone who follows the link should be able to comment. Stupid comments will be deleted. I have pre-done as much work as possible when it comes to setting up this diet, including links to all the online sources where I ordered ingredients or tools - please mark any links that no longer function. The full name of this substance is "Yudkowsky's Mildly Surprising Super Ketonic Dietary Replacement Fluid."  Slogans include "Your Alternative To Healthy Eating" and "It's Not Amazing, Just Mildly Surprising" and "Would You Believe That Eliezer Yudkowsky Actually Had To Take The Time To Research And Create This Stuff I Mean Really Talk About Civilizational Inadequacy".

Obvious, but well worth saying aloud. Just remember, your inner mob is composed of chimpanzees, not hominids.

Okay, pro-tip to everyone on Facebook asking "Why didn't any trick-or-treaters visit my house?"  Trick-or-treaters don't check random houses. Even little humans are smart foragers. They check doors with glowing pumpkins or some other visible sign of having treats. I know humans usually fail to solve all sorts of cognitive problems but our brains are GOOD at figuring out which visual signs correlate to gatherable food.

http://yudkowsky.tumblr.com/writing/thoughtful-responses Every Level 1 Intelligent character wants to toss your precious plot out the window and will seize any available chance to do so. You must craft their situations so that their optimizing responses drive the plot in the direction it needs to go. If they must make mistakes, have them be intelligent mistakes; ideally, have the reader not see it either on a first read-through. Discussion: https://www.facebook.com/groups/674486385982694/permalink/674565485974784/

http://yudkowsky.tumblr.com/writing/empathyrespect You can't write an intelligent character without putting yourself in their shoes and imagining yourself in their place, which is empathy; and you may have trouble empathizing with a character that you don't respect enough, or whose status you want to lower. Two obvious tricks for writing intelligent characters, then, are (first) to actually imagine yourself in their place, and (second) to start with a character template based on some real or fictional person who you respect. Discussion: http://www.facebook.com/groups/674486385982694/permalink/674544739310192/

I've been trying to come up with a good medium for publishing relatively longer-form essays. I am going to try a Facebook group, so that people can subscribe even if they don't want to see all the personal snippets on my Facebook wall. "Yudkowsky's Short Guide to Intelligent Characters" is the first thing I'll be posting, and this is the first section thereof. The larger group is here:  https://www.facebook.com/groups/674486385982694/

That is a pretty impressive hack. Apparently some countries will just give you a PhD-level university education in English for free, including Finland and Germany. Maybe they've recognized the importance of attracting Munchkins to their country.

I'm going to start explaining to certain effective altruists that just like they believe in the A-theory of time (aka presentism) which says that future people aren't real yet so we shouldn't be primarily concerned with them (or should discount their value on an exponential discount rate), I personally happen to believe in the corresponding A-theory of space. 'Here' is the most real place, just like 'now' is the most real time, and then as we move spatially away from 'here' ...the degree of realness diminishes along an exponential discount rate,  By the time we get to Africa, it's far enough from here that it's not very real. Clearly, this is already what most people believe, judging by how they act; and I think this widespread A-theory of space is *every bit* as respectable for effective altruists to endorse as the A-theory of time. So while it's true that people in the far future aren't nearly as real as current people, it's also true that people in Africa aren't nearly as real as people 10 meters away from me, leaving me with no net reason to favor global poverty reduction over existential risk reduction. As for the notion that the humans in Africa have their own notion of 'here' which is every bit as valid as mine, that's seems as shaky as the idea that the people who exist in C.E. 1,000,000,000 have their own 'now' that's every bit as real as ours. There's nothing wrong with provisionally not acting on an exotic theory like that, if you want to be a little less weird and a little more confident that what you're doing makes sense.

Does anyone else have that massive trauma where they were severely hurt during childhood by people saying "I understand" and "I feel your pain" and "I am so, so sympathetic to you" and the rest of the standardly-advised patter, while not doing anything to solve the problem?  Because people who actually want me to say that to them feel very alien to me, given my childhood trauma; and I literally can't make my lips speak those words to anyone else. To this day it seems impossible for me to imagine the tone of those words sounding like anything but a dismissal and a lie---I hear people telling me that they want me to say these things, and even so I can't imagine what it feels like to hear them on the other end. It exceeds my power of literary imagination, which is why nobody in HPMOR ever nods warmly and says "I understand". Does anyone else feel like that?

I am currently 42% through a Lawrence Watt-Evans book and I have absolutely no idea what is going to happen. He just uses intelligent characters instead of plots and lets them run free. Maybe one of them will start a war with the Wizard's Guild and destroy a country and maybe not. I doubt the author himself knew at this point in the story. His characters are just allowed to do whatever seems to them like a good idea. I bleeping love Watt-Evans books.

Best illustration photo ever. (Well, of the last week, anyway.)

James Harrison had the best moral luck I've ever heard of in history, enabling his over 1000 blood donations to protect over a million babies and allowing him to become a tremendous hero from making only completely straightforward choices. Yet I can't even say it fell into his lap, because it was discovered as a result of his childhood resolution to become a frequent blood donor, before he knew anything about his rare antibody. My hat is off to him. HT Tilia. 

Are there any notable econoliterate libertarians who oppose all of the Basic Income, the Negative Income Tax, the elimination of taxes on the bottom third, raising phase-out of benefits to above the bottom third, etcetera?  Is it a fair statement to say that every libertarian-leaning economist is concerned with implied high marginal tax rates on the bottom third?  Is there any respectable libertarian economist who has advocated eliminating welfare without also saying something about eliminating the income tax and payroll taxes on the bottom third?  Am I living in a tiny sheltered bubble of libertarian economists who care, or are the econblogs I read reasonably representative of modern trends among respectable libertarian-leaning economists?  (Austrians, goldbugs, people who predicted hyperinflation due to QE, etcetera don't count as respectable.)

My design for the world's most depressing T-Shirt would say "EVEN THE TINY POTATO HAS STOPPED BELIEVING IN YOU" and have a picture of the tiny potato, looking sad. Or maybe just a plate of french fries, that would also work.

Overheard at MIRI: Benja:  "I guess we do want to think of this [proposed decision rule for Oracles] as optimizing for impossible possible universes." Eliezer:  "But who among us can say that they've never optimized a logically impossible world that they know they'll never get to experience?  Let them cast the first stone." Benja:  "Actually, I think only Nick Bostrom can say he *has* done that."... Eliezer:  "EVERYONE THROW STONES AT BOSTROM!" (Context on Bostrom:  http://lesswrong.com/.../you_have_just_been_counterfact.../ao4m...)

Interesting question. I have two answers but they both seem relatively boring.

Surprisingly insightful!

Yikes. The hell happened to the elite?

For the last week, I've been trying to practice 15 minutes of high-speed writing on a daily basis. My brain was very resistant to "just writing at a high speed with low standards" and expected it to be super painful, but I managed to get it to do successfully by telling my brain that the form of the writing exercise was to spend at least 1000 characters describing a place, followed by at least 1000 characters describing a person inside the place, which works out to around 15...

Guy on the street just asked if he could have a piece of my chocolate cookie. I was like "Sure" and started to break it off and he was like "No, it's okay!" and wouldn't take it. Doesn't seem likely a priori but I wonder if he was trying rejection therapy.

Whether Bryne of Overstock.com succeeds in this attempt or not, it's coming eventually and it will be huge. I so predict.

In the final chapters of HPMOR, Fred and George Weasley will uncover the hidden entrance to Godric Gryffindor's Chamber of Courage, within which dwells the Courage Wolf. What is your probability estimate that the above sentence is a joke?  If two commenters have sufficiently divergent estimates, you might want to make a bet on that.

What are the good books on Kindle Unlimited?  Any recommendations?  From what I've browsed so far I'll mention "Nice Dragons Finish Last" by Rachel Aaron and "The Shadow of What Was Lost" by James Islington.

After a writing exercise, my brain suggested a Robin Hanson-ian magical system would consist of foolish and irrational spirits all intensely engaged in signalling to each other, and magic consists of getting them to do unusual useful things by setting up clever systems or incentives. When an enemy sorcerer attacks you, your spirits and their spirits will start composing screaming chants about how bad the other side's spirits are.

Level Zero skill:  When you make a mistake, rather than rehearsing the action you wish you'd taken, rehearse the plausible thought process that you wish had led up to that action. Like, if I fail to notice confusion, I imagine what it would have felt like at the time to notice the small note of discord, promote it to my attention, and reason about it using general heuristics that would have led to the right conclusion. Basically you want to visualize what it would have felt like, experientially, to be the nearest person to you who would have avoided that mistake using general thought processes and without any advance foreknowledge.

If I understand correctly, this is remote code execution via anything that can pass any environment variable to bash. All sysadmins, drop everything and patch. Vulnerability test:  env x='() { :;}; echo vulnerable' bash -c "echo this is a test"... 

Does anyone happen to know what the sex ratio among 30-year-olds was like among ancestral hunter-gatherers?  How did the balance between death in childbirth and death by violence work out?

Rational _Atlas Shrugged_ plot outline: Dagny Taggart as an alternate Google cofounder, who's been pushing hard on robotic cars in order to reduce traffic accidents. Hank Rearden is an alternate Tesla cofounder, trying to produce electric cars to reduce carbon footprints (he's not building rockets because Elon Musk is too powerful a character for this story)....

If you set your own prices for a service, always charge the *least* price that makes you feel genuinely excited and happy to get one new customer, including e.g. happiness because it is enough after-tax money to buy a nice thing (this is the algorithm I already used to decide that it costs $2000 for a day of my time, not including any required travel). As you make more trades, this price rises naturally as you need less marginal money.

Any rationality fans from Uruguay?  My S.O., Brienne, may go to Uruguay for 4 months for the winter, and could use local help in getting set up, particularly finding a place to live that isn't at American-tourist prices but nonetheless lacks spiders. She doesn't not speak Spanish, but isn't fluent either, and expects she can get along fine---it's mainly the early setup that she's worried about. Brienne strongly prefers to live outside the city, in a small town or other uncrowded area.

It's not that I expect being dead to hurt, but it's the ultimate opportunity cost. (H/t James Hudson.)

Epistemic Guess Culture is when you're only supposed to articulate a belief if you expect the person you're talking to agrees with it; if they don't, they become very uncomfortable about not agreeing with it. Epistemic Ask Culture is when it's okay to articulate a belief someone else might disagree with, expecting that, if they do, they will say so. Just like in Ask Culture it has to be okay to say 'No' at any time, in Epistemic Ask Culture it has to be acceptable to say 'My System 1 makes me feel like there's something vaguely wrong with that statement, but I don't know what, and can't tell you."  If it's not okay to say that, because you have to be able to justify your disagreement, then the person talking to you has to *guess* whether the belief they're articulating will make you feel a vague sense of disagreement, and *avoid* saying beliefs like that, because then you'll feel uncomfortable but not have anything you're allowed to say about your sense of discomfort. So then you have an Epistemic Guess Culture again.

Some idiot on Tumblr is claiming that Eliezer Yudkowsky has said that "transgender people never pass". I literally cannot think of one thing I have ever said in my life that could even be misinterpreted this way. I AM BLOODY FACEBLIND AND I CAN'T EVEN TELL... never mind I don't dare finish this sentence because some idiot on Tumblr will claim that I'm implying that all nonfaceblind people have perfect trans detectors or something HOW IS TRANS DETECTABILITY EVEN SOME KIND OF HOTBUTTON DEBATE IN THE FIRST PLACE THERE IS NO CONCEIVABLE MORAL ISSUE THAT DEPENDS ON WHETHER THAT IS TRUE never mind I don't want to know Slate Star Codex will tell me if there's something here that sane people need to know about  Please be on notice that idiots on Tumblr are now making up 100% fabricated false Eliezer Yudkowsky quotes out of thin air, and apply the same skepticism to weird things Eliezer Yudkowsky has allegedly said that you would apply to an Albert Einstein quote about Buddha. AND FOR THE RECORD IF THE CONCEPT OF TRANSNESS IS PHYSICALLY MEANINGFUL THEN IT IS IN PRINCIPLE EXPERIMENTALLY DETECTABLE THERE NOW TUMBLR CAN CRUCIFY ME but I take no position one way or the other on that "if" until Scott tells me what the right answer is

North Carolina's sky is definitely, I am confident of this, 4 times as large as the sky over Berkeley. Like you could take 2 Berkeley skies side by side and they would just about stretch from one North Carolina horizon to the other. I do not know how this can be so, but it is. I shall be seeing 8 local HPMOR fans in one hour at Branciforte's in North Wilkesboro. Looking forward to it!  Also it is awesome that at least 8 people in driving range of a random cabin in the middle of nowhere are reading the HPMOR Progress Reports and can show up on 33 hours' notice.

Obviously, the cerebellum must be part of the 90% of the brain that nobody uses, right?

"Lucy's account of her experience is emblematic of what investigators say happened during a 16-year reign of terror and impunity in this poor northern English town of 257,000, where at least 1,400 children, some as young as 11, were groomed for sexual exploitation while the authorities looked the other way. One girl told investigators that gang rape was part of growing up in her neighborhood. Between 1997 and 2013, despite numerous reports of sexual abuse, only one case, involving three teenage girls, was prosecuted, and five men were sent to jail, according to an official report into the sexual exploitation of children in Rotherham published last week." #civilizational_inadequacy doesn't seem to cover it.

See, now this is the sort of way you would expect real beisutsukai to be training themselves.

48 Laws of Sanity, #14: If you didn't predict the mistake in advance and it's the first time you've made a mistake like that, it is a cost of doing business. Be patient and don't expect things to go right on the first try. If you make the same mistake twice in a row *then* start beating yourself up. If you are tempted to beat yourself up on the *first* repetition then go read papers about hindsight bias, including the part about how hindsight changes what we think were the... "obvious" factors we should have paid attention to, until you understand on an emotional level how in real life you can't actually see bullets like that coming. I mean, if you can predict it, you should evade, because you *will* be justified in beating yourself up if you actually saw it coming (not just "should have" seen it coming) and didn't try to avoid the mistake. But if you didn't see it coming and it's the first time?  Then that's just a cost of doing business in reality, and you really will drive yourself crazy if you try to think otherwise.

The fresh triumph of honesty over social desirability bias is often worth reposting, and I haven't read this one before. Like many modern-day econoliterates I favor the Basic Income.

Brienne is not a fan of Umesh's Principle "If you've never missed a flight, you're spending too much time in airports."  We got here 37 minutes before boarding even started and she's like "But that only happened because everything went right. What if something had gone wrong?" and I'm like "Then it would have used up some of those minutes" and she's like "But then we would have had to rush!" I don't think she agrees with my theory that nothing has really "gone wrong" on a trip until someone gets hospitalized.

Valuable info!  I'd noticed before that depression seemed directly related to how much time people spent talking about the past, and that successful Prozac caused one person to suddenly just stop talking about their past, but the added clue about exactly what type of recall seems to be associated with PTSD is fascinating.

Gooood question.  Definitely another worthy anthropic dilemma. I'm currently leaning toward keeping the measure of an observer-instant as objective but saying that which futures are 'you' might end up having to be encoded in the utility function, sigh. So you couldn't increase the measure of people like yourself winning the lottery by an act of redefinition or a new choice of prior, but you could have a utility function that cared about fewer of them in the selfishness term, without that changing the objective measure of any observer-moments.

Overheard at MIRI:  "Your idea is very inspiring. It inspires me to search for better alternatives."

Everyone in Napa:  I hope you're all right, and remember, they don't get earthquakes in Uruguay.

Brienne is considering places to stay the winter to avoid S.A.D. and Uruguay, one of the suggestions, looks so good that I'm wondering if it would be a good place to move MIRI and create a rationalist startup hub and/or mathematical monastery. Immigration requirements look actually sane. Does anyone know a good reason why that shouldn't happen?

Okay, this was still horrible enough to surprise me. $321 in fines and 3 arrest warrants *per household*. http://marginalrevolution.com/.../ferguson-and-the-debtors-pr...

My mother's mother, before leaving on a brief taxi trip: "I'm going to go to the washroom first." My mother:  "You can't go there first, Eli just got out. You can only go there next." Both sides of the family...

My father's cousin:  So that is your [sports] car out there? My father: Of course it's my car. Cousin:  Why'd you get that?... Father:  I stole it. Cousin:  Stole it? Father:  You know, sometimes people just leave cars around... This is where I learned my way of answering questions when, you know, the normal sort of conversation I extrapolate happening by default would be too boring.

"Why can't my life pick something, call it normal, and STICK TO IT?-!-?-!-?-!-?" --Ilyasviel von Einzbern, magical girl, after her time-traveling daughter showed up (not canon) In my case I think the answer is "Because I have goals and the optimal route to them never sticks to any particular domain."

I just spoke to Heather, an eight-year-old who read Harry Potter at age five, and is now reading HPMOR. Her eyes became very wide when I was introduced as the author. Also she's read Godel, Escher, Bach. I look forward to great things from her when she is older---say, age sixteen or so.

Cheat codes for writing, concept h/t Glenn Davis: There is no writer's block, there is only holding yourself to too high a standard. Start in the middle of the action.... Leave out all the boring parts; you will be truly amazed at how much you can get away with ignoring or collapsing to one sentence the long transitions you think are 'necessary'. Write an existing character that you love, and give them a different name; your writing style will make them your own and nobody will know the difference. To get an intelligent character, make someone who you respect too much to see them be stupid, then give them a problem that even they will find difficult. Try to write the least story that contains the plot (Ben Hoffman), so you aren't ashamed of not doing justice to the plot. If you don't know how to end a scene, end it in disaster. Write fanfiction.

The part of me that runs Professor Quirrell is grimly amused by how people get all indignant on Facebook when police abuse journalists. I mean, just for a start, it's journalists who decide that this is surprising important news, and going along with that blindly seems a bit... manipulable. But that's only the start. If you'll pardon a brief lecture from a mixture of me and Professor Quirrell:  Journalists have status because they have unchecked power, manifested in the abil...

I've noticed that in our community, which seems to have a lot of non-neurotypical people, there seem to be a number of us with freakishly exaggerated face-recognition abilities. Like, after being introduced to someone only three times, they can see that person at a party the next week and just know their name, on the spot. They can recognize other people by facial information alone, even after those people have changed their dress style or haircuts. Just a single hour of exposure can be enough for them to learn a face. I'm wondering what could account for this tremendously exaggerated face-recognition ability, and whether it correlates with intelligence or rationality in any more specific way than generic non-neurotypicalness. (I do not have this particular cognitive quirk myself.)

Sometimes I do feel a little shounen. Thought/proposal:  Try to very quickly write a bestselling thriller novel using what may plausibly be my above-average literary skills and not putting in the same amount of complexity or polish as HPMOR. Brain's reaction:  "Editor gatekeepers may not let you through. Do you really know what the thriller audience wants?  Can you really lower your standards enough to write that fast?  Would your literary ability really carry over?"... Thought/proposal:  Try to write a bestselling thriller novel with the title _Graafiznablufamperpants_. Brain's reaction:  "Okay, that sounds weird and difficult enough to be interesting."

In the Infinite Counterfactual Newcomb's Problem, Omega flips a fair coin until it comes up tails, then shows you the number of times the coin was flipped. Call this number N. Omega has put a million dollars in Box B if and only if Omega predicted you would take only Box B if the coin had been flipped N+1 times. (Aside from that, the setup is as in the standard Newcomb's Problem: Box A is transparent and contains a thousand dollars; Box B is opaque and contains a million dollars or nothing; you can either take both boxes or take only Box B; if you try to randomize by flipping a coin, or take too long to make a decision, you will be run over by a trolley; etcetera.) The correct choice is of course to take only Box B [EDIT: for N > 1]. That was simple, wasn't it?

Someone recently asked me, regarding P-Zombies and my strong confidence that consciousness is not epiphenomenal because it causes philosophers to write papers about consciousness--- (see e.g. http://wiki.lesswrong.com/wiki/Zombies_(sequence) ) ---the question, "Why do you think you should trust your judgment on that question over the judgment of similarly qualified people?  I don't get it."...

I just realized I'm not sure I've ever written this down, so: In a Traditional Rationalist upbringing (you grew up in a science-literate, Sagan-and-Feynman family) you learn that to learn well and be a good person, you shouldn't take things on authority. Even if someone you respect says a thing, but you can't see why it's true or it doesn't seem well-justified, you need to go on questioning them skeptically until the belief seems well-justified. "I can't believe in General ...

I learned my gut-level understanding of Transparency Illusion by watching my readers come up with brilliant misunderstandings of HPMOR, that had never occurred to me as possible alternative interpretations because I suffered from the handicap of already knowing what I meant. The key point here is that some of the alternate interpretations of my writing were blatantly respectable and smart. This is too rarely the visible case with other people misunderstanding us. In some cases, like when people asked "Why does Harry assume so quickly in Ch. 23 that there's a real phenomenon to be explained with respect to intergenerational decline in magical power?", they were just plain right, and I'd missed it because my own knowledge of the background answer "The answer is the Interdict of Merlin is causing knowledge loss for powerful spells" led me to neglect valid possibilities. (Harry does have evidence, which he thinks about---people mentioning that Hogwarts, the Sorting Hat, and the Invisibility Cloak can no longer be made, even though they continue to function---but that's not sufficiently strong evidence given the number of cultures which have falsely believed that everything was declining, and that Harry has been told the non-reproducibility only by other people who might be buying into the fallacy.) And that experience mattered a lot to my System 1 finally getting it. Usually, when you're misunderstood, there's some attempt to interpret the people not getting what you mean as cognitively disadvantaged, to think that the meaning was there but missed. But Harry not considering enough that society's magical power might not even be declining in the first place, was clearly a valid possibility *I* had missed. So it taught me that Illusion of Transparency isn't about hint-missing, it's about there really actually respectably being multiple interpretations. And that was when I started to understand that my words were really actually not pinning down the meaning I had in my own mind, because I couldn't see all the possibilities I needed to exclude, because I was blinded by my own knowledge of the intended answer. And that is how writing a novel where I knew the correct answer, and other people had to figure out the clues I thought ought to pin down that answer, and their wrong answers being sometimes unexcluded and brilliant, taught me about Transparency Illusion on a very gut level.

There Is No Great Stagnation:  Actually, since 1795 C.E. up until now, our civilization has been incapable of digging 140 feet downward. This level of inadequacy is not a recent development. And if there's actually no treasure down there, then whoever set it up was perhaps the most successful troll of all human history. #civilizational_inadequacy Michael Vassar

Holden:  "If you give all your charity in one place, it forces you to really think about it and take the decision seriously."  This is a reason beyond standard expected utility arguments to donate to a single target, which I had not previously thought of. Seems obvious in retrospect, giving everywhere can be a kind of mental laziness or mental out. #easummit

I wish I had been able to see other presenters' talks at the Effective Altruism Summit before doing mine. I would have spent a lot more time on methodology and epistemology, and not "MIRI's Plan" which is the talk title I was given. Maybe talked about lessons learned from founding MIRI.

Geoff Anders:  "We need signs other than correctness to tell if we should look closer [at an idea]." Your internal cue for whether to consider an idea more deeply cannot just be surface probability; then you never check surface-implausible ideas to get any sort of feedback on which are right. With practice, some of my investigation cues started to feel like plausibility cues. But I'm not sure Geoff's point ever becomes truly obsolete.

Well said.

Stellar, a new cryptocurrency and distributed payment network, made by the founder of Ripple, just launched. You can support MIRI for free by signing up. Every new Stellar user gets 6000 STR, and can send an additional 1000 STR to another user for free. Our Stellar username is "miri".

Okay, I'm turning into Scott Alexander as I say this, but I'm going to try to steelperson the Projective Inverse Nirvana Fallacy. The Projective Inverse Nirvana Fallacy---let me know if it has a more standard name---is as follows: "Eating a 5-year-old's nose is bad. Eating a whole 5-year-old is worse. This doesn't mean it's okay to eat a 5-year-old's nose."...

To countersignal, the audience must first know that you have at least a medium score in the characteristic!  This is a key element of countersignaling that I was missing earlier and explains a lot about people who fail to pick up that HPMOR is deliberately plainspoken, not showing off. Hm. Now I wonder if I should actually go in and put the references into the first ten chapters just to reduce some of the more clueless status-sniping. It would be a bit sad but perhaps effective, and those chapters don't have strong momentum to disrupt.

The concept of "mandatory reporting" on sexual assault seems REEAALLY scuzzy. Like I'm not sure I actually buy that this is stupidity rather than malice. Let's take the case of a student who has been sexually assaulted at a university, and a professor who is a mandatory reporter of sexual assaults. A law plausibly intended to help, a law I can imagine was originally honestly intended to help, might say, "If the student wishes to report an issue, you as her professor are mandated to help her through the process if she wants."  Instead the law strictly removes an option the student otherwise had to discuss things privately with a trusted professor. The law says, "You MAY NOT tell any professor, social worker, or other person with any power or authority or influence who might help you, nor is anyone else allowed to consult them, UNLESS you are already certain that you want to make a formal complaint with everything that implies, including the accused learning who you are and that you are acting against them."  I get the impression that there are in fact people who would do the equivalent of realize this, chuckle, rub their hands together in glee, and set out to deprive the students of help. Am I being paranoid or overestimating the cleverness of regulators?  For that matter, am I missing some hidden rationale that causes this to make sense?  Or is my impression accurate that we should all add "mandatory reporting" to our list of extremely evil laws that were plausibly passed by specifically evil people with regulatory capture?  What kind of coalition is holding this in place?  Who actually supports this, or who would oppose if someone tried a push to outlaw "mandatory reporting" requirements at a state or federal level?  Naively I would think you could collect a lot of endorsements very fast. #civilizational_inadequacy EDIT:  Jim Syler has provided a plausible explanation!  The ones who have both the power and the incentive to do this are university presidents, as follows: It guarantees that when an incident occurs, the university president can either say that the university had no knowledge, or pass blame down to whoever knew but protected the victim's identity. Removing all decision-making options from the process isn't there to deliberately harm students, it's there to ensure that the high-level bureaucrats can never be accused of knowing anything (can always claim ignorance).

Sure, *you* benefit socially from not telling people when you wish they were dead. But the fact that everyone reasons that way means that depressed people do, in fact, live in a world where if all their friends secretly wished they were dead, those friends would in fact not say so. If we were only more frank about telling each other when we wished that they would die, depressed people would know---for a solid fact---that their friends didn't secretly wish them dead. Depressed people are the ones who suffer for your social convenience!  The Law of Unintended Consequences strikes again! ...now I'm visualizing a village in an alternate universe where a mother is carefully explaining to her child that, yes, you must always tell people when you hate them, even though that may be inconvenient for you, because otherwise nobody will ever be able to be sure that they aren't hated, and that would be terrible. I don't actually want to live there, mind, because trolls. Like what we're ultimately describing here is 4chan. But it's kind of interesting and deranged to contemplate what a society that tried to maintain trustworthy, strongly distinguishing social signals would be like.

What I think when I hear about Heifer International, a charity that purports to give cows to poor families:  Are they just buying the cows on local markets?  Then doesn't that mean somebody else doesn't get a cow?  Is the theory here that existing cows are poorly distributed and Heifer knows how to distribute them better?  Is the actual mode of action that the price of cows increases enough to increase the supply of cows, and that not enough resources in these countries are currently being spent on cows?  Is the primary mode of benefit through increasing the amount of foreign exchange available to these countries? What Givewell thought:  Why are you assuming that a cow is the best thing money can buy?  Don't you need to overcome a burden of proof with respect to why you're giving them a cow instead of just giving them money?  Don't these programs come with all the possible problems of cash transfer programs, plus additional concerns having to do with livestock and whether the recipients are ready to take care of the livestock?  Are you checking for any of those problems the way cash transfer programs do?  (original: http://blog.givewell.org/.../gifts-of-livestock-eg-heifer-in.../) What I think the average donors to Heifer International are thinking---actually I'm not going to write it, you can probably figure it out. What the Bill and Melinda Gates foundation was thinking when they recently gave Heifer another $25M, on top of several earlier grants:  ???

I am reading Allie Bosh's _Hyperbole and a Half_ in book form. Going on the absolutely precise, insightful, concrete yet correctly abstracted description of all the things the main character does wrong, it is clear the author is a master rationalist. *I* had not abstracted some of these failure modes and would still occasionally do some of that, which I will now attempt to stop. So this author, describing this silly character, is a good enough rationalist to school Eliezer Yudkowsky. The book is autobiographical. I notice I am confused.

"I said the narrative arts put us in the minds of other people. So does standing right next to another human being. But let's say that instead I had been spending the past hour chatting with the 5 people who were chained to the track and endangered by an oncoming trolley. They've told me all about their spouses and children, their goals in life. I look to the distance and see a platform where one guy is contemplating pushing a fat man to save the 5 people I've just been speaking with. What is my moral intuition then?" -- Scott Sumner http://econlog.econlib.org/archiv.../.../07/i_hurt_therefor.html

Does anyone know what it means if my brain says it wants to eat spicy or crispy things?  I ask because my current diet is ketosoylent and my brain often pings me for "Spicy thing!" but I don't know what that actually translates into. I.e., "Eat very crunchy things, like an icecube!" might mean I was low on iron, but I don't know what "Eat crispy spicy things!" means. In particular my brain is visualizing bacon, and doesn't think that salmon or ice cream or a protein bar is ...an acceptable substitute for whatever it wants, but would consider a steak especially if it were crispy. If fed sushi, my brain would want the sushi to come with a spicy dip and be heavily dipped. Again, these are my brain's taste preferences, not nutritional preferences. I'm trying to figure out what the implied nutritional preference is so I can feed it without actually using bacon.

I was really expecting at least one of these words to not have its usual meaning.

New chapter of HPMOR at http://hpmor.com/chapter/102. I don't know why, but fanfiction.net hasn't sent out update emails yet. Nonetheless, it's live. Enjoy!  Warning, there may be spoilers in comments below, so read the chapter before looking at any Facebook comments (I strongly suggest). Trouble remembering what's going on?  I suggest starting at http://hpmor.com/chapter/100.

What rationality or cogsci-related phrases would make sufficiently good thriller book titles?  So far I have: _Evidence of Absence_ _Cromwell's Rule_... It's hard to find ones that sound genuinely realistic for a bestseller list, but I think those two qualify.

I was just browsing Hacker News, and somebody called the Ethereum currency (one of the first genuinely different successors to Bitcoin, in which ether pays for arbitrary computing services) a "cult". So here's my bad idea of the week:  Let's just call everything we don't like a cult, and see how far we can spread the habit on Tumblr. If the Internet calls everything that exists a cult, people will be used to hearing themselves called a "cult" for the crime of voting Democratic or eating meat, and distrust it when others are called a cult; the word will become meaningless through sheer overuse and people will be allowed to be odd again, since the English language will no longer have a handy derogation that means "weird people" as opposed to generically "people I don't like". I mean, English will still have words like "weirdo" but it won't come with the scare-factor of "cult" whereby all weirdos are tarred with the brush of Scientologists.

Xposted w/ edits from a comment on Effective Altruism, asking who or what I cared about: I think that I care about things that would, in your native mental ontology, be imagined as having a sort of tangible red-experience or green-experience, and I prefer such beings not to have pain-experiences. Happiness I value highly is more complicated. However, my theory of mind also says that the naive theory of mind is very wrong, and suggests that a pig does *not* have a more-simpli...

I just read online:  The actor playing Darth Maul is a real martial artist (staff fighter) whose stance, balance, and movement makes the other fighters look amateurish by comparison. Rewatched this: https://www.youtube.com/watch?v=Oh4l39Lo194 Now I'm feeling insecure in my masculinity because I did not notice this earlier. It seems really blatant as soon as you're told to look for it---Qui Gon and Obi Wan should've been dead almost immediately if they were that outclassed. ...They're like big wobbly blobs compared to Darth Maul's compact, precise mass. I suppose I was looking at the shiny things instead of watching stances and balance. Despite some preliminary Googling I still can't find any good analysis of how fighting with an inertialess instakill sword should actually work, beyond the obvious "For God's sake, don't bother spinning."

I have a dream that someday, two people having a loud, heated, public argument will be surrounded by spectators yelling "Bet!  Bet!  Bet!  Bet!"

When I think of the Great Stagnation I think of the FDA destroying drug development to the point where we have exploding obesity; the degradation of many sciences to the point where dieticians can't solve obesity; the fact that math papers from 1960 seem far more readable and friendly despite, or maybe because of, not having access to LaTeX; I think of university systems dying amid exploding student debt; I think of declining real median income in an environment of rising rents and healthcare costs and the aforesaid student debt; I think of barriers to entry and everyone suing everyone else and all the other forces that have driven innovation into bits because innovation in atoms is somehow a lot less profitable; I think of coal plants in the places where liquid fluoride thorium reactors should be; I think of slums that weren't still supposed to be there, and maybe wouldn't be there if things had improved for the bottom 20% in Western countries at the same rate they did between 1930 and 1970. I don't think of flying cars or Mars, but the fact that I think of these other things does make me sympathetic to the picture. The great improvement since 1969 is China and all the low-tech places rising up to become medium-tech. But that doesn't exactly refute Great Stagnation when you think about it. It might be for the best. Faster economic growth in First World countries could just shorten AGI timelines.

By request, a repost of the improved versions. There was no room for flavor text on the first card, but if there were, it would be: "I saw the gods in all their terrible glory, and I saw the thing that ate them like popcorn."

Me:  <sad> Brienne:  Would it help if I took my shirt off? Me:  Usually, yes. On this particular occasion, probably not. Brienne:  Will it hurt? Me:  No.... Brienne:  I'll take my shirt off. It won't hurt and could possibly help. Me:  I admire your expected utility calculation (pause) as well as your breasts. Brienne:  Awww, that's so sweet.

I didn't like the last versions of these I saw on Facebook, so I made my own.

It's amazing how fresh one's writing can become when you question whether something that is Designated Evil doesn't actually have to be. (People thinking themselves to question Good usually just end up as mere cynics, with not much I find interesting to say about it.)

People ask "How can I change myself?"  If they asked "What do I expect would change me?" I expect their brains would produce entirely different answers.

What is the best economics textbook for a smart person who likes math with symbols, but hasn't taken calculus, and who presently has almost no physical intuition for anything monetary?  The purpose is "actually understand human society" rather than "pass college exams". I tried giving them Mankiw's "Principles of Microeconomics" which was the most common online recommendation, but they had a reaction I interpreted as "Yuck, low-density text, where are my math symbols". I'm looking for something more compressed that still presents all the core quantitative intuitions (supply-demand curve intersection, equilibrium and adjustment, hidden hand, Nash equilibrium != Pareto optimum, tragedy of the commons, etcetera) to a reader who's never heard of them before, meaning that there are clear diagrams and so on. Any ideas?

Suppose an ideal spherical planet, covered in frictionless fluid. It is orbited by an ideal moon, which creates tides in the fluid. Left to itself, this system will continue forever. Now suppose that you install, perfectly anchored to the planet's surface, a floating bob attached to a lever. As tides go by, the bob and the lever rise and fall. This small motion in turn powers an electric generator, which lights a small LED. The power to light the LED must come from somewhere. By Conservation of Energy, adding this bob must somehow eventually cause the moon to crash into the planet. Before looking at the comments, how do you think that happens?

1)  Think of a cherished, difficult, but realistic goal. 2)  Look at the clock on your computer. 3)  Someone puts a gun to your head and will shoot you---or obliterate Earth, whichever of these two events your System 1 cares about more---unless you can increase the probability of this goal being fulfilled by 1% in the next five minutes.... Did you think of anything before the clock was up?

I'm starting to feel very worried about our planet's Internet. Was it always this pit of endless hate?  Was it like this even four years ago?  It seems to me that the trolls are getting worse, that the average tone of comments keeps getting darker and darker, that there's a downward spiral of hate and I wonder what it will be like by 2024. Maybe my memory is rose-colored, maybe a wider audience has *heard* about me now and that's why I'm exposed to more of it. And yet it really seems to me that things are getting very grim. I imagine children trying to build an online presence on this Internet, and I imagine that by the time they're 15 they're living in a mental world where everyone online hates them for everything they do, all the time; while the people they knew in real life were still smiling... if any of their fellow 15-year-olds can still smile by then, if the culture of 4chan's worst parts hasn't already taken over the hallways of public schools and the Internet's actual successor to 4chan is even worse. People see themselves surrounded by hate, and it shifts the Overton window for what counts as being nice, and meanwhile there's10%? 25%? a growing percentage? that tries to outdo the other haters in order to get noticed. I don't know. I don't feel like I have a good grasp on what's happening. Maybe I'm turning into an old fogey yelling at the kids to get off my lawn. But to me it seems like there's a downward spiral and it's spiraling very fast.

There's an experimental technology a friend of mine is considering using---ovarian tissue cryopreservation. (Sample link:  http://www.asrm.org/.../OvarianTissueCryoprservation2014-nopr...) The advantages over traditional cryopreservation of eggs or embryos are that (1) it's faster, cheaper and safer because the user doesn't need to take hormones for a month to get her ovaries to produce more eggs; and (2) it preserves a lot more eggs. Since it has no waiting time, this technology can also be applied to preserve ovarian tissue by users in very bad condition, about to undergo chemotherapy, etcetera. The problem is that this is a new technology and unreliable. Allegedly, in the few cases in which preserved ovarian tissue has been used, there's been a 15% success rate. My friend isn't sure that this 15% success rate is real, because she's worried about (1) selective reporting of successes and (2) confusion with natural pregnancies. I ask:  Is there anyone who knows anything about ovarian tissue, biotech, or cryopreservation of tissues, who can venture a well-calibrated informed opinion on whether, if ovarian tissue is preserved *now*, it's likely that the technology will have improved enough in another 10 years to make it >50% reliable for IVF?  Or whether the currently reported 15% success rate is real?  Real life decision coming up fast.

What the bleeping bleep

_Superintelligence_ #1 in Amazon's Computer Science Study Books.

I am suddenly alarmed by the realization that, living in a merely 3-dimensional world, my brain thinks that "convex" (in the sense of a mixture of any two points within the volume is also inside the volume) and "spiky" (in the sense of having tips that extend far out from the surface in many directions, compared to points on the surface that are near the center) are incompatible properties. This is true in 3 dimensions, but totally not true in, say, 100 dimensions, where a 100-dimensional unit cube is convex but has corners that are 5 units away from the cube's center, while the center of a cube's hyperface is only 0.5 units away from the cube's center. Now I realize that I have absolutely no idea what it feels like to look at a 100-dimensional cube using an appropriately generalized visual cortex. I used to think my visual intuitions could be generalized to N dimensions, but now I realize that my visual intuitions *have no model* in N dimensions because there are things that are both very convex and very spiky.

If anyone reading this is good at visualizing the Curse of Dimensionality, I've got a question for them. It is motivated by literary purposes rather than FAI research, but it still seems interesting to me. The Curse of Dimensionality is that higher-dimensional spaces are almost impossible to search for random points. If you take a square 1 unit on a side, and put another square 0.9 units on a side into one corner, the 0.9-wide square occupies 81% of the total area of the 1-...

I think it has become mostly pointless to speak of "libertarian economists" versus "socialist economists", because the difference between economists and non-economists has become overwhelmingly larger. A libertarian economist, moderate economist, and a socialist economist might argue whether (a) abolishing income taxes on the current lowest bracket, (b) establishing a wage subsidy, or (c) providing a universal minimum guaranteed income, would be the better way to help the bottom quintile. This difference is almost nonexistent, it is mere splitting hairs, compared to (d) the conversation between an economist and a non-economist: "Let's double the federal minimum wage to $14.50/hour!" "That might not be the best idea in a time of already-weak labor demand. Current evidence is suggesting that minimum wage increases have surprisingly low effects on unemployment, but if you literally double the price of something, employers will buy less of it -" "ARE YOU SAYING THEY DON'T DESERVE A LIVING WAGE WHY WON'T YOU SIGNAL CONCERN FOR POOR PEOPLE NOW I HATE YOU" I care much less about where we are inside a-c than I care about a-c vs. d. Maybe I should start giving my political affiliation as "Econliterate" rather than "Very-small-'l'-libertarian."

I was expecting _Secretary_ (2002) to be a lot more heated than it actually was. The main word I would use to describe this movie is "adorable". It's like the My Little Pony of BDSM. It also depicts, clearly and viscerally, a claim that human beings go completely haywire when they don't have a "role" that fits what they're trying to do. Like, if you don't know that you're a "dominant" or a "submissive", and if you don't have any cultural preconceptions that say how somebody is supposed to act if they feel the way you do... then you mostly either act on impulse or do literally nothing, don't communicate or say anything out loud about what's going on, and generally don't do anything strategic or organized or with any visible long-term goal in mind. Or so this movie would have us believe, and I think I actually find this pretty plausible. It goes a long way toward explaining why BDSM bloggers have so many posts about "the Blah acts like blah and feels blah" (often contradicting each other). I had often found this a tad odd, but this movie makes a plausible claim about what most people with BDSM impulses would be like if they did *not* have known roles to select from. Without pre-supplied roles, you just have a man who wants to spank his secretary and a secretary who wants to be spanked, staring awkwardly at each other without saying anything because they have no scripts to read from. At one point the male love interest turns cold toward the female protagonist for no previously shown good reason. I paused the movie and declared that a woman had written the story/screenplay (though not with high confidence because it could be a codified romantic-comedy trope that male writers would also use, or it could just be a way that the woman-gender-role is reputed to think about the man-gender-role without that belief actually being localized to the instantiations of that gender). The deduction was correct, though.

AAAAAHHHHH WHY #civilizational_inadequacy

Clearly the work of a diamond maximizer.

We need a better name for a certain FAI problem, which I now explain as follows. Suppose you foolishly build an AI with a utility function U along the lines of "maximize happiness". Suppose also that this AI is smarter than you are. Problem 1:  The AI is smarter than you, therefore it visualizes more possible strategies for achieving its goals than you have time to consider, and also more possible configurations of matter that it will evaluate against its utility function th...

"I like the phrase 'cool story, bro' but it seems slightly too contemptible to use for countersignaling." -- Pantsmistress Elizabeth  #godrics_hollow

Sunlight is like caffeine for me. It wakes me up while I'm in direct sunlight, but a few minutes after I leave, I crash and feel very lethargic and sleepy, sometimes for the rest of the day, to the point where it feels like a bad idea to be in the sun for more than 20 minutes if I want to get any work done the rest of the day. Anyone else have this going on?

"Now anyone who has sojourned among the various Religions, will have seen and remarked, that the different peoples take approach their God in different ways, as the primary approach of the most Christian Faith to God, is through Christ, and the Faith and Belief in him. And having been among the Jews, they may remark on a surprising quietude so far as matters of Faith are concerned; that, indeed, a Jew who cries too much or too loudly of his Belief is suspected by the others....

*facepalm* Apparently if your society has an excess of males, it becomes impossible for most women to find an acceptable mate. The aliens watching this planet are once again flabbergasted.

Me:  Jews have a deep emotional relationship with weddings that they don't have with, say, God. Brienne:  Whyyyy? Me:  Basic hedonics, I suppose. You say your daily prayers and nothing happens, but you go to a wedding and get cake.

"Democracy doesn't prevent tyranny, it just creates one where nobody is in charge." -- ShaperV

I think what I need to do is get together with Andrew Hussie of Homestuck and Sam Hughes aka qntm of Ra and arrange for all three of our masterpieces to conclude at the same time, namely just before finals

I just read up to the current point on Ra by qntm (Sam Hughes). This is the very highest caliber of story. 

Unskeptically sharing dubious claims on Facebook causes over ten million preventable deaths per year.

Is it just me, or is this actually a really valuable lesson to teach your kid?  I mean you wouldn't do it exactly this way. When your kid was 5 years old, you'd start out the same way my own father did at that age, by telling really blatant lies like "The screws that hold on your head are inside your nose, so if you pick your nose your head will fall off". Then you'd start with slightly more subtle, still pretty blatant reasons for why your kid can't succeed at things, like "You'll never be good at dodgeball because there's a gypsy curse on our family."  And so it would go over the years until finally your kid was in university and their friend would be like, "I can't be a physicist, I'll never pass the calculus course" and your kid would be like "HOW DO YOU KNOW THAT".

As of Ch. 7, Alexanderwales's "The Metropolitan Man" has crossed the line between where you ask about the story "Can it keep up the goodness?", and where you ask "Will it live up to its promise of greatness?"

This is *excellent*.

The HPMOR subreddit is discussing what happens if you use a Time-Turner so that, by murdering a third party, your past self tries to turn your future self into your own horcrux. I <3 my fans. http://www.reddit.com/.../horcruxing_a_timeturned_version_of.../

Slowly, dizzily, you blink your eyes open. You seem to be in one corner of a huge matrix-like structure of cubicles, your back to an opaque wall, and other cubicles visible above you and in front of you. You cannot remember how you got here. In fact, you're not even sure you can remember your name. There is a 2 block here. There is a 4 block above you.

"The purchase price of unethical behavior is low, but it is the maintenance costs that will kill you." -- 

The movie of Ender's Game was disappointing. All the best moments in the movie were the ones that were not in the book, which makes me think the scriptwriter was competent but their hands were tied by the need to cram in a disconnected collage of book scenes. Also movie Ender seems significantly more like HJPEV than like canon Ender, but not in an awesome way.

I'm the beneficiary here. Less shoulder pain = more writing!

From http://freefall.purrsia.com/.

Actually the Bayesian Drinking Game is when you drink enough that your expectation of drinking more alcohol is exactly balanced by your expectation of throwing up alcohol you've already drunk. Bayesian drinkers should not be able to predict a net change in their own alcohol content.

Brienne:  I don't want to cook right now. Me:  Well, fortunately you're not cooking right now. You're lying in bed. Brienne:  I mean right now I don't want to cook. Me:  What, right now you don't want to cook ever again?  Rarely have I been so glad for the instability of your desires. Brienne:  Right now I don't want to cook for the next several hours.... Me:  Oh. Well, how do you feel about causing other objects to cook?

Does anyone have any objections to the phrase "anapartistic reasoning" before I start using it?  The idea is to describe the subfield of Friendly AI concerned with averting the sort of phenomena that arise when Agent 1 makes a mistake in building Agent 2 and then (by default) Agent 2 has a convergent instrumental incentive to resist modification by Agent 1, avoid being shut down by Agent 1, deceive Agent 1 about whether it made the mistake, manipulate Agent 1, etcetera. The ...intent is to describe an Agent 2 that behaves as though it knows that it's only partially built and doesn't interfere with the further building process including error correction, hence "anapartistic". An example of a specific technical thing would be a thing we're working on describing three classes of utility functions such that they avert the convergent instrumental incentive to avoid the pressing of a shutdown button, or to disable such a shutdown button.

This is a thing that actually happened. It is going to sound like a joke, but it actually happened. But first, I would like to remind everyone that all infinite recursions are at most THREE LEVELS DEEP. Object level, meta-level, meta-meta level, and then there IS NO meta-meta-meta level. Nobody has ever used a meta-meta-meta-anything for any productive purpose, ever. The counting numbers go 0, 1, 2, omega. So here's what happened:... Yesterday, I asked Brienne to put my blue jeans through the laundry. Brienne delegated Elizabeth to put my jeans through the laundry. Liz delegated Nick to include my blue jeans in the laundry. Another thing that happened yesterday, is that our fifth housemate, Robby, left on a little trip. So to reiterate, I delegated Brienne to put my blue jeans in the laundry. Brienne delegated Liz to put my blue jeans in the laundry. Liz delegated Nick to put my blue jeans in the laundry. NOW MY BLUE JEANS ARE IN WASHINGTON D.C. AND I SERIOUSLY THINK THAT IF YOU HAD ASKED ME IN ADVANCE TO WRITE DOWN EVERYTHING THAT COULD GO WRONG WITH LAUNDERING A PAIR OF BLUE JEANS AFTER DELEGATING IT THROUGH THREE LAYERS OF ADMINISTRATION AND I HAD TAKEN THIS TASK SERIOUSLY THEN "THE BLUE JEANS END UP IN WASHINGTON D.C." WOULD NOT HAVE BEEN IN THE FIRST THOUSAND ITEMS ON MY LIST I WOULD ASK HOW YOU END UP WITH THIS LEVEL OF CRITICAL FAILURE LIKE HOW IS THAT OUTCOME EVEN ON THE DIE-ROLL TABLE BUT I KNOW EXACTLY WHAT HAPPENED WHAT HAPPENED IS MORE THAN THREE LEVELS OF RECURSION

Brienne:  I remember when my System 1 decided it was a kodama. It grew little arms and waved them around, yelled, and hid under a rock. Eliezer:  There are times when I suspect that your inner life really is very different from mine.

Brienne:  I remember when my System 1 decided it was a kodama. It grew little arms and waved them around, yelled, and hid under a rock. Eliezer:  There are times when I suspect that your inner life really is very different from mine.

Scumbag reporter Zachary R. Mider finds flimsy excuse to question the motives of three heroic billionaires who gave away most of their money, in secret, to relatively decent causes! 

Robin Hanson: "[It's easy to say that] research patrons should stop paying for crap research, firms should stop paying for crap ads, blog readers should stop reading crap blogs. The great puzzle of Sturgeon's law, why do people pay for the 95% of everything that is crap?" The negative externalities of 'stupid people with buying power' on the market experienced by other actors looks to me like an underexplored topic in economics.

"Eliezer, I don't always have a use in mind for everyone I make friends with." "Sometimes Slytherins aren't trying to be friends with you just because they have a use in mind for you, yes. Sometimes they just think that this seems like a generally useful person who'll probably be useful later." "Exactly."

I'm telling someone today. Are you?

With 2 hours and 15 minutes remaining, the Sankara Eye Foundation is leading MIRI by 461 to 432 *unique donors*. There's a grand prize and we need more people to donate (at least) $10 who have not already donated, by midnight Pacific Time today. The grand prize is $250K in Microsoft in-kind giving, which won't literally be worth $250K to us but includes hardware, software and consulting services; plus the publicity of winning this major competition among charities. This is... one of the most leveraged chances to give $10 that you'll probably ever encounter ever. Please give now! Or if you're *sure* you won't forget, enter your credit card information on the form, wait until the last two minutes before midnight according to a reliable clock, and donate $10 exactly then. Already MIRI has been doing very well in the parts of this competition that revolve around having lots of unique donors in each hour. I hypothesize that there are a lot of big charities with a few big donors who are willing to give $20,000 in an optimized way, but MIRI is the charity with a grassroots community of small donors who will give $10 in a precise optimized way. We just need more of you to win---this is definitely coming down to the wire.

I couldn't help myself when I saw this was a thing, so here's my #twosentencehorrorstory: "I wonder if the devils tell you right away when you get to Hell, or if it's more effective for them to let you figure it out yourself. And whether it's just a coincidence that I had that horrible vivid dream about crashing my car, the night before I lost my job, ended up on the streets and started going blind."

The best time this year to give to MIRI will be on Tuesday (May 6th), if you do it exactly right.

Tegmark Level 5 contains all the impossible possible worlds that seem plausible to agents at various levels of non-logical-omniscience, like the world where Fermat's Last Theorem is false on the natural numbers, or the world where 216359 is a prime number. Tegmark Level 6 contains all the inconceivable worlds, like the worlds with p-zombies, the world where Jehovah is real and rules all of the Tegmark levels and behaves as described in the Old Testament and is perfectly morally good, the world of ducks that are both blue and not blue, the world of trivialism, and the world which is just like this one except that nothing is true. Tegmark Level 7 is just a giant middle finger extended at all of epistemology - the territories which do not correspond to any maps, even incoherent ones.

We need a name for a subfield of FAI which refers to the sort of reasoning we would want an AI to do while we were still in the middle of building it. For example, we would want to avert the convergent incentive to 'prevent anyone from modifying my utility function' because we would want the AI to reason as if it knows that it's incomplete and it should let us go on building it. Similarly, most utility functions will give you a convergent incentive to remove a shutdown button if you find that you have a shutdown button. We would like to avert this convergent incentive, which is an open problem. For now we need a *name* for this class of problems. Some suggestions so far have been "reasoning while incomplete" or "non-self-trusting agents". We would very much like to have a name that sounds like it's a real technical thing, as opposed to "immature reasoning" or something like that. Latin or Greek roots for things that are still in the process of being built, missing parts, visibly incomplete?  Latin or Greek or traditional theist words for the sentiment in e.g. Cromwell's "I beseech you, consider in the bowels of Christ that you may be mistaken"?  Any ideas?

Elizabeth:  "Is it 12:46 yet?" Robby:  "It's 12:45." Me:  "What happens at 12:46?  Should I be running?" Elizabeth:  "Yes." Me:  "It's hard to get veridical information in this house."... Robby:  "12:46 is our Ungrounded Panic Minute."

Seth Roberts is dead, having collapsed while hiking near his home. Seth Roberts was responsible for 20 pounds of personal weight-loss for me via Shangri-La, and when I reported that the diet mysteriously stopped working after that, he personally Skyped and emailed with me on suggestions trying to get it working again. His spirit of personal experimentation was an inspiration to many and is probably to some extent responsible for my trying to compose my own ketogenic Soylent now. He stopped in once at MIRI to borrow the wireless Internet. He was too young for me to have expected this. I'm sad.

#ShitBayesiansSay "Okay, now I'm going to convince you that this series sums to 1." "You just did."

Rationalist put-downs:  "I have great faith in your abilities, where faith is distinguished from justified belief."

The human species isn't unable to have good ideas, it's just 200 years behind the curve of when those ideas would have been truly useful. I predict, as a test of this cynicism, that NGDP level targeting will become economic gospel just as e-finance starts to defeat central banks.

From yesterday's whiteboard. Warning, may cause nerdrage.

Brienne:  "I am *definitely* not a Disney princess!" Me:  "You just wait for them to get there. By 2017 Disney will have cute evil princesses who end up... accomplishing some good..." Brienne:  "You mean Byronian anti-princesses?" (Pause.) Me:  "I will not write this movie. I will not write this movie. They would never produce it, so it would be a waste of time. I will not write this movie."... (Pause.) Me:  "I will, however, post this to Facebook."

I'm not sure how much updating to do on the fact that Brienne's life insurance company is asking her whether she skydives - whether I should conclude that skydiving is so risky as to form a fact that life insurance companies want to know about, or whether they've found it's a useful statistical proxy for other risky or risk-seeking behaviors, or whether someone at the company just made it up. (My life insurance company didn't ask me.)

It is alleged in passing here that when the one doctor who was performing the brain surgeries for cortical brain implants for the blind, William H. Dobelle, died after operating on his 16th patient, all such surgeries ground to a halt. #heroic_epistemology if true, in particular the #hero_theory_of_innovation. I'm not quite sure how much to believe it, though checking against http://en.wikipedia.org/wiki/Visual_prosthesis... does show a number of subretinal implants, and some research projects on cortical implants, but no cortical-implant projects accepting actual patients for surgery, except a brief window on the Dobelle Eye.

Most of the novel rationality proverbs suggested in /r/HPMOR weren't very good, but I quite liked this one by jaiwithani: "Imagine having an arch-enemy. Do things that make them sad."

I think I realized one of the reasons I read so much fanfiction, and also a reason Worm worked so well for me. I'm not just face-blind, but also a sort of generalized identity-blind; until I've met someone a dozen times, I have trouble associating their face to a name, and I also have trouble associating names to human identities. And lo, I was recently reading a non-fanfic urban fantasy when I realized how much trouble I was having keeping track of who everyone was; and that... perhaps this was something that varied from reader to reader. In fanfiction, I have a much better and more immediate idea of who all the characters are supposed to be; I've already met them a dozen times. Their personalities will vary from fanfiction to fanfiction, but at least I don't have trouble associating their folders to their names. This is not a trivial inconvenience for someone like me, and it probably accounts for a significant amount of the felt effort I feel like I'm expending while reading mainstream novels. In Worm, (a) characters are introduced slowly enough, over the 1.75-million-word novel, that I'm only trying to learn a couple at once; and (b) they're named things like "Tattletale" and "Grue" and "Clockblocker" which associate to their functional roles, rather than "Frank" and "Fred". Often we get to know the person behind the superhero alias on a first-name basis, but at least by that time I know who the person is. I shall definitely mark this down as a trick in my author's toolbox, going forward:  Make sure you're only asking the reader to be "learning" at most two unlearned people at any given point; give the reader repeated cues associated with their functional roles until the reader knows the characters very well; and if at all possible in your universe, give them highly distinct functional names. #writing #writing_advice

I have a confession to make. It's something which has been weighing on my mind for a long, long time - since late 2000, actually. I did not invent timeless decision theory. I did not invent the rationality techniques I've claimed as my own....

They still won't let me name our group house "Sugarcube Abyss."

It's great that they did all this description of me personally, but don't the other INTJs need their own signs?

At $29 this is the best belt, by far, that I've ever owned. It works on a ratcheting system, and has no prepunched holes. When I want to tighten my belt, e.g. to start running, I just pull on the belt-end and it tightens. If I want to loosen my belt before sitting for an extended period, I lift the buckle slightly and it loosens. If I lose weight and the belt-end extends too far out, I can detach the buckle, slice off some leather from the detached end, and reattach the buckle (the cut end is never visible). Since the manufacturers don't need to worry about belt lengths and manufacture the buckle and belt separately, they can offer a wider variety of colors and buckle designs. I wish now that I had bought this belt years ago. It makes it substantially easier to wear nice pants. This belt has inspired in me that very rare feeling of joy which comes from wanting something to exist, looking it up, and finding that it not only exists but has been done *better* than you imagined; the feeling of living in an adequate civilization where you can have nice things. It is Correctly Designed. The eBay price is the lowest I've seen and it claims the sale ends in 4 days, which might or might not be true.

Holy crap I was not expecting this. I think I owe somebody a bunch of Bayes points about this prediction but I forget who.

In my previous status, someone brought up male circumcision. Ceteris paribus, I expect cutting off an evolutionarily designed part of the penis to be a bad thing, and I don't get the impression that there's adequately strong evidence in favor of it, and indeed much evidence against. (EDIT:  I need people *in favor* of male circumcision to present their best studies. Currently the thread is mostly people with standard studies against it, which is compatible with the hypothes...

Every child is unique, at least relative to your own parenting experience. Nobody raises any given child correctly on their first try. Don't feel guilty about it. Just do better the second time you raise them.

Pro-tip:  When I called Comcast with a "billing issue", I was routed to a person who spoke very halting English, couldn't handle or figure out my issue, and refused to escalate my call. When I called again and selected "downgrade service", nerving myself for an even worse gauntlet because Comcast surely wouldn't want me to do *that* successfully... suddenly, with no hold time, I ended up speaking to a quite competent person on the "customer loyalty team". Lesson learned:  Any time you need to speak to someone competent at Comcast, just navigate to the part of their system that handles downgrade requests.

I'm sick, so finally getting around to reading Homestuck. (Place:  003551, just after the creation of the Davesprite.)  Serious question:  Has there ever been a lawful time travel plot more convoluted than this?  This is wonderfully chaotic, but I'm not sure the author has set down strict rules for how time travel works in their universe, and the trust in that quality (along with everyone with time travel access using the rules intelligently) is a central part of the story for me.

Sayings of Buddhamort: Clear your mind of all desires, except the desire for power. Let go of your positive emotions.... Release other beings from the wheel of reincarnation by annihilating their pathetic souls. The universe of sensation endlessly betrays the senses. All the material objects you perceive are plotting against you. Strike first.

Maybe Buddhism originally began as a cynical plot to remove the uncool people from the wheel of reincarnation by teaching them the absence of desire, thus causing them to fall out of the cycle of life and into an empty void devoid of sensation; all so that, eventually, only the cool people will be reincarnating. Their strategy is just a marketing campaign to describe nonexistence using nice-sounding language, and make nonexistence look like what all the cool kids are doing. If you fall for it, the true masters of Buddhism think you unworthy of existence.

This is what the inside of my perspective would look like, if, as in BBC's Sherlock, my thoughts appeared as white-text labels on objects. On my way home from the grocery, I walk past the usual line of taxis at the train station. One taxi is parked particularly close to another. Overlay:  White line weaving through cars in parking lot. Label:  SHORTEST PATH. The hypothetical path that would follow the grid directions is also outlined, along with a label saying PYTHAGOREAN ...

(Inspired by Slate Star Codex's "What universal human experiences are you missing?") It was the gelling of the HPMOR hatedom which caused me to finally realize  that I was blind, possibly I-don't-have-that-sense blind, to the ordinary status-regulation emotions that, yes, in retrospect, many other people have, and that evolutionary psychology would logically lead us to expect. Status is a tremendously valuable and scarce ancestral resource, and one which exists in people's mi...

*blinks* Am I overinferring from one piece of data, or does this writing mean that there was an entire branch of the 1970s women's liberation movement like this, which lost the battle for the heart of the movement and was driven out?

I seem to remember reading that deaths under general anesthetic went down by a factor of 100 once someone began to track death rates for anesthesiologists, and they had an incentive to actually use the safety checklists which had been developed. Can't seem to find a reference. Does anyone know, is this true and where can I find a reputable link?

On the eve of Russia's occupation of Crimea, TRIP snap-polled scholars in different areas to ask them about the probability that Russia would intervene militarily in the Ukraine. The absolute worst average prediction, by category of scholar, was given by scholars at Top 25 universities. Snapshots like this provide an important ongoing reminder of who's most and least on the ball.

Is there such a thing as a geometry of at-least-3-dimensional space where most straight lines, or most straight lines restricted to a potentially curved surface, will pass near some particular central point?  In other words, is there such a thing as a space which has a preferred center, or a land within that space which has a preferred center given the geometry of that space, in the sense that walking in a straight line will usually bring you just a few meters away from the Center at some point along the line? EDIT:  To rephrase:  One day you wake up in an apparently indefinitely extending but otherwise featureless grassy plain which may optionally have hills, or screens of trees that prevent you from seeing too far. You find that, whenever you start walking from any point, if you continue walking in a straight line indefinitely, you come to or approach near the same point in the mysterious place, let's say a big golden menhir. What kind of geometry could this place have? Where's the golden menhir in that geometry?

Today I bought, for $80, a burned-looking used Nook HD+ which has 1920x1200 resolution on an 9" screen and reads microSD cards. Then I put over 1,700 illustrated science and math textbooks on a tiny chip which is literally smaller than my thumbnail. Having those 1700 science and math textbooks is illegal, meaning that only rebel outlaws have access to that kind of concentrated knowledge. As Matt Boyd wrote: It is unquestionably the future, and you would have crashed your stupid flying car anyway.

Danielle Lei, when you are older, you have a standing invitation to join the conspiracy.

I wonder if any truly keen philosophy has ever been conceived of by someone at a time of their life when they thought of themselves as solemn, serious, and wise. This is by Zach Wiener, who usually makes penis jokes.

Well said. Three cheers for evenhanded application of criticism standards to more than one side of a story.

Does anyone know if there's a good, precedented "is actual" symbol in philosophy?  I may be about to write something where possible events are denoted by integers, and the symbol B(x) means that the event denoted by integer x has actually occurred. Similarly, B(x) -> B(y) would mean that the actuality of x implies the actuality of y. Is there something more precedented than B(x), like some kind of greek letter or hat or squiggle, keeping in mind that this symbol will be used quite a lot and must be short?

http://xkcd.com/1331/ alleges that people in Phoenix, AZ buy a pair of shoes around twice as often as they put on a condom.

What are some examples of people who aren't typical examples of *any* reference class?

From a recent conversation about gay marriage (with an older academic lawyer type person) after I said that, unlike the case with gun control or nuclear power plants, there really *weren't* any legitimate arguments against gay marriage: Him:  "Okay, what about the slippery slope argument?  If it's legal for men to be married, what about two men and a women?" Me (hiding a smile):  "Yes. I'll tell you right now that I'm just going to slide all the way to the bottom." Him:  "Okay, then what about a sterile brother and sister?" Me:  "Yes." Him:  "What about a fertile brother and sister?" Me:  "What about any other couple where both the man and the woman have copies of deleterious recessive genes?  Should the State be able to rule that they can only marry if they don't have children?  Arguably yes. But either way, you just crossed over into arguing, not that you don't like the couple, but that you don't like the child's genetic constitution." Him:  "Well, we have to consider the probabilities..." Me:  "Still eugenics either way."

Here is how my brain now works when I am asleep. While I am *sleeping*. It didn't previously do this sort of thing entirely on autopilot. I blame writing Methods. In the first dream, someone is doing small magic tricks to amuse a kid. I don't remember their name, so I shall call them Green. Green is trying to cue someone else to take a quarter so they can pull it from the kid's ear, but the other person keeps missing their cues, so I helpfully reach over and palm the quarter from Green. However, I don't actually get a chance to use the quarter before that dream ends. In the second dream, I've gone back in time to prevent someone from changing the timeline... or something like that. I am definitely there as Eliezer, not some other character. Since I'm back in time, I end up fighting Conan the Barbarian as played by Arnold Schwarzenegger, and since my brain is evaluating this scenario realistically, it takes him less than three seconds to put a sword through my chest. Conan:  "I have you now." With my last strength, I reach out my left hand and pull the quarter from Conan's ear. (Pause.) Conan:  "Green?!" Myself (neither confirming nor denying this):  "The timeline... is yours to protect now... keep it safe..." (dies)

What amazingly nonstupid media coverage:  http://www.forbes.com/.../inside-googles-mysterious-ethics-b.../

...and I'm out. Officiating that wedding sure was a different experience the 500th time I did it. I was like, "I don't get it, this wedding is going *fine*, why am I stuck?" and then it turned out the key point was that Brienne needed to remember she had rational choir practice that night. Ugh, I am so sick of time loops.

A valuable warning to us all.

"People sometimes ask where I get my passion from, and I find it hard to answer. We hold the entire future of the universe in our hands. Is that not justification enough?"  -- Nate Soares

Sigh.

"Proves Too Much" is the fallacy-detecting technique of spotting a flawed argument, not by zeroing in on the particular flaw, but by showing that an analogous argument, sounding equally strong, will conclude things we already know to be false. People sometimes say that the dietary theory known as Calories In, Calories Out (you lose fat according to how much you exercise, minus how much you eat) is mandated by the laws of thermodynamics. But this isn't actually, literally 100...

I was not named after this Rabbi Eliezer BUT I TOTALLY SHOULD HAVE BEEN. HT Elizabeth.

Some part of me does like living in a world where people are worried about the quiet spread of the shadow banking sector of the financial world, and people are writing alarmed notes about it accounting for 20% of Chinese GDP and so on. I mean the kind of story where the villains are called Shadow Bankers sounds like it could be really interesting if the author was economically literate. Anyway, I think shadowbankers should all wear dark robes with hoods instead of business suits. Who's with me on this?

I don't think it's a fic I'll be recommending to anyone, but even I have to admire the sheer unabashed self-indulgence of having a self-insert genderbent time-traveling Jedi rock star go to Hogwarts.

For nearly the first time in my life, I forgot to eat today and didn't notice a difference and didn't get a terrible headache or have my body shut down. I'm still tinkering with the recipe, and it still tastes awful, and I'm still getting upset stomachs, and I'm still getting many vitamins and minerals from pills, but I think I'm willing to say at this point that Super Ketonic Dietary Replacement Fluid is basically working and causing me to lose weight. Remember, everyone:  If you're hungry, it means you're not losing fat!  If your fat cells were releasing fat to be burned, as mine apparently are right now, you wouldn't be hungry.

I've been keeping my money in a bank and that makes me part of the problem. It's time to hold my valuables as mostly index funds and Berkshire Hathaway, converting to cash only as required. Now that I have a smartphone (sigh) which can take pictures of checks to deposit them, I have no need of a physical bank. Most cash I currently withdraw is done in grocery transactions. What is the fee-minimizing, convenience-maximizing solution?  I've already received a suggestion for Charles Schwab, anyone have anything horrible to say about them?

I recently realized the following incredible, mind-blowing, totally unexpected insight which I've never heard pointed out before: The Mane Six from My Little Pony form a Myers-Briggs style personality space. Pegasus axis:  Exuberant/adventurous (D) vs. quiet/reserved (F)... Unicorn axis:  Stylish/sociable (R) vs. bookish/introverted (S) Earth pony axis:  Silly/creative (P) vs. sober/hardworking (A) I'm definitely a Sparkle-Pie (no non-Sparkle-Pie would have posted this) but am somewhere around the middle of the Dashflutter scale. How about you? (And just in case this post ends up getting 500 shares: http://hpmor.com/ )

Everyone in /r/HPMOR and in the Ch. 100/101 reviews who claimed that Harry must be carrying the idiot ball for *not* regarding Professor Quirrell as evil for putatively drinking unicorn's blood to extend his life for a short period, had better be a goddamned vegetarian who doesn't eat pork to extend their own life for six goddamned hours, or I call shenanigans on them and their cartoon sense of morality. (There is no evidence in canon or HPMOR that unicorns are more intelligent than pigs, and all intelligent (language-using) beings in canon or HPMOR look humanoid and many can interbreed with humans suggesting a heritable magical effect etc. as Harry has already reasoned out.)

This probably isn't the worst fairy tale ever, but it's in the top tier.

Today's brilliant moneymaking idea:  A coffeeshop named "The Schelling Point".

There's something truly heartwarming about seeing someone on /r/HPMOR saying they're 90% sure that Harry's father's rock is the Resurrection Stone, and six other users replying with offers to bet at those odds. /u/illtakethatbet was too late to get in on the action. And so a new kind of sanity was born.

Okay, starting to like this villain now. 

The tragedy of BBC's Sherlock is that the writers are smart enough to write the character of the adorable psychopath, but not smart enough to plot his murder mysteries intelligently.

Aaaand this was always the big problem with the "There's a limited number of Bitcoins!" argument. 

Being on a planet of aliens is what being an alien feels like from the inside. (Conversely, feeling like an alien is what being on a planet of aliens feels like from the inside.)

(In a conversation about veganism.) Me:  "Pick a category that you think is binary." Brienne:  "Oddness." Me:  "Okay. What about the number 2.999?"... Brienne:  "Of course not!  That's definitely not odd!  Or do you mean two point nine repeating?" Me:  "Nope. Three nines. 2.9990." Brienne:  "Calling that odd is a category error." Me:  "Yes, exactly!  But it's very close to something that *is* odd." Brienne:  "I'm not sure I'd agree with that. I don't consider the real number 3 and the natural number 3 to be identical." Me:  "Is the real number 3 odd?" Brienne:  "That's a very good question. I'd have to think about that." Me:  "Suppose we introduce the category 'nearly odd' to describe real numbers which are very close, on the real number line, to real numbers which correspond to odd integers." Brienne:  "Okay." Me:  "Chimpanzees are nearly conscious."

This is the last Christmas story, beyond which no other Christmas story can exist. (Rational!Munchkin!Santa, neutral!genie!elves.)

Oh damn it, I can't believe I've been sent back to the start of 2014 *again*. Will this cursed Loop never end?

2013 was actually an okay year. I would not mind doing this again.

If we could get any one actor to read Professor Quirrell's "One Killing Curse will bring it down" speech:  Benedict Cumberbatch (BBC!Sherlock) or Patrick Stewart?

AAAAAAIIIIIIIIIIIEEEEEEEEESee Translation

The Economist jumps on the Civilizational Inadequacy bandwagon, publicly invoking the We Can't Have Nice Things Theorem. This is also a correct meta-level rationale for their award. I'm impressed. "But the accomplishments that most deserve commendation, we think, are path-breaking reforms that do not merely improve a single nation but, if emulated, might benefit the world. Gay marriage is one such border-crossing policy, which has increased the global sum of human happiness at no financial cost. Several countries have implemented it in 2013--including Uruguay, which also, uniquely, passed a law to legalise and regulate the production, sale and consumption of cannabis. This is a change so obviously sensible, squeezing out the crooks and allowing the authorities to concentrate on graver crimes, that no other country has made it."

There seems to have been a very lopsided flow of funds into the MIRI and CFAR fundraisers. The balance is tilted sufficiently that I'm now willing to call it for the next marginal dollar being more valuable at CFAR than at MIRI, at least until CFAR's fundraiser completes. 

This matches my own life observations as well, mostly in the realm of obesity and reputation management. I really wish certain people would be more cynical about all the super-helpful advice they get.

"The Night Watch", first on this list, is a good candidate for the highest density of humor particles per second of anything I have read in 2013. [Edit: Not by Pratchett, this is a different "The Night Watch."]  I very nearly did a spit-take several minutes *after* I finished reading "The Night Watch" when, taking a swig of my Drink of Despair, the phrase "I HAVE NO TOOLS BECAUSE I HAVE DESTROYED MY TOOLS WITH MY TOOLS" popped into my mind and I had to carefully hold the liquid in my mouth for 30 seconds while giggling hysterically, swallow one gulp, then hold the remainder in my mouth for another 15 seconds of giggling until I sternly repressed all thought processes long enough to swallow the last gulps and then start giggling madly again, which I'm still doing right now. Non-programmers might not get it. http://blogs.msdn.com/b/oldnewth.../.../2013/12/24/10484402.aspx http://research.microsoft.com/.../p.../mickens/thenightwatch.pdf

"That whole question -- who elected you? -- inverts the model," he said. "They elected me. The overseers." He named the chairmen of the Senate and House intelligence committees. "Dianne Feinstein elected me when she asked softball questions" in committee hearings, he said. "Mike Rogers elected me when he kept these programs hidden. ... The FISA court elected me when they decided to legislate from the bench on things that were far beyond the mandate of what that court was ever intended to do. The system failed comprehensively, and each level of oversight, each level of responsibility that should have addressed this, abdicated their responsibility." "It wasn't that they put it on me as an individual -- that I'm uniquely qualified, an angel descending from the heavens -- as that they put it on someone, somewhere," he said. "You have the capability, and you realize every other [person] sitting around the table has the same capability but they don't do it. So somebody has to be the first." -- Edward Snowden, 2013 http://www.washingtonpost.com/.../49fc36de-6c1c-11e3-a523-fe7... #heroic_epistemology #civilizational_inadequacy

http://lesswrong.com/.../j.../building_phenomenological_bridges/ ALL HAIL LORD BENSINGER THE EXPLAINER.

Books that would be useful: "So!  You want to positively reinforce people. Of course you do!  You're not stupid, right?  But you don't seem to feel naturally enthusiastic at the same times other people do, or not in the same way, or something. You can't just express your outwardly overflowing unreserved enthusiasm because that's not how you operate internally. So you feel gratitude and gladness, and you smile, and you wonder if they can tell that the smile is forced, because even though you're genuinely glad X happened, your body wasn't going to smile naturally at that time. You say 'Yay!' and you wonder if your voice or body language is sending signals for dishonesty. (It's not like anyone would tell you if you were. You've told college students that they have strong body odor, because someone has to do that or the rest of their lives will be terrible, and they almost always say that nobody has ever told them that before.)  You know that it's very easy to make _you_ uncomfortable by trying to say a word of congratulations at the wrong time, or that you don't think is fully deserved, or that you wonder if the other person really believes. So you say 'Yay!' and wonder if you're just making things worse, or maybe remain silent. Thankfully, there's a practical way to solve this problem!  Just use this included computer program where you speak aloud various sentences of congratulation, endorsement, high esteem, and so on. The program will use a webcam to monitor your facial expression, body language, semantic content, and tone of voice, and tell you how you would do relative to the lowest quartile of the average smart-person population. If you don't know where to start, we also have some videos of people doing it right for you to imitate, and we can even suggest specific muscle groups to modify or tell you exactly how to raise or lower your voice's pitch if you seem stuck in a low-scoring rut. You may have to do some training, but the training itself will be straightforward and you'll know when you're improving." Books that actually exist: "Smile when someone does something nice for you, and congratulate them!  It's so easy, and the benefits are so huge!  Here's a case study of somebody who made a million dollars and afterward attributed it to smiling at the right times!  Aren't you glad this super-helpful book told you this non-obvious fact that nobody ever mentioned to you before?" See also Alicorn's problem-task distinction: http://lesswrong.com/.../let_them_eat_cake_interpersonal_pro.../

Does anyone know of a cabin in the woods (or something), in the general Bay Area, where Brienne and I could go to for a couple of days' relationship retreat?  It does _not_ have to be on the coast - I've been to several corporate-style retreats on the coast and never once gone down to the beach. I'm familiar with Craigslist and Airbnb but they only seem to have things outside my price range. A small quiet cabin in the middle of nowhere, an hour or two's drive away, for $75/night would be ideal. Undead monsters optional.

Watching _Despicable Me_ with Erin: Villain protagonist:  "I will steal the greatest thing that has ever been stolen!  I will steal... I will steal..." Me:  "The moon!" Villain:  "The moon!" Me:  "Apparently I think like a cartoon supervillain."... Erin:  "Yes, you do."

Enclose it in something opaque and quiet, take it back to 1930 and you have magic.

There's an incredibly bright point of light in the west sky. Visible through clouds, despite sunset. Doesn't seem to move. ?

In retrospect, I wish I had written HPMOR under the pen name "Snizzard Baconwalker" or "Lord Flibble the SanityMaster" so as to avert the anti-status-seeking response of people who - yes they exist it's extremely common - had the reaction, "The author is writing this story to brag about how much science he knows."

So apparently there's such a thing as network execs who tell writers that the cartoon should have girls, but they shouldn't be as interesting as the boys and should be a step behind the boys, because girl viewers won't buy action figures, and then when the writers go into the female characters' backstory and it's interesting and girls start watching, the cartoon is canceled because of that. http://io9.com/paul-dini-superhero-cartoon-execs-dont-want-...

Myself at the decision theory workshop:  "X, I think you're overestimating my intelligence. I know I've written some good blog posts but that's when I've got hours to edit them. You need to drop your estimate of my intelligence on 10-second timescales by 20 IQ points."

"Um, so now the Earthlings have..." "What now?  I honestly didn't think it could get any worse after you told me about the soybean oil in the babies' parenteral nutrition." "They've invented an amazing clever reason to spend so much of their computing power doing fundamentally useless hashes that their cost of rentable computing is going up." "..." "Yes, really."... "Why?  For the love of Cthulhu, why?" "It's... oh, forget it. They're Earthlings." #civilizational_inadequacy #madworld

This seems surprisingly clueful (that is, parts of it are in accord with things I had already believed, and other parts I hadn't yet guessed but fit with the parts I had, which is what feels like 'surprisingly clueful' from the inside).

Fun facts from my early experimentation with Dietary Replacement Fluid: 1)  Adding pectin (because I couldn't find a safe-plant source of resistant starch to feed my gut biome, because I couldn't turn up any trustworthy documentation about whether retail unmodified potato starch is 73% RS or not) turned the 'Fluid' into batter. Erin, who usually mocks my cooking disasters, actually liked the taste - I do not understand this - and is eating this awful substance. We also tried frying some of it up as a pancake, but the batter was mostly fat so it ended up as a very thin pancake. 2)  Coconut oil. I do not understand how to keep coconut oil liquid in a Fluid. If you melt it, it goes solid again and sticks to the side of Fluid container. MCT oil is nicely liquid, so it's not purely about the size of the fatty acids. Is there some source of non-MCT saturated fat with no polyunsaturated part which I can use in place of coconut oil for non-MCT fat? 3)  Rice is a safe starch source, but adding rice flour to the Fluid produced an experience I can only describe as 'chalky'. Next attempt, tapioca maltodextrin, but that won't arrive until Wednesday. 4)  I have a rather large number of supplements on the way from Amazon Prime because there are zero, count them, zero multivitamins which have been put together in the correct relative quantities and with all the ingredients correctly selected in all their fiddly little aspects. Like making sure the selenium isn't inorganic, checking that everything which needs amino acid chelation is chelated, having the B vitamins be once a week rather than daily, distinguishing folate (good) from folic acid (less good), using all the different vitamin E components instead of just one, having the silicon be Ch-OSA instead of big chunks of silicate and the B12 be methylcobalamin instead of cyanocobalamin and having the choline not be from soy lecithin and... ...seriously, I have to learn all the dietary science in my head and hand-assemble all the components just so that I can personally solve the problem of 'creating human chow' on top of everything else I'm doing? Seriously, Earth? Plus, apparently the final version of Soylent has swapped out MCT oil, which was in an earlier version, for canola oil, which has way too much (highly reactive) polyunsaturated fat. Like, it's an okay ratio of Omega-6 to Omega-3 but an order of magnitude more of both than human beings should ever eat. Damn it, Rob Rhinehart... The word 'fat' is actively harmful to dietary thinking and should be discarded from the English language. All the lipids are different and they do different things. Even different 'saturated fats' or 'polyunsaturated fats' do different things. Even in 'omega-3 polyunsaturated fats', ALA is not DHA. There should be a word for oleic acid and a word for capric acid, but no word for 'fat'.

I'm not usually hopeful about cancer cures but this one has allegedly worked on humans in three different centers doing tiny clinical trials.

And this is why politicians wouldn't believe AI scientists about AI development even if there was moderate consensus in the field. CLARIFICATION:  In other words, politicians are already used to hearing and discounting strange, alarming claims from scientists who (the politicians think, and not without justification) want more funding.

My favorite example so far from a reddit thread on "Magical worlds ripe for abuse" (i.e. Munchkining) is _The Adventures of Pinnochio_. "Zl abfr jvyy abj tebj, naq V nz abg bzavcbgrag." (http://rot13.com to decode.)

As is only briefly noted in the story, the real story is that one person can do this (a) without anyone else's cooperation (b) without any other part of the system noticing. #civilizational_inadequacy #madworld

http://rockcenter.nbcnews.com/.../18833434-drug-treatment-ome... Congratulations to the FDA on creating this real-life trolley problem!  In Mark Puder's shoes, I would hope that I'd have the courage to kill the required number of babies, but I would try to arrange it so that the doctors and nurses carrying out the procedure didn't know what they were doing, and I would try to avoid seeing the babies or meeting their parents. But seriously, Dr. Puder, can't you find subjects for a... controlled trial who would otherwise *all* run the standard risks of lethality on the traditional, damaging parenteral nutrition?  I'm not usually sympathetic to government bureaucrats who demand that doctors deliberately kill a number of babies, but they're going to die *anyway* given status quo, and the need for controlled tests is very real. #reallifetrolleyproblems #deadbabies

Up to 600,000 bitcoins generated by Silk Road may remain unseized by the FBI, the lost pirate treasure of the Dread Pirate Roberts. In years to come, if Bitcoin's price increases further, the value of this treasure will grow past a billion dollars; and we can expect to see people being sold hints to where this vast, lost treasure can be found. There will be stories of buried USB sticks. There will be maps. Those of you with the wrong kind of literacy know there can be only one appropriate name for this lost hoard, the greatest treasure in the history of piracy, never found after the legendary Dread Pirate Roberts was captured by the authorities. It is the One Piece.

All I want for Christmas is a source of roughly 1g/day of supplemental choline which doesn't come packaged with 2g/day or more of Omega-6 fatty acids, such as one would find in sunflower lecithin or soy lecithin. I can't find bulk egg yolk lecithin, just doses 1/10th the target level. Does the Community know a solution?

I wonder if BDSM masters and slaves would care enough about each other to make each other sign up for cryonics. Is it completely screwy that my mental model holds out the distinct possibility that a dominant would be much more protective of a submissive than, say, a mother for her daughter, a son for his father, or an average non-BDSM husband and a wife?  That a slave would be more afraid of their master dying forever?  Or am I just projecting myself onto one more space I haven't yet checked for failure?  Posting this here to increase the probability that I remember to give it a try.

I overheard a bit of conversation last night on the theme of (yet again) how someone didn't really get the metaethics sequence, and they thought maybe I was arguing for moral realism... Reflecting on things much later, I think that maybe what I was really trying to do, besides explain a bit of FAI theory, is get across the following 3 counterintuitive points: 1)  A rational agent can be doing nothing with its existence but maximizing paperclips without being defective in any ...

When I was a child, saying the Pledge of Allegiance, I would always end, under my breath: "With freedom,... and justice, for all except the children." Those days are now long gone, and I can't quite imagine, a Pledge I could say today. "I pledge conditional friendship, not to any flag, but to the ideals, which the constitutional republic of the United States, was originally formed to protect. Thirteen nations, bound together in mutual defense, against huge Foreign Powers, which could have crushed any state alone; and unrestrained trade, without tariffs imposed on riverboats; with several freedoms and justices, theoretically guaranteed to every citizen, if they were one of the select, a group which widened over time, but never enough to include children." Those years are now long gone, never to return, for Time does not tick backward. And I might say a kind word, for the megademocracies of Later, and the war they fought against Hitler, in the years when some wars were just. But that era also passed, carrying with it the time when people good and wise could pledge allegiance to a flag. Maybe that time ended with Guantanamo, and maybe it never existed, but I know I remember it, from when I said the Pledge in class, even if it was a dream. That dream is gone, and I can't wish for its return, for we will not be the better if we forget what we have learned. With the passing of that small allegiance has come a wider fealty not to stars on a flag, but to stars in a sky, and my loyalty to them, is not plagued by catches in my voice, nor evils to unsee. Even so, knowing the flag was never clean, and that nations are not worthy things for human minds to give allegiance, I miss the Pledge, that childhood error, which must never return.

!

We settled for a large finite TV screen, but we could have had an arbitrarily larger finite TV screen. #infiniteworldproblems We have Porsches for every natural number, but at every time t we have to trade down the Porsche with number t for a BMW. #infiniteworldproblems We have ever-rising expectations for our standard of living, but the limit of our expectations doesn't equal our expectation of the limit. #infiniteworldproblems 

Overheard at the decision theory workshop: "I consider myself a combination virtue ethicist and consequentialist, restrained by deontological rules which are justified by consequentialism." "I don't know what half of those terms refer to."... "Okay. I try to live my life so that in the metafictional universe above ours, the TV Tropes page on me will list me as a good guy." "*That* I understood."

Charity Navigator hates Givewell and EA. Their CEO just wrote an article that's more outright namecalling than ad hominem ("defective altruism"). We should probably all stop trusting or using Charity Navigator in any way shape or form. Remember, kids, the rest of the planet thinks this is what an "argument"looks like.See Translation

Overheard at the workshop: "Humans taste like pork." "How do you know?" "I tried pork a couple of years ago."

So Anders Sandberg and I - society should probably serve us with some sort of restraining order forbidding us from giving each other ideas - have invented the following amazing business idea. Not just bitter dark chocolate, but bitter dark evil chocolate made with an endangered species of cacao beans, salted with the tears of Burundian orphans, and hand-conched by slave labor in a plane that flies around the world in night to escape the life-giving light of the sun, as well as increasing the chocolate's carbon footprint. The business model would be explicitly evil rich people who wanted to impress other evil rich people, like the Simpsons's Mr. Burns.

I'm given to understand that the Estonian press has accused MetaMed (in which Jaan Tallinn, Estonian cofounder of Skype, is a principal) of being a Jewish conspiracy bent on world domination, thus demonstrating that even a stopped clock is right once every 2500 years.

If you have a sexual fetish for people who have a fetish for recursion, and they have a fetish for people with a fetish for recursion, the two of you have a fetish for each other via Lob's Theorem.

Brienne seeks *soft* running trails. She runs in Vibrams and is used to deciduous forests, and hard trails will injure her feet (this has already happened). Are there any soft trails... in the whole larger Bay Area, really, but especially near Berkeley?

Sometimes I accidentally do something that strongly sets off my supervillain genes. It's not Super Ketonic Dietary Replacement Fluid, just a sort of grotesque hack to go alongside meals; but around the time that I took my unholy blend of 1tsp potassium citrate, 1tsp salt, stevia, 1.5 scoops strawberry protein powder, 2tsp raw potato starch, 3/4 cup MCT oil, and then *also* for the first time tried adding a packet of Emergen-C vitamins as a makeshift vitamin supplement, I began feeling a strong impulse to laugh maniacally and alliterate at length about this dread draught, the fell fluid I now title the Drink of Dismay.

"Copper is an essential trace mineral that cannot be formed by the human body. It must be ingested from dietary sources."  -- Wikipedia Guess Wikipedia doesn't believe in the fusion theory of metabolism.See Translation

If I can synthesize Super Ketonic Fluid and it actually does work well enough to be resold, then I shall find some safe food dye and dye it all dark red. That way, you meet your friend who you haven't seen in a while, and they look thinner and prettier and they no longer eat food and occasionally drink red liquid from a bottle. *Obviously* they've been turned into a vampire while you were gone.

Keeping in mind that this was not a nonsense sentence, but one intended to be interpreted semantically and nonmetaphorically:  By far the best Statistically Improbable Phrase I have heard spoken in the last six months is:  "You are no longer a houseplant, but your nipples are missing."

And now!  For the first time ever in human history!  An attempt to measure surgeon skill in the operating theatre, and calibrate the measure to outcomes!  Revealed for the first time ever:  Surgeons have importantly different skill levels which can be detected by watching them operate!  Will this skill ever be measured by a third-party certifier?  Will consumers ever be able to access a measure of surgeon skill, or just mortality rates vs. third-party prior ratings of patient prospects?  Will the worst, most lethal surgeons ever be fired?  All the smart money is on HELL NO because if you lived in that kind of civilization, it wouldn't have taken until 2013 to ask the question. Maybe Singapore will do it.

Human society quickly solved the problem of displaying a bubble with an amazon product whenever your mouse wanders over an affiliate link, or just a possible keyword. As for displaying abstracts when you mouse over bibliographic references in a paper, that's never been tried and might well be illegal.

From "The Perfect Health Diet", a tragic tale of dead babies and the difficulties of local hill-climbing when you don't have the right abstract knowledge. (This book seems incredibly well-informed (original quote included many footnoted references), I need to check with the community if I should believe everything in it. A great deal of earlier context in the original book had already established that excess omega-6 fatty acids are damaging.)  Also, am I missing something, ...

Not a misprint or bad reporting - the explanation is in the article, and I would not have guessed it. "Strangest of all was the ability of infected machines to transmit small amounts of network data with other infected machines even when their power cords and Ethernet cables were unplugged [i.e. running on battery] and their Wi-Fi and Bluetooth cards were removed."  Self-repairing malware that communicates with airgapped computers and can infect OpenBSD systems. Built by, and I want to emphasize this point, human-level intelligences.

In _My Little Pony: Friendship is Signaling_, Twilight Sparkle and her companions defeat Nightmare Moon by using the Elements of Cynicism to prove to her that she doesn't really care about darkness.

For the record, the *last* time I was at that house, there was *not* a nearly invisible glass door blocking the entranceway.

"Science is universal, and the same discoveries are made by the people with the same names, in the same numerical year under the local calendar system, across every alternate reality. In Middle-Earth there was still somebody named Kahneman and he published on the conjunction fallacy in 1983 of the Third Age, shortly after the Dwarves awakened Durin's Bane in Moria." My answer to an aspiring fanfic author on /r/HPMOR, on why he didn't need somebody from our world to be transported to Pokemon in order to write rationalist Pokemon fic with references.

I'm on Arc 11 of Worm, an online original free serial superhero novel, and so far none of the supposed smart people have done anything stupid; they credibly possess the level of intelligence they should have. They use their powers correctly and with Munchkinism aforethought. I only even noticed 150,000 words or so into the book that I wasn't noticing all the characters being idiots. Epic heroes and villains whose powers would merely entitle them to wallpaper status in a lesser story, except that they're using their powers *intelligently*. This is *remarkable*.

The opening lyrics to Friendship is Magic include:  "Big adventure / Tons of fun / A beautiful heart / Faithful and strong / Sharing kindness / It's an easy feat / And magic makes it all complete." So apparently if you happen to live in a universe where there's big adventures, tons of fun, beautiful hearts faithful and strong, sharing kindness, but *no magic*, you'll always feel incomplete.

An absolutely classic tale of bad science, science heroism, jaw-dropping obliviousness to incredibly blatant flaws, and the triumph of a lone student over a subfield. It even has Alan Sokal and the part where the big journal rejects the paper after sending it to the academic whose work is being criticized.

I'm 90% confident that there was a historical Jesus (because reasons) but even if I were not, this essay explains correctly why it would be stupid to choose that of all things as a battleground.

Myself to Brienne:  "My model of you understood what I was thinking when I said [blah]." Brienne:  "That gets me curious about what your model of me says about my model of you." Myself:  "Hm. Okay, before I reply, what's your current model of my model of your model of me?" Brienne:  "This relationship is bonkers."

I'd like to be the guy at the FBI in charge of answering FOIA requests from people demanding their own FBI files. I mean, you could have some fun with that. "Subject has requested own FBI file, probable sign of terrorist involvement."  [Aside from this, the file is completely blank.] "Subject appears completely loyal to the USA and has led entirely boring life. Good, obedient citizen."... "Subject may have been involved in planting explosives on World Trade Center towers." "Subject appears to lead an innocent life, but associates with many known or suspected criminals including international jewel thieves Mike Blume and Alicorn, retired assassin Anna Salamon, and ex-KGB handler Louie Helm." "After [REDACTED] subject was taken from [REDACTED] and raised by "Moshe Yudkowsky" and "Rachel Yudkowsky" (see attachments). Subject's true parentage remains unknown. Subject's residence has been examined several times but no trace of [REDACTED] has yet been found."

Well-informed criticism of my earlier 'politicians are a faction aligned against voters' model.

It seems unlikely that the Swiss will pass this (huge) basic income guarantee, but I'll go on record as making a very startling prediction:  That even if it passes and is implemented, it will not very much affect poverty and people will have to go on working awful jobs. The forces restoring the poverty equilibrium are tremendous. Compared to hunter-gathering, agriculture can sustain 100 times as many people per unit area of land... and there were still poor people, indeed more of them. Then agricultural employment dropped from 95% to 2%, implying a rather large increase in productivity of each farmer... and there were still poor people. They were, in many ways, better off, but they still existed in an environment of constant fear, scarcity, desperation, living hand-to-mouth, sometimes going hungry. Yes, they do outright *die* a lot less often nowadays, I am not denying progress. But there's still experienced poverty, even after one farmer became capable of producing 100 times as much food. There must be extremely powerful forces which enforce the existence of poverty. This basic income guarantee is not going to surpass them. I don't quite understand what forces underlie the Poverty Equilibrium. My guess is that there are many forces like rent and taxation which continue to extract value from people until they are so desperate that nothing more can be obtained from them. I also suspect that the temporary emergence of a middle class was an anomaly (I don't know why it happened) and that we are now watching the Poverty Equilibrium come back into force as rents rise, the cost of school rise, many people have to borrow for basic living expenses and have to spend more of their income on credit servicing - the systematic extraction of all but a tiny amount of value seems to be coming back into play. If productivity increasing by a factor of 100 didn't destroy poverty, then neither will this. All that will happen will be that Swiss rents will rise and their schools and healthcare will get more expensive... or something, I'm not sure what. I don't quite understand where the Poverty Equilibrium comes from. I do strongly suspect that after 10,000 years *this* will not be the final change that defeats it, especially when there doesn't seem to be any consensus on what forces underlie the Poverty Equilibrium in the first place.

Character 1:  "Someone has to make sure nobody destroys the world." Character 2:  "How did you get this job?" Character 1:  "I figured out that nobody else was doing it." -- Adventures in Effulgence, by Alicorn and others... Reading Yudkowsky-influenced fiction is really... *odd* for me. Little bits and pieces of myself inside fictional people who are not, in fact, me. It feels rather like John Malkovich must have felt like when he wandered into the world of John Malkoviches. Either that or my brain has never known what it is like to be in a world where it is at all normal, and weirds out at the experience.

Every time I read about what one of my acquaintances is going through in a medical internship, I have to hold down the impulse to assemble a band of plucky sidekicks and rescue them.

When I grew up, the most important part of the libertarian identity - at least the identity I heard about - was economic literacy; you were supposed to be the one who knew enough economics to identify the unintended consequences of the government-intervention proposals that naive people were enthusiastic about. Either this has changed over time, or a new divide has emerged between 'libertarians who read econblogs' and 'libertarians who don't read econblogs'. I therefore present to you the Libertarian Reflection Test, intended to be akin to the Cognitive Reflection Test, 3 tricky questions at successive levels of difficulty. To take the test, state an economically literate response to the following 3 proposals. Do not bother trying to make it persuasive to the general public, just state what would be your view of the proposal. 1. An explosion at a major gasoline refinery has caused a shortage which makes gas-station prices increase by $.50/gal nationwide. An influential Senator announces a bill to pay $.30/gal on the price of each gas purchase in order to make gas more affordable. 2. A bill is proposed to tax all imports by 10% and subsidize all exports by 10% (that is, 10% of each import purchase price goes to the government, and 10% of each export purchase price is paid by the government) in order to encourage exports, discourage imports and thus decrease America's trade deficit. 3. The bankruptcy of many major financial firms has produced a financial recession, despite a previous government attempt to bail-out those firms. The Federal Reserve has dropped the target Federal funds rate (interest rate) from 3% to 0.5% while announcing that it remains ready to respond to any signs of excess inflation. Neither of these interventions has fully prevented a recession and unemployment is on the rise, so the government now announces an $800 billion stimulus program - to be funded by issuing Treasury bonds rather than by increased taxes, of course.

Does anyone in the local community know how to tighten the hinges on a Samsung Series 9 NP900X4D 15-inch laptop?  I will use this laptop if its hinges can be tightened, resell it otherwise. (Sad but true.)  Googling didn't find anything.

Suppose a being exactly like me, with all the atoms in the same places, and possessed of all the same causal facts, and indeed also possessed of consciousness, except that it lacks the property of conceivability. Since this being is the same in all ways except for not being conceivable, we know that conceivability is a separate fact from consciousness. Thus, whether or not philosophical zombies are conceivable cannot tell us about consciousness.

Apparently even in China it costs $100m/mile for subway at best. Yes, that's 24 times cheaper than in NYC but $60,000/meter still seems quite expensive for a tunnel. What on Earth costs all this money, does someone know? Let's say I wanted to build a tunnel 2 meters underground, with no lighting or electricity, but that would remain dry when it rained. Say we want (automated electric) cars to drive along it - in the dark is fine, and the cars don't need a power supply. What would be the cost per meter of that - the bare-bones enclosed tunnel a couple of meters underground?

Erin:  "The government's been shut down!  Look out the window!  Can you see the chaos?  Neither can I."

You know, I *really* doubt that there's any simple way to embed a live video feed into a Beamer presentation... but if there is, please let me know. I'm writing a talk which (a) should be recorded, and (b) for which it would be highly appropriate to embed live video feeds of myself giving the talk, into the talk. Especially if the feed can be delayed by 10 seconds.

So my plan yesterday was to take a day with no computer, tablet, Kindle, or physical books in order to get some metacognition done about why I was having trouble getting started on my MIT talk. Result:  Spent almost the entire day lying in bed in a pseudo-REM state, then fell asleep a couple of hours early. Next day, lo and behold, writing the talk doesn't seem so daunting. I think I was just mentally and physically exhausted, *and* (this is something I reeeaally need to remember which is why I'm saying it in front of all my friends on Facebook) having access to a computer, maybe even a Kindle, was sufficient to prevent previous rest days from being restful.

I am so incredibly happy that these kinds of guesses are finally being tested. I'm so happy I'm smiling very slightly right now. Also, this is better than a journal because **no publication bias**.

Besides implementing a zero-angst policy, going to erotic hypnosis meetups to ethically obtain your blood supply, installing a sufficiently powerful lamp in your coffin-room that you didn't miss the Sun as much, and possibly (magical rules permitting) converting to an especially obscure religion so that people couldn't figure out which holy symbol would repel you, what would *you* do if *you* were a vampire?

I was laughing fairly hard at this after a while. Requires a very loose acquaintance with Friendship Is Magic. https://www.fimfiction.net/.../changelings-changelings-everyw...

Erin:  It's getting dark early these days. Myself:  Of course. As the power of evil grows, the sun fails and darkness covers all. Leaves wither on the bough and birds flee the land. The sky itself weeps, and a chill as from the grave pervades our very bones.

Brienne and I have created the following rough draft of an attempt at ketogenic Soylent, or as I prefer to term it, The Mildly Surprising Super Ketonic Dietary Replacement Weight-Loss Fluid - It's Not Food, It's Dietary Replacement Fluid!(R) If any of you think you see something that's going to go wrong with this, make your prediction *now*. No claims that you knew-it-all-along afterward shall be entertained; Soylent is a closed system, and if your model can make any prediction afterward, it ought to be able to make that prediction now. Speak now, or forever hold your peace when I say in the future that some human beings cannot undergo ketosis, or that ketosis fails to always produce weight loss. To put it another way:  Pretend that this formula failed to produce any weight loss. What will you say afterward was the cause? Main open questions I'm pondering:  Should I use more than 1866 calories to start, maybe some extra olive oil and flax oil, in case ketosis takes time to kick in?  Should I taper introduction of MCT oil and if so, how much MCT oil on which days?  How long is the mentally-disabled blah induction phase likely to last, do I have time to go through this before my MIT visit?  Is the ground flax a viable source of fiber and is it going to make the whole thing taste powdery?  Will this last through refrigeration for my Oxford visit in November, maybe if I add the MCT/flax oil/olive oil separately?  Is there a special dose of extra electrolytes which should be added while inducing ketosis? 1 scoop Gold Standard whey protein 1? tsp calcium citrate powder 1 tsp creatine ? cup+1 tbsp ground flax 4 tbsp Hershey's Special Dark cocoa powder 2 tbsp lecithin ? tsp potassium citrate on day 1, increase gradually to 1tsp by day 5, don't exceed 2tsp ? tsp iodized salt ? packet Emergen-C ? cup olive oil 1? tbsp flaxseed oil ? cup MCT oil Sucralose to taste We might need to add water to get the consistency right. Pills: 1 capsule vitamin D supplement/day 2 Opti-Women vitamins per day  1 capsule  MSM Totals Per Day Calories: 1866 Fats: 193.5g Carbs: 12g Protein: 54g Fiber: 25g Biotin 250mcg  Calcium 150mg  Chromium 120mcg  Copper 2mg  Folic Acid 600mcg  Iodine 200mcg  Iron 18mg  Magnesium 75mg  Manganese 5mg Methyl-Sulfonyl-Methane 1000mg Molybdenum 70mcg  Niacin 20mg  Pantothenic Acid 20mg Potassium: 5g  Riboflavin 20mg  Selenium 70mcg  Sodium 3g Thiamin 20mg  Vitamin A 5,000IU  Vitamin B6 20mg  Vitamin B12 100mcg  Vitamin C 250mg  Vitamin D 5000IU  Vitamin E 100IU  Vitamin K 80mcg  Zinc 15mg

Today is September 26th, Petrov Day, celebrated to honor the deed of Stanislav Yevgrafovich Petrov on September 26th, 1983. Wherever you are, whatever you're doing, take a minute to not destroy the world. http://lesswrong.com/lw/jq/926_is_petrov_day/

The graphics in Temple Run are even more amazing in 3D, as I serendipitously discovered just last night. To play Temple Run in 3D on your current, unmodified phone or tablet, just close or cover one eye while playing. (Alternatively - this is what I happened to try while making the discovery - let your eyes defocus, so that you see two copies of your screen, and then pay attention to only one copy.) The graphics will now appear to be in 3D.

I get back from my trip to Chicago, having spoken to someone (not Mom or Dad) who shall remain nameless, and I'm thinking, "Muggles really don't know how to think *at all*. And they don't know how to learn how to think or how to perform any sort of activity which will make them better at thinking."  And then I get back home, and run across this on Facebook. We forget, sometimes, just what is the alternative to being the sort of person who has an opinion about frequentism vs. Bayesianism.

So I'm playing Temple Run 2... and the thought occurs to me, "Who says it's okay to just swipe this idol?"  Then I suddenly thought back to Indiana Jones and "Raiders of the Lost Ark", which I haven't seen in, oh, a good long time, and I think, "How on Earth is it okay for Indiana Jones to just waltz in and take a gold idol?  That is _stealing_!  It is still stealing even if the idol was made by non-Westerners!  Someone put hard work into crafting that idol!"  Then someone else shows up and swipes the idol from Jones who is all indignant because the idol has ownership once a white person has laid hands on it. And then I understood the concept of 'colonialism' and why a lot of countries don't like the West very much.

"He thinks he's smarter and has a higher morality than the rest of us... that he can see clearer than other 299-million 999-thousand 999 of us, and therefore he can do what he wants. I say that is the worst form of treason." John Bolton on Edward Snowden #modesty_argument #antiheroism

If no hero however valiant or tyrant however terrible escapes your fell grasp once you've accepted your commission, you're spending too much effort on each assassination. #umeshisms

Dad to my nephew:  "What could you do with flash powder?  You could blow up your stroller!  That's right!  Your whole stroller!  Wouldn't that be fun?" Nephew:  (Cries.) I could write this as how Professor Verres-Evans interacted with Harry as a baby, and nobody would believe me. "Real life is unrealistic" is the trope they use to explain to novice writers how "But that happened in real life!" is no excuse because your audience won't believe it anyway.... Also, everything in my parents' entire pantry is nutritionally equivalent to a lump of sugar. I would say that this explains my metabolism, except that nobody else in my family is fat.

Summary:  8 of the original 14 are still polyphasic in some way, but they're only a month in or so. Note that the entire human species (7 billion people) spends around 1/3 of its days asleep or trying to sleep, that sleep is desperately important to human productivity, and that even many individual humans could potentially gain a great advantage over their peers by having more hours in their day (vide Time-Turners). So, given the total value of this information to the human ...species and even to many wealthy individuals, we should expect that these issues will be explored primarily in an ad-hoc, unfunded way by people in the quantitative self community, by unusually nonconformist effective altruists, or by people who can socialize within a rationalist community. As opposed to academic science, the Gates Foundation, the NSF, etc. Please also note that it doesn't matter if this study comes out negative, given the obvious net value of info we still have strong evidence for #civilizational_inadequacy #heroic_epistemology #nihil_supernum.

Myself to my sister's recent baby:  "Obi-Wan never told you the truth. I am your uncle."

Yvain:  "Skepticism and metaskepticism seem to be two largely separate skills. That is, the ability to debunk the claim "X is true" does not generalize to the ability to debunk the claim "X has been debunked"." Commentary:  Looks like the same skill to me, especially if we consider 'debunking' to only be a skill insofar as it fires for false rather than true beliefs. The reason they seem to come apart in practice is that there's a large population of unskillful loud people on the Internet who enjoy the feeling of superiority which comes from believing that you've found a flaw in someone else's belief. They repeat the words of some skillful skeptics, but have little or no ability to distinguish good skepticism from bad skepticism.

As Yvain points out, hot dogs being sold in packs of 10 and buns being sold in packs of 8 is the sort of thing any bun-seller could see how to fix in 2 seconds of thinking. So why does the condition persist?  This is a good test of your belief in Civilizational Inadequacy - do you think that further investigation would show some kind of mysterious mix of self-interest and cooperation, like every bun-seller knowing they can sell more buns that way and none defecting from the ...collusion?  Or would you expect that further investigation would show that there was no such selfish reason? To be clear on what The World Is Mad hypothesis says, if we find that a company which sells buns in 10-packs sells fewer buns than its competitors, the world is not mad. If someone started a company like this and it briefly outsold the competition before supermarkets refused to carry the product because total bun sales dropped, the world is mildly mad - there's a self-interested explanation, but so what, you still can't get the right number of hot dog buns. If there's a company which packages buns in 10s and it's doing fine and it just happens that nobody else has tried it because Tradition, then the world is very mad. I have not yet tried to see if anyone else has found this answer. I put 10% on not-mad, 35% on mildly mad and 55% on very mad, assuming this question can be definitely resolved by research - an economist arguing for 'not mad' or 'mildly mad' without strong evidence does not count as a resolution!  What do you think?

I don't see how this could possibly be good for the Catholic Church. Good for humanity, yes, but I don't see how it could be good for the Church. I make the falsifiable prediction that during Pope Francis's tenure the Catholic Church will shrink, its proportional membership will diminish and its contributions per member will drop. God cannot survive without hate.

Thumbnail doesn't come through as animated gif and may confuse some people, so don't add an image when sharing this. Interesting as optical-illusion phenomena go, I had not seen this one before. Really we don't have nearly enough animation-based optical illusions.

Brienne:  "I have some problems with the axioms of Gricean implication." Myself:  "What do you expect me to do about that?"

In reply to a question about whether I expect actual progress from Google's anti-Death program: "Unless they're doing something very unusual, by default I expect no significant progress. Science bureaucrats can only give money to other science bureaucrats. Larry doesn't seem to be investing personal effort and expertise like Elon. Maybe the Genentech guy can make actual progress happen but by default the answer is no." This estimate is subject to revision if their effort is structurally different from other attempts to throw money at medical R&D - for example, if they're mostly prize-driven rather than 'decide who is reputable enough to get money' driven.

Shnorkies!  When did roughly half of HN become enlightened?

In the depths of the Great Stagnation, all remaining significant technological progress occurs because some ascended post-exit Silicon Valley mogul decides to spend their own money to make it happen, out of the goodness of their hearts.

Just got my first tablet (Nexus 7, used). Any good Android puzzle games for people who experience average Android puzzle games as trivial?See Translation

Apparently the ongoing stock market rally is being referred to by some (e.g. Art Cashin, director of floor operations, UBS) as the 'rationality put'.

Tyler Cowen: "Throughout the 1970s and most of the 1980s, the so-called 'right wing' was right about virtually everything on the economic front. Most of all communism, but also inflation, taxes, (most of) deregulation, labor unions, and much more, noting that a big chunk of the right wing blew it on race and some other social issues. The Friedmanite wing of the right nailed it on floating exchange rates. Arguably the "rightness of the right" peaks around 1989, with the collapse of communism. After that, the right wing starts to lose its way... Starting in the early 1990s, the left wing is better equipped, more scholarly, and also more fun to read." Okay, so I *wasn't* just completely hallucinating in thinking that when I grew up the Republicans, at least in ideology, were the forces of sort-of economic sensibility. I just wasn't sufficiently in the loop to notice immediately when the tide shifted. Today of course the Republicans are horrors from beyond the gates of the spaceless void bent on devouring the souls of all humanity. [Link corrected.]

Summers has dropped out of the race for Fed chairman. This is the most important event of the month that most people won't care about. According to Scott Sumner (no relation *whatsoever*), the S&P being up by 1% on this news is probably an underreaction because apparently several Democratic senators on the key banking committee had already withdrawn support for Sumner, i.e., the 1% rise is just the last bit of icing on this cake. Note that according to the most intelligent economic analysis I know of, this rise in the S&P represents 1% increased expectations of *real economic growth* based on being *sure* that Summers won't be appointed Fed chair. Furthermore, the market knows this. Consider what this means for his having almost been appointed in the first place. It's great news for the U.S. over the next dozen years. Possibly not such great news for the future of the galaxy, depending on whether economic growth helps AGI more than FAI. However, depending on exactly why Summers dropped out, it may also be good news about the influence of science on politics. Not overwhelmingly good news, because as Dario can attest, I did *not* feel certain that Summers would be confirmed and was surprised that Dario thought he was a shoo-in on the basis of political clout (apparently Dario thinks the world is crazier than I do). The key question from the global-sanity perspective is whether this was driven by the letter from 300 economists pleading with Obama not to appoint Summers, or whether it was other political factors. As Scott Sumner observed, a recent Atlantic magazine article entitled "The Comprehensive Case against Larry Summers" contained no mention whatsoever of Summers's views on monetary policy. The US has dodged a major bullet nonetheless. Earth's state is the same as ever, possibly slightly worse. Mixed feelings as always when I hear about economic news.

Patrick was recently mentioning a card he'd invented (for a strategy game with some blank cards) called Tragedy of the Commons:  "Each other player may choose to draw a card, or not draw a card. If all other players draw cards, you win the game."  This started me thinking of what other cards might be part of a more-than-two-player game which could create more complicated incentives than just wanting to damage other players: Blackmail:  Choose a target player with more life points than you, and name a number X of life points, along with an action or condition. If target player does not perform the action or fulfill the condition, they receive X damage and you sacrifice X life points. Reluctant Protector:  Use during your turn only:  Target player with more life than you receives 1/2 of all damage you receive this turn. (The damage you receive is not reduced.) Precommitment:  At the start of each turn, you may name something you will do or not do, for example, "I will not give into any Blackmail card" or "I will not spend more than three mana healing any other player."  The precommitment may be arbitrarily complex and contain any number of 'and' clauses. If you fail to fulfill your Precommitment, you lose the game. Unfortunate Incentives:  Choose two target players. Each gains 1/2 many life points as any damage dealt to the other player, until the end of the round.

I wonder if the constant worry that parts of the world which seem crazy, might actually be highly competent elites who you shouldn't dare disagree with, might have something in common with social anxiety.

My dreaming brain thinks that the War of English Revolution was fought at Agincourt against Napoleon in order to establish the primacy of the industrial revolution in Britain, complete with visuals of peasants in a smoky, dim-lit library preparing for combat, along with a narrative voiceover about how the decisive feature of the battle was that the English had twice as much clothing per capita because it was cheaper.

Since people are crazy and the world is mad, I wouldn't find it particularly surprising if an acne medication treats a particularly hard-to-cure form of schizophrenia, studies demonstrate this, and yet nobody has heard of it because the drug is off-patent and nobody has a financial incentive to push it through. If you aren't willing to shrug and say the world is mad, what's your excuse?

It's my birthday. (Thud.)  Happy birthday. (Thud.)

I have now read about MCT oil, which allegedly gets converted directly into ketones, which adipocytes allegedly don't absorb. If so, MCT-oil calories should *actually* be available to my brain instead of being sucked out of my bloodstream by fat cells. I'm rolling to disbelieve, and am consulting my Facebook network for the +6 bonus to my saving throw vs. possibly bogus dietary info. Kevin Michael William.

Counseling Psychology is the lowest-paid major *ever*, beating out Childhood Education. Going to college soon?  Be sure to take a good look at this graph, it's probably the only info you'll ever get about the economy's central allocation question, unless you go looking for more.

[Corrected.]  The Ultimate Newcomb's Problem: You see two boxes and you can either take both boxes, or take only box B. Box A is transparent and contains $1000. Box B contains a visible number, say 1033, and the Bank of Omega, which operates by very clear and transparent mechanisms, will pay you $1M if this number is prime, and $0 if it is composite. Omega is known to select prime numbers for Box B whenever Omega predicts that you will take only Box B, and select composite numbers if Omega predicts that you will take both boxes. Omega has previously predicted correctly in 99.9% of cases. Separately, the Numerical Lottery has randomly selected 1033 and is displaying this number on a screen nearby. The Lottery Bank will pay you $2 million if it has selected a composite number, and otherwise pay you $0. You previously played the game with Omega and the Numerical Lottery a few thousand times before you ran across this case where Omega's number and the Lottery number were the same, so this event is not suspicious. You have two minutes to make a decision, you don't have a calculator, and if you try to factor the number in your head you will be run over by the trolley from the Ultimate Trolley Problem. Do you take only box B, or both boxes?

Does anyone know what trends in the "labor share of income" look like if we exclude the income of executives?  Or more generally, what does the labor share of income for the bottom 90% look like?

Both men professed to love animals after Mr. Lhota was questioned about his much-publicized declaration, made after part of the subway system was briefly shut down last month to protect two lost kittens, that he would not support stopping transit service for kitten safety. "I'm not the anti-kitten candidate," Mr. Lhota said Sunday, adding, "We have thousands of cats -- literally thousands of cats -- that are in the subway system every single day, day and night, scurrying across... the tracks, and they don't get killed." "I never said I wanted to kill a cat," Mr. Lhota insisted. Mr. Catsimatidis seized the opportunity to differentiate himself, saying, "I love animals, I love cats, I love dogs." He said that Mr. Lhota's stance against the kittens reflected his "inner emotions." -- It seems to me like a reasonable public policy to ask people how they stand on an issue like this, and if they say to protect the kittens, quietly arrange for the electronic voting system to ignore their votes.

No general procedure for bug checks will do. Now, I won't just assert that, I'll prove it to you. I will prove that although you might work till you drop,  you cannot tell if computation will stop.

Overheard at the current decision theory workshop: "What is the largest value of 5 for which this works?" "I consider blackmail and negotiation to be the same thing." "We're trying to work out the conditional independences for CooperateBot playing against itself."

Going on considerations of scope, the most epic possible story would be one in which the Tegmark Level IV Multiverse is invaded by That Which Doesn't Run On Math.

Has anyone in the realms of philosophy of mind ever suggested that building a brain out of twice as much material stuff - wires twice as large with twice as much electricity flowing through - leads there to be twice as much person-fluid or experience-weight contained within?

It's being alleged here that lower-priced capital does produce a lower labor share for income, because capital can substitute for labor and agents will use more capital as the price goes down. I would consider the labor share of income to be one of the great issues of our times (among the economically literate), so this is important if true. Obvious question:  Is the labor share of income lower now than in 1850?  Certainly *vast* quantities of capital equipment are priced lower now than then, and it was harder to access capital markets. (Looks it up...) This says *no*:  http://e-archivo.uc3m.es/bitstream/10016/406/1/wh031006.pdf

Never send to ask who the bell tolls for.

To play the right-mind-person not-use-words game, you must say what a thing is without saying the words most often used to say it.

This is a beautifully visualized and quite helpful resource; a shame that it only appears so late in humanity's history. When I saw the front page I thought it was only displaying contradictions, but if you scroll down there's more. I would've liked to see attempted religious rebuttals, and counter-rebuttals, to each item; but there does exist some volume of examples which cannot be denied even if you only see half the argument map.

LLLOL (literally literally laughing out loud).

Are they fucking kidding?

Best supervillain origin ever. It is later shown that he keeps to the whole philosophy, too.

Starting on the opening pages of Christopher Hitchens's _God is Not Great_, just to check whether I could easily do better. The answer is no. This is what writing sounds like when the author is skilled, and not holding back. I expect you won't learn anything new from this book about rationality, but you might learn something about writing.

Fascinating and a bit scary. First thought:  You could certainly make the case for similar tendencies now. Second thought:  Are those tendencies anywhere near powerful enough to make up for the enormous flood of energy into attempted innovation?  Third thought:  There may be a lot of wannabe-innovators but they're almost all entirely ineffective, so maybe. I wish econ growth -> sci research -> faster UFAI wasn't an issue so that I didn't have mixed feelings about this sort of thing. Virtuous people should be able to just label it 'bad'.

"For thousands of years, mankind has dreamed of destroying the sun! But today, I shall go beyond that! I shall exceed the greatest dream of humanity, and I shall devour the sun!" - Pope Obteneratus III (in _Overlady_, ch. 31)

Just used a Zeo sleep-recording device for the first time. It claims I get very little deep sleep - looked like a single downward spike on the graph, though afterward it said 45min and I'm wondering if that was rounded or something. Zooming in showed that even this deep sleep didn't occur as a solid block but as a few downward spikes from light sleep. Interesting.

Tumblr update:  _To Create An Awesome Character, Envision An Awesome Destiny_ I find that fiction writing in general is easier for me when the characters I'm working with are awesome. The most important lesson I learned from reading Shinji and Warhammer 40K is that every character has the potential to be awesome - I'm thinking particularly here of when a random bridge bunny ends up holding off a riot using a fake movie-prop chainsword and Kensuke being turned into a Techprie...

Important:  Louie Helm says: "The standard citation for the claim that "the best programmers are 10x better than average ones" actually says something terrifyingly different: 'The horrid portion of the performance frequency distribution is the long tail [...] in which one poor performer can consume as much time or cost as 5, 10, or 20 good ones.'... Translation: A small number of the very worst programmers are very bad. These bad programmers are 5-20x worse than the very best. However, the best programmers are only 2-3x better than "average" ones in this study...."

My favorite LW post since a while, by Robby Bensinger (RobbBB@LW).

So what we ought to do is find some atheist male, with a very high sex drive and rated very highly by previous partners on dimensions like sex positivity and encouragement, and have a project to arrange for him to get together with *73* virgins. Just to be like, "This is what you can obtain in *this* world for *not* crashing planes into buildings." (This is in no way meant to imply that I personally endorse virginity as a sexual ideal or the concept of 'taking' an objectified virgin as some kind of sexual triumph, etc.)

Tumblr update:  Why isn't Googology a recognized field of math? Why isn't googology (the study of large numbers) a recognized subfield of mathematics with its own journal? There's all these different ways of getting large numbers, and different mathematical questions that yield large numbers; and yet all those vast structures are comparable, being either greater, less, or the same. The process of considering how to construct the largest possible computable numbers naturally yields the recursive ordinals and the concept of ordinal analysis. All mathematical knowledge is in a sense contained in the Busy Beaver series of huge numbers. You'd think there'd be more Math done on that, rather than there just being a recently-formed Googology Wikia. Three hypotheses come to mind: 1) The process of determining which two large numbers is larger, is usually just boring tedious legwork and doesn't by itself produce new interesting insights. 2) By Friedman's Grand Conjecture, most proofs about numbers can be formalized in a system with an ordinal no greater than ?^3 (omega cubed). Naturally arising huge numbers like Skewes' Number or Graham's Number are tiny and easily analyzed by googological standards. Few natural math problems are intricate enough or recursive enough to produce large numbers that would be difficult to analyze. 3) Nobody's even thought of studying large numbers, or it seems like a 'silly' subject to mathematicians and hence is not taken seriously. (This supposes Civilizational Incompetence.) I would think (2) most likely rather than (3) in this case; someone like Conway, who invented the surreal numbers, would not have balked at... inventing Conway chained arrow notation, come to think, possibly as late as 1996 from what I've read, and that's just up to ?^2. Hm. Maybe it is just Civilizational Incompetence and the googology wiki will blossom into a new field of math? I honestly don't know.

I am beginning to wonder if Zhang Yue of Broad Group - the Chinese company which has that famous Youtube video of a 30-story prefab hotel being erected in 15 days, and which is now looking to construct Sky City, a 202-floor 838m skyscraper, in 7 months - could perhaps be a Good Guy. Zhang Yue is making *numerous* good-guy noises, e.g. the word 'rational' appears several times in his statement responding to criticism of Broad Group, but the line that really jumped out at me was: "Groundbreaking to completion the Empire State Building took only 13 months, which, however, occurred 80 years ago. Did humanity regress?" I mean this is essentially the exact rhetoric which Michael Vassar would use if he was constructing skyscrapers in China.

Honestly I *am* somewhat concerned that in 20 years we will be hearing from the nascent Paleo Sleep movement. But that kind of maybe-possibly concern may not be a sufficient reason why we should all stay motionless for 8 hours per day.

So I'm late to this party, but still:  

The form of the Enemy loomed huge on the horizon, a living castle of dark flesh, brown-grey and pulsating, folds of tissue the size of mountains, huger than her mortal mind could comprehend. She wiped her forehead grimly, clearing her eyes of sweat. She hefted her sword in both hands, channeling just enough mana to light the blade with silver glow. Small and lonely her form, a dust speck against her foe, the light of her sword invisible against the flesh-mountains. It wasn't ...the most winnable battle ever. Gritting her teeth, she charged forward anyway. It seemed ages later that she was panting in the middle of a sea of ashes, the charred remnants of the Enemy scattered widely around her, red-glowing with fading fire. Her own flesh was torn and bloody now; would always be scarred, from this day. Her body finally exhausted, along with her mana, her ki, her willpower, her aura, and her soul's energies. But the war was won. It was over. It was done. And things would be easier, from now on. Everything would be easier, with the Enemy finally conquered, no longer an obstacle to every single damn thing she tried to get done. She could feel the relief through her whole body as her clenched will relaxed, knowing that it was over, all over, that it was all finally over - And then she woke up, eyes blinking away the light crust of sleep that blurred her sight of the grey dawn's light seeping through the windows of her apartment. She lay there for awhile, wishing futilely that she could go back to sleep. It was too early, said the shade of blue-grey light, the color of 6AM. And she knew that she would be bleary and weary and slow this whole day long, for lack of sleep. But she knew by this point, from sad and long experience, that she could lie in bed all she wanted, for hours even, and she wouldn't fall asleep. Her brain wouldn't let her. It still took a while to make herself accept the reality of that, as she lay motionless in bed, wishing that things were other than they were. Hyperbolic discounting ensured that the brief shock of cold air from removing her blanket, loomed larger in her thoughts than the minutes she was wasting; and she was too sleepy and exhausted to use the discipline to counter that. She knew that being bitter about the whole thing would just waste mental energy, and possibly apply some type of negative conditioning on waking up or getting out of bed. And yet she couldn't make herself stop being bitter. Stupid dream... As she stumbled off toward the shower, some final remnant of dreamlike state provided her ears with an auditory image; she could have sworn she heard her brain, laughing.

Needs more contrived torture scenarios.

Does anyone I know have more use than a car-junking place for a 1997 Crown Victoria with a flat tire and in need of new catalytic converters to pass smog, which has been sitting in our garage for around 8 months and might or might not start?  Otherwise we're about to toss it for the junk price to free up space in our garage.

"Safe, sane, and consensual", they say. Obvious question:  What is 'sane sex' and how is it different from safe, consensual sex?

Now I want to see an Effective Altruist-style presentation on fighting monsters. "If an elder vampire kills just 1 person every month for 100 years, killing them can save 1,000 lives. The Slayer claims to hunt down 2 elder vampires every year on an annual budget of $100,000, which appears at first like an extremely favorable QALY/$ ratio. However, we question whether the Slayer can become substantially more efficient with more marginal funding - as a single individual, she cannot expand her operations in the same way as the Against Zombies Foundation."

P/S/A:  If one of your acquaintances thinks Richard Dawkins is arrogant, you probably shouldn't try to make them read HPMOR.

Currently feeling good about having sent out Brienne to buy K'Nex so that she could build a 3x3x3 cube with the appropriate diagonals, along with 3D simplexes, so that I could follow the 3D version of this N-dimensional proof of Brouwer's Theorem. It was helpful, and I feel like I am being properly Munchkin about turning money and a slave into mathematical understanding.

Huh. Shouldn't this information totally not exist or be highly guarded?  How does this work?

So as of right now, though I haven't looked everywhere, the best online explanation/proof I've found of the Bolzano-Weierstrass theorem is this rap. (Will, any relation?)  This does encourage me somewhat to eventually write an explanation of recursive ordinals as a shounen manga.

Are there any completely reliable methods of weight loss besides mega-liposuction and adipotide? By "completely reliable" I mean that their theoretical and pragmatic efficacy is not subject to revocation by quirks of metabolic disprivilege. So "starve yourself" doesn't work because its pragmatic efficacy relies on your fat cells being willing to relinquish lipids before your body cannibalizes muscle tissue and otherwise starts doing serious damage to itself, which your fat cells can just refuse to do if you're metabolically disprivileged. Mega-liposuction and adipotide don't care if your fat cells are malfunctioning and refusing to release lipids. They just physically kill or remove fat cells. Anything else like that, or which operates at a similar level of disregard for metabolic disprivilege? Interventions that operate orthogonally to malfunctioning fat cells or other metabolic disprivilege only, please. I will delete comments suggesting diet or exercise.

Harry's cynicism in Ch. 97 about journalism is derived from my observation that mainstream journalists *cannot* accurately report on Bostrom's Simulation Argument that Not(1 And 2 And 3) where 1 is "We will survive", 2 is "If we survive we'll make lots of ancestor simulations", and 3 is "We are probably not living in a simulation."  A newspaper just *can't* report the complex, non-atomic sentence stating that these three propositions are mutually incompatible. They can *only* report:  "Nick Bostrom thinks we're living in a computer simulation!"

Your daily failure of elites when lives are at stake: The $1 trillion F-35 aircraft is slow and unmaneuverable, and will be 'clubbed like baby seals' by Chinese/Russian knockoffs with the worst design elements of the F-35 subtracted.

Chesterton's Absence of a Fence:  Never put up a fence until you can explain why someone else didn't build a fence there earlier, to the satisfaction of a sober-minded skeptic who thinks it improbable that you're somehow better than all the other people who could've built a fence. (Explicit subtext:  It sometimes makes sense to ask why somebody did something, on the occasions where people actually do something. For inaction, even the inaction of large groups, looking for some sort of elaborate story is overreaching - you shouldn't be *trying* that hard to explain it. Also, you can easily acquire a comparative advantage versus various "elites" on the many, many occasions where you are there and trying to do something, and they are not.) #heroic_epistemology #nihil_supernum

Most of my utility from carrying a cellphone would be gained from carrying a *small, light* credit-card-sized object, with an e-ink display, which could only send and receive text messages.

So the first problem I spotted is, rivers don't run. They don't have legs, right?  Rivers flow. And if water is inside a cavern, it's not a sea, it's a lake. So: In Xanadu did Kubla Khan  A pleasure dome decide to make Where Alph, the sacred river flowed... Through caverns which no man had knowed Down to a sunless lake Recite my version to your English major friends, they'll love it. #revisedclassicalpoetry

#revisedclassicalpoetry Two roads diverged in a woods, and I Stepped on the one less traveled by Yet stopped, and pulled back with a cry... For all those other passers-by Who had this road declined to try Might have a cause I knew not why What dire truths might that imply? I feared that road might make me die. And so with caution to comply I wrung my hands and paced nearby My questions finding no reply Until a traveller passed nigh With stronger step and focused eye I bid the untouched road goodbye And followed fast my new ally. The difference made I'll never know 'Till down that other path you go.

Well said.

"It is the proper duty of every British subject to come to the aid of the TARDIS." - Steven Moffat, explaining why he turned down the second Tintin movie for Doctor Who

Today I have asked my first question on MathOverflow. Vote up if you also want to know the answer.

I have created a new subject of careful thought. <3

When John Baez visits the MIRI workshop, he needs to invent an amazing new formulation of decision theory so we can call it Baezian decision theory and confuse everyone forever bwahahahaha.

Qualia of Purple (Murasakiiro no Qualia) passes the IQ test. It's sad that this is now something like my bare minimum for being able to really enjoy literature, but there you go. HT Gwern. > "Hatou Gaku has a very odd friend at school named Marii Yukari. Yukari has purple eyes and a bizarre way of looking at the world: she sees all living things as robots... Yukari insists that the things she says she sees is true, and her vision seems to give her insight into the abilities of others... However, there is one important distinction among those who see humans as other objects. Do humans appear as unimportant as objects, or do those objects appear as important as human beings?" And then things start to get weird. If 60% of Greg Egan wrote a manga, it would be this.

#ThingsIMustNotWrite: A version of the _Foundation_ trilogy where Hari Seldon is just a conventional macroeconomist (well, market monetarist) and the Empire is collapsing due to deflation and software patents, with John Galt as the evil Austrian economist threatening the nascent Foundation from within. ...The horrible thing about breaking the taboo against fanfiction is that an ordinary writer has to only resist the temptation to modify their *own* stories.

My reply to Holden's reply to my question on GiveDirectly. Posting here in case somebody can tell me what I'm missing economically before I bother Holden again.

We need a compact name for That Incredibly Annoying, Logically Rude Way Of Talking As If Your Moral, Procedural, or Epistemic Standard Is Clearly Visible To The Other Person And Their Departure From It Is Only Explicable By Sheer Intransigence, And Everyone Should Be Expected To Agree With This Without Any Further Evidence. E.g. "It's ironic that they call their blog 'Overcoming Bias' when they're so biased themselves."

> "If you are a good person and think intelligently about things, Harry includes you within his circle of affection, otherwise you are simply part of a utility function." Ring of truth, there. I feel sympathy for random, not-known-to-me-personally human-shaped objects as I see them suffering or even see an unusually good opportunity to help them. I wince when I hear about bad things happening to statistical masses of people whose very existence I know only from the news. But that doesn't count as being part of my circle of affection. And learning more about a human not in the 'good person and think intelligently' set is not likely to cause my circle of affection to extend thereby - although it should be said that 'think intelligently' consists not in impressive mathematical feats but the degree to which you can see things that I consider far more obvious. And with all that said, people whose utility function is circumscribed only to their circle of affection are part of the problem, because that's a really tiny utility function. So of course my utility function is wider. How couldn't it be?

Currently up to $68K of $200K. Time remaining is until Aug. 15.

Brienne has proven that all finite sequences of the words 'buffalo', 'police' and 'fish' are grammatical. E.g. "Police buffalo buffalo fish fish".

Machine learning algorithm:  First you try linear regression. Then you see if you can improve on linear regression. Then if you can't improve on linear regression you walk away.

SPARC teacher:  "You should be more rigorous. My model of a SPARC student is worried about lack of rigor - they want you to say what's a function, with what domain, and so on." Paul:  "My model of a SPARC student wants everything to be strongly typed because they're doing type-checking." Me:  "Oh, *now* I understand!  'Rigor' always seemed very vague to me, I mean, what the hell is 'rigorous', but I can totally understand what it means to type everything."

Bleg to EAs:  Besides the Giving Game, and Holden asking the audience at the EA Summit to raise their hands to try predicting positive vs. negative vs. no effect on previously tested interventions, what exercises have been used to teach effective altruism and the cognitive skills thereof?  Assume that we can give people paper and 5 minutes and ask them to use math as required.

Michael Vassar is a PC, but who he *wants* to be is the character with the giant yellow exclamation mark over his head who gets to give PCs quests by making cryptic statements.

Which of these interventions do you expect to have positive, negative, or no effect?  I took notes in a separate document and got 8 out of 8 correct on yes/no, though due to misreading the instructions I didn't distinguish 'no effect' from 'negative' (except that I did correctly distinguish negative vs. positive vs. no effect on the 2 items where Holden asked for raised audience hands at the EA Summit; details in a comment on the post). I mention this because Carl sometimes asks me "How have you tested your intuitions?" and I would surely accept more tests like this, albeit I would prefer contexts where the importance of metagaming is reduced. If I'd been asked to assign probabilities I would probably have been significantly underconfident and expected to get 2 of 8 wrong. I'm also curious as to how Givewell's folk compared. Also, is there a more difficult test which I would be expected to fail and which Carl would expect to win on?  (E.g. that dice game or the trivia calibration game, both of which I've had less practice at specifically though, and which aren't charity-specific.)

An important cautionary tale - due to spreadsheet errors, published estimates of $/QALY for deworming were off by two orders of magnitude. Givewell's account of how they tracked down the error is intriguing and applause-inducing; it started with the realization that almost all the supposed benefits were allegedly coming from reducing cognitive disability from one particular type of worm, which seemed off...

(Mildly nsfw.)  The more I think about it, the more I realize that Catholicism is the most BDSM religion ever. Chastity. Punishment. Uniforms. People in monasteries whipping themselves and wearing hair shirts. Nuns checking the underclothing of schoolgirls for evidence of naughty thoughts (apparently this was a thing). I literally don't see how it could be pushed any further while still maintaining the veneer of denial that it isn't sexual. It's actually kind of sad that it's no longer possible to start a religion like this and have it be taken seriously, because it would only take a few minor adjustments to create BDSM-optimal Catholicism.

Oo. Good question. The big obvious candidate for me is the Orthogonality Thesis:  Sufficiently advanced minds can have almost any kinds of goals. Second big obvious candidate:  That humanity really seriously actually might die before flowering.

My latest. Current unemployment has nothing to do with current AI. *Maybe* someday, but the future can't be a cause of the past, and AI causing unemployment later can't cause unemployment now. The Great Recession was not caused by a sudden increase in automation!

Mainstream religion doesn't make sense even on an emotional or literary level, which is why most modern fanfiction that needs a background theology will use either _Sandman_ (Destiny, Death, Dream, Desire etc.) or _Oh My Goddess_.

Currently debating David Brin and PZ Myers on immortality. http://www.youtube.com/watch?v=Pm-5s__aZE0&feature=youtu.be

fubarobfusco:  "What ideas do I possess that the Devil? approves of me possessing because they undermine my ability to accomplish my goals?  (?) 'The Devil' is shorthand for a purely notional opponent whose values are the opposite of mine." http://lesswrong.com/.../.../i0b/open_thread_july_1622_2013/9dzn

Entering into the darker and more extreme depths of BDSM exposes you to certain awful, forbidden temptations which must be resisted, no matter how strong the impulse. I am referring of course to the temptation to blog about it.

The article below was written by Yvain, who just started practicing in a modern hospital. Some people consider Professor Quirrell a cynic but the truth is that real life is so vastly more insane that there is no way to have it make sense even as a story allegory. You'd need Azkaban to have been built as an old-age home for people's beloved parents because they can linger for another few years, before finally dying, if they're being eaten by Dementors. Scott's description of a modern hospital reads like a description of Azkaban right down to the screams coming from behind locked doors, only with more grotesque tortures than just your life and happy memories being drained away. What the FUCK is wrong with our civilization that we would rather torture old people to death to show how much we care, and then they inevitably die ANYWAY, rather than sign them up for cryonics so we could let them go peacefully knowing we'd done our best and that they might actually have a chance at coming back.

Professor Quirrell's arguments in Ch. 95 were inspired by conversations with Michael Vassar. Michael Vassar is basically Professor Quirrell with a phoenix.

I've 'intended' to get around to selling T-Shirts for roughly the last 8 years. Katie Hartman in her magnanimous awesomimity, with assistance from Michael Keenan, is now setting it up. If you think you might want a shirt saying "There is light in the world, and it is us!" or any other Yudkowskyism, please indicate your buying desire here.

I think a lot of people are temporal solipsists. They don't truly believe (alieve) that their future selves exist.

God damn it, how can I read through the draft and not spot the inconsistent timing in the first paragraph, but as soon as it actually goes online and I check it at HPMOR.com, *then* I see it?  I'm giving up and changing the story time of Ch. 95 back to late morning - I tried to move it to the afternoon, but if I missed one reference I could easily have missed others.

Have you obtained magical girl powers?  Try synthesizing element-126 (the island of stability). Then give it to professional scientists to verify that it has the right properties and to test out for research purposes. Also deduce that this means the objects you're created probably aren't summoned matter, since the universe probably doesn't contain much element-126. Wonder why the energy blasts you can create are so much smaller than the corresponding amount of mass-energy needed to create whole objects. Saga of Soul passes the sanity check.

I like the quote. But shouldn't the woman be, well, not pretty?  Unless she's from a ficton in which she has major depression in which case sure.

It's when you begin to see yourself as the guy in the red plaid shirt that you start taking responsibility.

FYI currently looking extremely improbable that I will update HPMOR on Monday (it's the last day of the workshop and I'm pretty worked-out). 95% I will update Wednesday.

These authors don't like observational (correlational) studies: "We ourselves carried out an informal but comprehensive accounting of 12 randomised clinical trials that tested observational claims - see Table 1. The 12 clinical trials tested 52 observational claims. They all confirmed no claims in the direction of the observational claims. We repeat that figure: 0 out of 52. To put it another way, 100% of the observational claims failed to replicate." I mainly take the lesson "Death to p-values and small effect sizes."  Randomized trials fail to replicate too.

Apparently the pro-resurrection Methodists have declared themselves to be Team Zombione.

Will Sawin, explaining how the L3 agent works:  "Find an agent which L2 *understands* and *fears*. Then, run that agent."

"Because it's not a Nash equilibrium" is a great explanation of why many possibilities in the world are not realized, except of course for everything that isn't a Nash equilibrium.

What is with all the emphasis on 'rapid inductions' in online discussion of hypnosis?  Are people honestly that impatient?  ...of course they are. But still, you'd think that for early students of hypnosis the big emphasis would be on maximizing the probability of getting some positive results on the first try, and the easiness-to-learn-remember-and-use of the inductions, not on trying to hypnotize a new subject in 30 seconds via some elaborate special technique... oh, never mind, people are crazy, the world is mad.

"Submissions are welcome on all aspects of causal analysis, especially those deemed impossible."  -- Judea Pearl, announcing the first issue of the Journal of Causal Inference. (Pearl has no particular reputation for advocating heroic epistemology, but he did co-invent an entire field from scratch. Doing that is likely to confer some amount of heroic epistemology, displayed here in casual passing.)

I'm going to skip today's possible HPMOR update. No complaints please, you got that update on Sunday the 7th instead.

"Betting Therapy" should be a thing. You go to a betting therapist and describe your fears - everything you're afraid will happen if you do X - and then the therapist offers to bet money on whether it actually happens to you or not. After you lose enough money, you stop being afraid.

This crosses the line from pandering into adorability.

A heartwarming review of CFAR. Somehow establishing a market niche for real actual evidence-based human optimization practices marketable to intelligent skeptics who correctly consider themselves to be above the derpy 'self-improvement' marketed to epiphany junkies seeking their next dopamine hit of hope and illusionary progress, is exactly how I'd describe the concept of CFAR. That and eventually iterating far enough to produce Gilbert Gosseyn.

Qiaochu:  "But what does it *feel like* to see a nonstandard number?  What does it feel like to see a Turing machine halt at a nonstandard time?" Me:  "I can't describe it because it involves a nonstandard quale."

Minor household rationality practice:  Saying "Yay for experimentation!" or "Hooray for value of information!" every time Erin tries cooking a new dish and I turn out not to like it.

I like how I can talk about Hermione becoming an alicorn princess and people will assign 40% probability that I will come up with a plausible way to make it happen. They have learned to fear me. This is good. I think that I shall play on these fears by introducing more MLP elements into HPMOR, unless of course that isn't my real motive. But if vampirism were going to be key to the plot - if vampirism were required to solve the story dilemma as it appears in Ch. 89 - it would have been foreshadowed and emphasized before Ch. 89 in the story. E.g. Frigideiro is introduced in Ch. 15, Harry's father's rock in Ch. 17. If vampirism now turned out to be key to the plot, it would not be possible for the reader to solve the plot, regardless of how clever they were. Therefore this is a literary impossibility. Therefore Hermione will not become a half-vampire like Elspeth, Alicorn's princess. Though it really was a very clever guess.

The Effective Altruists of Hogwarts: MIRI:  Ravenclaw Gryffindors. "We could tear down Azkaban, and end this darkness... if we could just get good enough at math..." FHI:  Gryffindor Ravenclaws. "We're the part of academia that studies how to save the world instead of, you know, squirrel migration patterns."... CFAR:  Hufflepuff Ravenclaws. "To find the truth it's not enough to have insights, you need practice!  Lots of practice!" Leverage:  Slytherin Hufflepuffs. "If we can just become *efficient* enough at hard work and cooperation, we can rule the world." Givewell:  Ravenclaw Hufflepuffs. "You've got to use numbers if you want to help our starving friends in Africa in the most efficient manner possible." Giving What We Can:  Hufflepuff Gryffindors. "You've got to work hard to help our starving friends in Africa." 80,000 Hours:  Slytherin Gryffindors. "You can help starving people in Africa most efficiently by becoming an investment banker."

Someone at the Effective Altruism Summit was suggesting that we need a better term than "effective altruists" for the practitioners. I suggest "Ravenclaw Gryffindors".

Even in the original Star Wars, the "I am your father" Big Reveal could have been so much more effective if Lucas had thought of it originally instead of making it up afterward, so that there could have been a proper buildup. Visualize the first Star Wars movie:  Princess Leia confronts Darth Vader and we learn that Darth Vader is the one who hunted down all the old Jedi, because everyone knows this. Maybe get a chance to see him do something more superhuman than lifting a ...Rebel by the throat, like walking through the combat casually using his lightsaber to deflect blaster shots. Luke has always been wondering what happened to his father; nobody would ever tell him, although a lot of other people - maybe not his uncle - seem to admire his father for some reason. Then Luke learns that his father was a Jedi and says to Obi-Wan, "Then... Darth Vader killed my father!" and Obi-Wan is like "Well..."  At the end of the first movie, Luke confronts Darth Vader and doesn't try quite hard enough to flee instead of fighting. Darth Vader intones, "You seem oddly familiar" or some such, and holds off on killing him. Obi-Wan intercepts, and Darth Vader kills Obi-Wan. Now Luke _really_ hates Darth Vader, and the viewers are speculating wildly about why Darth Vader didn't just kill Luke when he could have. And _then_ we get the second movie.

(1)  Assign Brienne to visualize a specific application of Gentzen's consistency proof for Peano Arithmetic:  A proof using the induction axiom and cut, its ordinal, and the cut-free proof with a lower ordinal. (2)  Brienne gets stuck, consults friend who specializes in sequent calculus. Friend cannot think of anywhere in the literature to find a concrete example of a sequent calculus proof using the induction axiom in PA. (3)  Repeat to self several times, "I am busy saving the world. This is a priority. I do not have time to work on the general problem of mathematicians being terrible at conveying knowledge." Even so, AAAAAAAAAAAAAAAIIIIIEEEEEEEEEEE

"You've somehow managed to whip up an interesting and more-or-less-stable dynamic between rationalist characters who would like nothing more than to hurl your plot out the window and crush their opponents into oblivion on the first page, while keeping resorting to story logic to a minimum."  -- Anonymous reviewer 'Matt', describing a big part of what makes HPMOR so difficult to write. Every character with agency wants to hurl my plot out the window!

When I picked my nose as a child, my father told me that the screws that held my head on were inside my nose, and if I picked my nose my head would fall off. He also explained during carpool that he had to navigate the car by sonar like a bat, so if we made too much noise the car would crash. Thus from a very young age I was taught Skepticism, Critical Thinking and Mistrust of Authority.

Re the BART strike:  Surely economists have analyzed the theory of strikes, but off the top of my head I don't see how you construct one. It's obviously not a Pareto optimum, and while a probability of striking could be a Nash equilibrium, for companies with more than one union I'd expect the Nash equilibrium to be that the company doesn't exist.

The cognitive skill taught in Ch. 88 is the insight that I call 'wasted motion'. If you read Ch. 88 closely, a 'Tick' does not occur just because time passes. It occurs after each of Harry's thoughts (or actions) that predictably do not contribute to [resolving the issue successfully]. For more general example, if you want to solve a problem, then after you've solved it, any emotional fretting you did about whether you could solve it will have been a wasted motion in retrospect - those thoughts will predictably not have contributed to reaching the goal in hindsight. "But if I'm genuinely not sure if I can solve a problem, the value of information about whether I can solve it is high, if the cost of trying and failing is non-negligible!"  True, though this depends on the existence of branches where you don't solve the problem, which isn't very heroic epistemology. The value of information about the exact level of effort required is even higher, and if it leads you to put in the correct level of effort, that will not have been a wasted motion in retrospect - heroic epistemology certainly allows for possible worlds in which higher levels of effort were required. But regardless of this sort of obvious theoretical objection, *in practice* you would still be very well advised to fix in your mind the scenario where your goal has been achieved, and ask whether a thought will predictably not have contributed to getting there in retrospect. In a mind which has not practiced detecting wasted motions, there will be many, many wasted motions; so ignore the theoretical objections and just do it for a while.

Chapter 88-89 are up but the HPMOR.com email list is not working! If you are waiting on that email, don't wait, they're up! Link is to Ch. 87 because I recommend reading from there. And try to keep spoilers off Facebook for a day. http://reddit.com/r/HPMOR on awaits you as needed.

We are on track for a Methods of Rationality double update (Ch. 88-89) at 5pm Pacific time today. If you're having trouble remembering the current plot, I recommend rereading Ch. 85-87 beforehand, or just Ch. 87 in a pinch. If you have had previous trouble with reading environments, remember to find a private refuge before 5pm. If an urgent outside event then occurs, do not  Ch. 88-89 if doing so will put you in physical danger. Please note that looking repeatedly at your computer clock will not cause time to move faster. Thank you for observing all safety precautions.

What would you do in exchange for my updating HPMOR 15 minutes early?  Make me an offer.

Being the source of HPMOR sometimes makes me feel like a heroin pusher. Or to develop the metaphor, it's like being the sole supplier to thousands of desperately begging heroin addicts, only you can't just *buy* the heroin from someone else, you have to painstakingly knit it out of your own eyelash hairs.

The philosophical position of 'I only care about my subjective experiences' can make sense, but only if you're paired with someone whose BDSM orientation is 'I only care about your subjective experiences'. Otherwise they might not be happy.

Me:  It's good that very few people take their philosophies seriously, or the human race would be even more diverse than it already is. Andrew:  That type of diversity is bad? Me:  When your species is this incompetent at philosophy, yes.

And then in another 20 years, we get to do this all over again for polyamory.

Oh fuck.

Who besides http://en.wikipedia.org/wi.../John_Crowley_(biotech_executive) and http://en.wikipedia.org/wiki/Martine_Rothblatt have, successfully or unsuccessfully, started biotech companies, joined biotech companies, done research, or otherwise personally resorted to Science to try to save their children or other loved ones?

Someone once observed that if Milton Friedman helped prevent another Great Depression then he paid the salaries of all the economists who have ever lived. It's noteworthy that although enormous amounts of GDP seem to depend on macroeconomic questions in open dispute, nobody seems to be suggesting, "We need more economists on the problem, stat!" Surely if we could get better answers by having more economists, it would be worth a tiny fraction of the GDP at stake to pay them. And yet I think it both true and agreed-upon that understanding of economics has improved over the last 30 years, though alas this understanding is not evenly distributed. Is the implicit belief that economic knowledge scales with more serial depth of economic thought, yet not at all with adding parallel economists?

"The end of history illusion."  Sounds like a handy thing for which to have an Official Bias Term.

So David Brin already had this idea, worked it out in more detail and figured out how to get 80% of the benefit with 20% of the cost. "New history books might state: 'Robert F. Kennedy was slain in 1968 by Doofus25.'"  HT Sedicious Mission.

One of those obvious-seeming notions I've never bothered to write about is that journalists are responsible for almost all the terrorism in the world. Suppose that after September 11th, every responsible journalist had refused to print any hint of who was responsible or what they wanted, while good and conscientious bloggers around the world helped flood the Internet with an indistinguishable morass of conspiracy theories. So that, even today, Al Qaeda had not received not ...a single jot of extra publicity, or no more so than the Irish Republican Army, whose videos claiming credit ranked just as high on Youtube. iIf you asked anyone who did it, they'd shrug and say, "Well, the official story is that it was the CIA using timed explosives instead of airplanes, but as for the truth, you know you shouldn't ask that."  In this world, the World Trade Center bombing never took place in the first place. There was nothing to be gained by it. Terrorism is an industry which receives free advertising from newspapers and TV stations in exchange for telegenic footage of flaming buildings. This trade is enabled by journalism, and the payment executed by journalism. If Columbine had not been helpfully advertised with so many false tears (as they counted viewers, and congratulated themselves for virtuously informing the public) - or if the names of the shooters had been kept out of media or obscured among a thousand others, rather than being made into legendary antiheroes - there would have been many fewer school shootings thereafter. Shooting up a school is, much like Internet trolling, a purchase of pleasurable attention and infamy which is enabled by the providers of that attention and mediated by the exchangers of that attention:  Journalists. It couldn't be any more straightforward if NBC were offering an ongoing bounty in money. Just calculate the value of the advertising time if it were purchased commercially; that's how much NBC pays for a really good shooting. As long as we're going to live in a world of unfree speech anyway, one could make an extremely good case for, at the very least, outlawing any announcement of the *names* of people who commit spectacular crimes (or publication of any other identifying material or predicates) and for flooding the Internet with 'leaked real answers' to create permanent uncertainty. Terrorists are trolls and should be fought with the only weapon effective against trolls, namely denial of attention. Or to take inspiration from the shadowbanning system where hellbanned users can only have their comments seen by other hellbanned users, journalists should only be allowed to accurately report on terrorist groups who bomb other terrorist groups. Attention is reward. Outrage is attention. Fame is currency. Infamy is fame. The more you pay for evil, the more evil the market will supply to you.

My brain processes math without real-world relevance as trying to cheat on the artistic constraint of real-world relevance, like a haiku with 14 syllables. Sure, some people consider shorter poems to be more elegant, but it was supposed to be 17 dammit.

Prevent the NSA from reading your email using this difficult-to-read font! Sweet adorable Cthulhu, the public understanding of cryptography. I would pay $5 for a picture of the expression on Bruce Schneier's face at the exact moment he first reads this particular bit of journalism. It would probably look a lot like this:  http://www.youtube.com/watch?v=ekqlTDsygNs

People with highly varied lives who repeatedly encounter difficult problems creating skill gain, may have effectively 10 or 50 times the life experience of somebody who's been repeating the same day over and over for decades. There are 300-year-old vampires walking among us in the guise of free-loving serial entrepreneurs who have since taken up angel capital and opened their own martial arts dojo, and others who've lived less than 1000 non-duplicated days (< 3 years) since puberty. Human variance in age and lifespan is far greater than chronology suggests.

Prettyrational.com for prettified rationality quotes by Katie Hartman.

(Slightly nsfw.) I may be reading too much into limited data (N=3), but I am beginning to suspect that a number of highly intelligent, sexually masochistic women choose a career in mathematics, submitting themselves to that iron rigor.

"After two or three years, your ability to perform at Google is completely unrelated to how you performed when you were in school, because the skills you required in college are very different. "  Said in passing within an interview with SVP of people operations at Google. Nobody takes notice of this as a searing indictment of the entire alleged purpose of college? Same interview:  "One of the things we've seen from all our data crunching is that G.P.A.'s are worthless as a ...criteria for hiring, and test scores are worthless -- no correlation at all except for brand-new college grads, where there's a slight correlation. Google famously used to ask everyone for a transcript and G.P.A.'s and test scores, but we don't anymore, unless you're just a few years out of school. We found that they don't predict anything. What's interesting is the proportion of people without any college education at Google has increased over time as well. So we have teams where you have 14 percent of the team made up of people who've never gone to college." Also interestingly:  "We found that, for leaders, it's important that people know you are consistent and fair in how you think about making decisions and that there's an element of predictability. If a leader is consistent, people on their teams experience tremendous freedom, because then they know that within certain parameters, they can do whatever they want. If your manager is all over the place, you're never going to know what you can do, and you're going to experience it as very restrictive."  Free to optimize!

Finished what will probably be Ch. 91 today. With any luck the next few chapters will be significantly shorter and easier. Not going to make the 23rd, but I'll be driving hard for the 30th. Though considering that Sunday night may involve school the next day - do people still have school on in July? - or work, and I was saying 7PM Pacific which is 10PM Eastern, maybe I ought to shift the first update in the series to Saturday the 29th at 5pm. Thoughts?

"Knowing that Nature had an explicit editorial policy to publish, in some form, work which refutes an important conclusion of any paper which appears in its pages, we submitted our findings describing the transgenic mice and our failure to replicate the work from Bellgrau et al. to Nature. We received two very positive reviews, but based on a third, very negative one, from Bellgrau et al., the editors decided not to publish our findings as a letter or as correspondence." This... matches other things I've heard from a very senior and prestigiosus scientist I once spoke to, who told me something along the lines of "The person whose work you are challenging will be asked to review your paper. When we took our grant proposal to a bureaucratically smart friend, they told us that we shouldn't mention that this might falsify theory X because the person who proposed theory X would have friends on the grant committee."  In response to which I said, "Doesn't that obviate the entire point of the scientific process?", they said "Yes", and I stood up and gently beat my head against the wall. This kind of 'peer review' is a sad joke which makes edited journals less reliable than blogs would be.

The Fifth Amendment was ineffectual in the first place. Why?  If you explicitly have to plead the Fifth and use silence, judges and juries will update in a Bayesian fashion; experiments show that juries, at least, cannot un-update by an act of will, they draw conclusions. This creates an incentive not to plead the Fifth because everyone knows damn well you're guilty. The real and worse problem is that lying to the court is an offense separate from the crime you're lying about. Suppose you steal a candy bar. As written the laws say that you should not go to jail for more than 30 days for stealing this candy bar. But the prosecutor hates you, so they ask you enough questions to get you convicted for lying to the court 20 times and send you to jail for 20 years or whatever. Lying to the court about an offense should be considered an inseparable part of the crime for which society has imposed a certain maximum penalty, and while lying to the court might exacerbate sentencing within that maximum penalty, it should not exacerbate sentencing beyond it. With that protection in place, the Fifth Amendment would strike me as kind of stupid from a Bayesian perspective. "You have the right for the jury to pretend not to have updated using valid logic to true conclusions based on your silence." The present system says that if you don't confess - either by pleading guilty or by pleading the Fifth in front of people who know damn well what it means - you will be convicted of much harsher penalties for lying to the court. This is a system telling you to either plead guilty to whatever crime you are charged with, or else not testify in your defense, any time you're charged with a crime, because you might get in much worse trouble if you try to defend yourself. Any system which escalates the penalty for a crime in response to actions you take to try to defend yourself, is a system which demands immediate submission as soon as you are charged with a crime.

...I don't think I've ever read about anyone this Gryffindor. Albert O. Hirschman was primarily an economist - one of whose primary theories was that entrepreneurial creativity was usually resorted to, not deliberately, but by people who didn't realize the mess they were getting into when they started out. Then Hirschman went off to fight the Fascists in Spain. And later, when France fell to Germany, he coordinated the Emergency Rescue Committee that saved thousands of refugees from the Nazis. "Hirschman screened the refugees, weeding out potential informers. He cajoled first the Czech, then the Polish, and, finally, the Lithuanian consuls into providing fake passports. He made deals with Marseilles mobsters and a shadowy Russian emigre to get money into France. He held secret meetings in brothels. Several times, he was nearly caught, but he charmed his way out of trouble. When the authorities finally caught onto Hirschman, he escaped across the Pyrenees to Spain on foot, equipped with false Lithuanian papers. On the ship to America he romanced a young Czech woman." This is who the Weasley twins want to be when they grow up.

A helpful key to understanding the art and technique of character in storytelling, is to consider the folk-psychological notion from Internal Family Systems of people being composed of different 'parts' embodying different drives or goals. A shallow character is then a character with only one 'part'. A good rule of thumb is that to create a 3D character, that person must contain at least two different 2D characters who come into conflict. Contrary to the first thought that cr...

I retract my previous criticism of Scalia in this matter, as apparently Scalia routinely "concurs in all but" on judgments having nothing to do with obvious political or religious controversies but slightly exceeding what Scalia feels to be the court's reach. Examples supplied by Dan Haecker from just the last two weeks include: http://www.supremecourt.gov/opinions/12pdf/11-1221_7l48.pdf http://www.supremecourt.gov/opinions/12pdf/12-167_d1oe.pdf http://www.supremecourt.gov/opinions/12pdf/12-62_5g68.pdf

The Fire Proverbs Game: "If at first you don't succeed, try fire." "Look before you fire." "He who hesitates, burns."... "Fire is the best revenge." "The bigger they are, the longer they burn." "The early bird catches fire."

I literally screamed out loud.

Every time I feel bitter about Internet trolls warping their presentation of my work, I should just think of John Tooby and Leda Cosmides, founders of evolutionary psychology, who have it so much worse. And I can't remember hearing of them even complaining about it, let alone, you know, weeping tears of boiling blood or launching drone strikes. There might be something to the attitude that *only* the academic reception of your work matters, the general public being already beyond hope. It's not optimized for saving the world, but you can easily see how it could be emotionally helpful to have that available as an option. The public is not blameless in many scientists not wanting to engage with the public.

If I made a list of things this civilization cares about, it would include asset prices, winning baseball games, possibly some other sports. The NSA seems to care about cryptography. Some supermarkets, airlines, maybe other things I haven't heard of, care about their item pricing; and some Internet companies may care about optimizing their traffic. Aside from that, is there anything our civilization cares about?  Anything else at all?  Is there anything else, whatsoever, on that list, which I didn't remember? To be clear:  The question is not what people spend too much money on, or too much time talking about, where people properly ought to care about your favorite cause X instead. That's easy. The question is what people care enough about that they will hire applied mathematicians to use machine learning algorithms to ferret out every last inch of optimizability, pay those mathematical talents top dollar, shut up and listen to them, and quickly seize on new innovations which seem to be working for other players, even if it means contradicting intuition or overriding some prestigious senior. A domain where at least some powerful decision-makers care so much that they will spend money figuring out the epistemic truth, believe it, and then behave as opportunistic consequentialists. Asset pricing, winning baseball games, supermarket pricing, Internet traffic optimization... anything else at all that our civilization really cares about?

Education is not secretly intended to turn adolescents into conforming factory workers. If 'they' were trying to produce factory workers 'they' would take advantage of elementary modern research on conditioning, reinforcement, and shaping to produce much better factory workers, rather than making conformity so unpleasant and unrewarding. If schools were actually trying to teach things they would take advantage of modern research on spaced repetition. If grade schools and high schools were secretly babysitting institutions, they would offer more flexible hours. If colleges had been designed by employers to weed out anyone with trouble submitting to authority, then there would be harsher enforcement of drug rules or more prohibitive sexual regulations as tests; as it stands, many students who gain a college credential will still have trouble submitting in a workplace. The educational process has no agenda, hidden or otherwise. The overall process of going to college might have the intention of gaining a piece of paper, but the actual day-to-day activities of college are not being optimized for any intended consequence, by anyone.

In general and across all instances I can think of so far, I do not agree with the part of your futurological forecast in which you reason, "After event W happens, everyone will see the truth of proposition X, leading them to endorse Y and agree with me about policy decision Z." Example 1:  "After a 2-year-old mouse is rejuvenated to allow 3 years of additional life, society will realize that human rejuvenation is possible, turn against deathism as the prospect of lifespan / ...

As far as I can tell, slower economic growth 'slows down time', gives us some more headroom in which we can act, and thereby favors FAI in the balance between FAI and UFAI. To be more precise, UFAI parallelizes more easily than FAI because it's easier to build a UFAI out of a collection of tricks and things-that-worked, so increasing parallel resources by economic growth favors UFAI over FAI. This sets two basic virtues at odds with each other and I would certainly love to conclude that faster economic growth made the expected future of the galaxy a better place, for then my virtues would align. But this is not a reason. Asking this question typically produces blatantly one-sided reasoning like "But what about the genius growing up in India who'll help with FAI?" to which the obvious answer is "What about the other 10 geniuses in India who'll work on plain old AI and shorten the timeline to UFAI"?  LW would be the preferred modality for commenting, but if you must comment on Facebook, try not to do the one-sided thingy.

Yudkowsky numbers spread as follows: Anyone who cameos within a work of fiction written by someone with Yudkowsky number N has Yudkowsky number at most N + 1. This rule also applies to fictional characters, e.g. Tohsaka Rin and Miles Vorkosigan have Yudkowsky number 1, along with the real people corresponding to Jeremy Jaffe, Rianne Felthorne, etcetera. Anyone who is the author of a character with Yudkowsky number N has Yudkowsky number at most N + 1. Thus David Brin has Yudkowsky number 2 because Gillian Baskin appears in _The Finale of the Ultimate Meta Mega Crossover_. Anyone who coauthors a written work with someone possessing Yudkowsky number N has Yudkowsky number at most N + 1. Thus Gregory Benford has Yudkowsky number 3 via David Brin. Anyone who has sex with someone with Yudkowsky number N has Yudkowsky number at most N + 1. Fictional characters must have had sex in canon to transmit Yudkowsky numbers this way. Thus Emiya Shirou has Yudkowsky number 2 via Tohsaka Rin. My Erdos number via math papers only is 4, but for more general coauthorship purposes it is 3. So if you have sex with someone who is the author of a character appearing in a cameo within a fanfiction written by someone with Erdos number 3, your Yudkowsky number is at most 9. Can you upper-bound your Yudkowsky number?

I'll maybe ask in the next Methods update if anyone with Erdos number 1 wants to knock out a quick collaboration on e.g. Visual Explanations of Bayes's Theorem. Erdos 4 is okay (I don't have Erdos 3 via Anna because the standard rules state only math papers) but nothing to brag about.

Quick question for Givewellians:  Does the causal model for GiveDirectly's positive effects imply that the government of those countries could achieve the same effects by printing money in the local currency and giving the same amount to the same recipients?  "Yes" is a legitimate answer because it's a dreadful truth that many governments around the world are not increasing their money supply enough, and also that choosing the right recipients can redistribute value productively even when supplies of medium-of-exchange are already sufficient. But it still seems like an obvious question.

I inherited my lineage from Mihaly Barasz, who inherited his lineage from Andras Frank, who inherited his lineage from Laszlo Szekely, who inherited his lineage from the Zero, who is the Origin. I am Eliezer Yudkowsky, and my Erdos number is 4.

Want MIRI/CFAR's old office space?  1360 sq. ft., $2173/month all in, a couple of blocks from the Ashby BART, starting July 1st. I can't personally testify to detailed knowledge of Berkeley office space pricing, but Kevin and Louie looked hard for this one so it should be a good deal.

I want to play an RPG in which I, the PC, can assign fetch quests to NPCs. Any time some irrelevant-seeming sidequest comes up, you can buttonhole a nearby hero in the tavern and say, "You need to collect the magic mushrooms!  I've got to get back to stopping Skoll from eating the Sun."  Then it turns out you need 1,000 GP to buy a diamond to complete the potion, and the local merchants are offering a 50GP bounty on wolf heads. So you buy a cellphone and call the castle and the king arranges for you to have an unlimited bank draft. Wouldn't that be _awesome_?  You could call it Delay Bypass Quest.

Think of a time in the last six months when you tried and failed. If you're having trouble thinking of anything, you are seriously, seriously, seriously not trying ambitious-enough tasks and projects, and playing far, far, far beneath your potential level. This is the most important Umeshism.

My latest. Technical. ~20,000 words.

This is a research thingy, not a general-attendance thingy, but if you're interested in researching the Lob problem it's not too late to ask about attending.

Since this formalism pits agents against each other in the Prisoner's Dilemma by letting them prove things about each other - e.g., FairBot is X = []Y or "I cooperate iff I prove you cooperate" - we were calling it "Modal Combat". This is probably one of the most significant papers you will ever read in terms of how much news it provides about the overall state of the Tegmark Level IV multiverse, because it gives us a better picture of how much cooperation occurs in the Prisoner's Dilemma between agents that have good guesses about each others' source codes.

Gwern is selling his soul - current top bid 1BTC ($120). I like the contract and will consider selling my own soul if Gwern gets a good price, though I'll have to think about probable increased future prices if my fame increases, vs. discounted value of marginal money if my fame increases.

Currently reading a fanfiction (_Harry Potter and the Temporal Beacon_) and I just noticed, for the first time, that Harry is (a) withdrawing gold Galleons from his vault and (b) looking at a transaction record for his vault which includes interest deposits of 50, 169, 167, and 166 Galleons. I would remark on how appalled I am that the author of this fanfiction thinks that gold coins sitting in a vault would earn interest from the bank storing them, but I've read this story at least three times and I'm only now noticing this. Probably due to reading _The Money Illusion_ econblog for the last few months.

...I am still having trouble believing this is not a joke article.

FYI, my sister has given birth, I'll learn the name in 8 days. Me:  I'm an uncle!  I'm now officially this kid's eccentric uncle. Brienne:  So how do you feel about that? Me:  (thinks)... Me:  That poor kid. (Sorry, Francelle, there's no realistic way whatsoever I could persuade Sis not to do it.)

"Bad things don't happen to you because you're unlucky. Bad things happen to you because you're a dumbass."  - That 70s Show "Single bad things happen to you at random. Iterated bad things happen to you because you're a dumbass. Related: '_You_ are the only common denominator in all of your failed relationships.'" - Yudkowsky "Corollary: The more of a dumbass you are, the less well you can recognize common features in iterated bad things. So dumbasses are, subjectively speaking, just unlucky." - khafra "The corollary is more useful than the theorem:  If I wish to be less of a dumbass, it helps to know what it looks like from the inside. It looks like bad luck. My first job is to learn to distinguish bad luck from enemy action, and include myself in my list of potential enemies." - Alan Crowe

Maybe I'm hopelessly unromantic, but when I hear the line, "Can we pretend that air planes / in the night sky / are shooting stars?  I could really use a wish right now / wish right now / wish right now..."  I think:  "First of all, shooting stars don't grant wishes. And second, if they did grant wishes, pretending an airplane was a shooting star still wouldn't help. And unfortunately, the two errors you are making do not cancel each other out."

No material wish in the immediate, real world is too hard. Medical immortality?  Increased intelligence?  A cure for depression?  Almost nothing you could practically wish for is too hard. 'Nothing is too hard' is a fair approximation.

So I've been thinking about STDs - no I do not have any symptoms of anything, they're just obstacles to human fun and this causes thought - and the idea occurred to me that while condoms are imperfectly protective against STDs, it seems like you could amp up the protection significantly beyond that. In particular, you ought to be able to design the equivalent of a male condom!jockstrap that would protect / prevent transmission from the entire genital area, which I'd think a ...priori would be more protective - maybe extend over upper thighs too if that's not enough. Latex gloves are cheap and I don't see why disposable latex underwear should be significantly more expensive. A brief Google check doesn't show it already existing. If you worked out how to manufacture it, a Kickstarter would let you check demand before proceeding. Just throwin' the idea out there in the unlikely event that anyone wants to try selling new physical things instead of developing apps.

I would like to see the Bayesian value-of-information calculation behind the claim that the best time to deploy this malaria vaccine is in five years, after a five-year trial. Oh, that's right, there isn't any calculation for how to save the maximum number of lives based on priors, Bayesian updates as evidence comes in, and increasing deployment as better effects are expected and the value of waiting further goes down. It hasn't even occurred to you that there might be a way to calculate that, or a moral obligation to deploy an optimum solution. You obviously care. You cared enough to develop the malaria vaccine in the first place. It's just that you never thought there might be an alternative, or that you might be doing something wrong. 

Normalcy bias:  "When two planes collided just above a runway in Tenerife in 1977, a man was stuck, with his wife, in a plane that was slowly being engulfed in flames. He remembered making a special note of the exits, grabbed his wife's hand, and ran towards one of them. As it happened, he didn't need to use it, since a portion of the plane had been sheared away. He jumped out, along with his wife and the few people who survived. Many more people should have made it out. Fleeing survivors ran past living, uninjured people who sat in seats literally watching for the minute it took for the flames to reach them." Also alleged in this popular article - anyone know an accessible survey paper? the Wikipedia page is very crude - on "Normalcy bias":  Although movies show panicking crowds, in real life 70% of the people in a disaster will walk at normal speeds. People starting to seek shelter from tornadoes are often called back by others who refuse to believe anything bad is happening. Most people need to ask 4 others for confirmation before doing anything during an obvious emergency (e.g. Katrina, building evacuations) - the first confirmation of emergency isn't enough, they'll ask again, again, and again and then, I guess, finally act. Moral:  Yes, people really are that stupid, so as you yourself exit the burning plane, shout back "Go go go!  Leave your seats and go, now!"  (final yell)  "Do not take luggage!"

Eh, not too bad. I'm sure many of them are flawed, but still.

P/S/A:  Apparently there are now *rumors*. So no, I don't have any STD symptoms. Good practice is for any sexually active person to regularly get tested for certain STDs regardless of whether or not you have symptoms. I was asking if anyone had a good place to go for a routine screening because, calling around, I got quotes like $200 after insurance and that seems like a lot - especially if you're going to get tested at regular intervals, which is what's good practice if you're not in a strict, closed relationship with at most 3 people total. And the fact that my talking publicly about that, apparently caused whispers to fly around is... terrible, terrible policy in Categorical Imperative terms. I'm actually feeling fairly good about taking one for the team on this - better me to set this example and make this point, than somebody who wouldn't be believed, or whose feelings would be more hurt. But let's be very, very clear on this:  Whispering behind your hands about anyone who openly talks about regular STD screening, is bad. Very bad. And you should feel bad. And you should go get yourself STD screened, because at a wild guess, you never did.

Read, then watch:  http://www.youtube.com/watch?v=OkT4vAJnJls

Followup:  "It's bangin-ass when you make it recursive."

I'm due for a regular STD screen (actually the thought has occurred to me that we ought to organize these more systematically within the Poly Graph). I've got standard Blue Cross PPO through MIRI. Anyone got a recommendation for where I should go in Berkeley where this will be cheap (and fast) after insurance?  Also, preferably somewhere that screens for HSV because apparently that's not standard.

Oh. My. Cthulhu.

Velorien is writing a rational!Naruto fic, only two chapters so far, but it's the most promising opening I've read for any Naruto fic ever. Representative quote: "Meet me at 5 am tomorrow at the Training Grounds. Bring whatever equipment you like, within reason, because you won't be able to leave once we start." Naruto raised his hand. "Kakashi-sensei, Kakashi-sensei, what does 'within reason' mean?"... Kakashi felt a sudden sense of impending doom. "It means you can only bring things you'd expect to be able to bring on a normal mission. There's a list of forbidden objects, like rare and hard-to-get chemicals or siege weaponry, plus the examiner has final say over what you can use." Naruto nodded solemnly. Those were some solid if not flawless rules, and would require thought.

Apparently Mercury would make a way, way better colonization prospect than Mars. Most of Mercury's surface varies extremely in temperature, but near the poles, 1 meter underground, it's constant 22C (room temperature) near large deposits of frozen ice on the surface. Solar power would be much more available than it is on Mars or for that matter Earth. Ice + electricity + room-temperature underground = colony.

Nothing I've done, nothing I've said, and nothing I am, has ever made me a persecuted underdog. And you haven't been more ideologically daring than I have.

Novices seem to use the word "safe" an awful lot in conjunction with placing a single medium-grade obstacle in front of one slice of the risk pie. This is definitely true in AI, I'm wondering if it's near-universally true in other fields I don't have experience with.

So apparently the FDA operates on an honor system where they trust that the company isn't just making up the results, and Ranbaxy just made up results. Lots and lots of results. For years. I'm upgrading the probability that it would be worthwhile for the Quantitative Self people to put together their own, Bayesian drug testing system.

I used to recite the Pledge of Allegiance leaving out the 'under God' part (it's not like they can hear you not speaking) and finishing, under my breath, "with liberty and justice for all except the children."

What's right with this picture?

I should've said something to the effect of "I notice I am confused about the Flynn effect" substantially earlier, but I wasn't sure what to believe about earlier centuries and possible media-bias selection effects.

Wandering into a random Wicked Grounds munch with around a dozen people and having two people recognize "Methods of Rationality" feels like the whole world is my family. Likewise blues dancing although that was out of a larger crowd. I feel like people must have used to feel when they lived in small enough villages that other people would know them and smile at them. I feel like I belong on this planet, or at least in San Francisco. And since the avenue by which I achieved this is insanely improbable, the rest of the world needs smaller villages or something.

It would have been trivial to fix _Revenge of the Sith_'s inadequate motivation of Anakin's dark turn; have Padme already in the hospital slowly dying as her children come to term, not just some nebulous "visions". (Bonus points if you have Yoda lecture Anakin about the inevitability of death, but I'd understand if they didn't go there.)  At the end, Anakin doesn't try to choke Padme; he watches the ship with her fly out of his reach, away from his ability to use his unnatural Sith powers to save her. Now Anakin's motives are 320% more sympathetic and the movie makes 170% more sense. If I'd put some serious work in, I'm pretty sure I could've had the movie audience in tears. I still feel a sense of genuine puzzlement on how such disastrous writing happens in movies and TV shows. Are the viewers who care about this such a tiny percentage that it's not worth trying to sell to them?  Are there really so few writers who could read over the script and see in 30 seconds how to fix something like this?  (If option 2 is really the problem and people know it's the problem, I'd happily do it for $10,000 a shot.)  Is it Graham's Design Paradox - can Hollywood moguls just not tell the difference between competent writers making such an offer, and fakers who'll take the money and run?  Are the producers' egos so grotesque that they can't ask a writer for help?  Is there some twisted sense of superiority bound up with believing that the audience is too dumb to care about this kind of thing, even though it looks to me like they do?  I don't understand how a >$100M movie ends up with flaws that I could fix at the script stage with 30 seconds of advice.

Making half a respirocyte is easier than I would've expected.

A song that's stuck in my mind since age... maybe 6 or 7 or so, when I saw "Explorers". The Internet is awesome. Also "The Construction" from the same album.

Patrick LaVictoire doesn't trumpet it very hard, but he's the leading edge of formal cooperation in the one-shot Prisoner's Dilemma between agents with knowledge of each others' source code, and he's currently organizing a group house in the South Bay looking for members.

Interesting results on cancer are 11% reproducible. "Fifty-three papers were deemed 'landmark' studies (see 'Reproducibility of research findings'). It was acknowledged from the outset that some of the data might not hold up, because papers were deliberately selected that described something completely new, such as fresh approaches to targeting cancers or alternative clinical uses for existing therapeutics. Nevertheless, scientific findings were confirmed in only 6 (11%) cases. Even knowing the limitations of preclinical research, this was a shocking result."

OMFG

We are all familiar with many cases of correct scientific skepticism, such as about Uri Geller and hydrino theory. It has previously been my model that almost all *erroneous* scientific skepticism (such as the impossibility of human heavier-than-air flight) had been conducted without calculation or in defiance of the default extrapolation from existing models. And hence that skepticism by eminent scientists which *doesn't* defy default extrapolation from the actual models is ...actually quite reliable, and that there is little historical advice to pay strong attention to what has apparently a small probability, so long as this small probability is obtained by default extrapolation of current models rather than just by eminent scientists saying skeptical things. The one exception that came to mind was Lord Kelvin's careful calculation that the Sun was at most sixty million years old, though that's not quite technological pessimism. Now a strong case has been made on LW that practical fission would've been effectively impossible if the one U-235 isotope had been missing from our Earth or had different properties, which may make Fermi's "ten percent" probability estimate on nuclear weapons another case of non-default-violating erroneous scientific skepticism. That's two cases of non-default-violating erroneous scientific skepticism. Is there a third?

Erratum:  Looks like the line in GCR:AIRisk about the Toba supereruption being humanity's nearest close call to extinction may be wrong.

So on the list of human failures to see the bloody obvious:  You know all those rich families that are terrified of their children growing up to be Paris Hilton?  I bet that some of those rich folks married... oh, let's see... beautiful women and handsome men. Who were not thrifty physicists. Is it *that* bloody forbidden to think about the implications of human heredity?

I approve.

"A couple of years ago, an anonymous family foundation launched a call for "extraordinary and unorthodox" philanthropic opportunities. We wrote critically about this at the time, but the winner of the contest turned out to be GiveDirectly (currently our #2 charity), which received its initial funding from the contest. We've since had some interactions with the funder, and we've been impressed with its thinking and with its broad interest in doing as much good as possible. The funder is now holding another contest with a similar aim to the previous one: to "identify and support one new great idea" that "can improve the lives of the world's most disadvantaged people."" -- Holden Karnofsky

7.8K words on the best approximation I've come up with so far to handling the Pascal's Mugging problem in decision theory.

Intelligence Explosion Microeconomics - my latest 40,000-word opus, trying to think about a self-improving AI in terms of returns on cognitive investments. Hopefully this makes the problem semiformal enough that interested econ types have something nontrivial to say about it.

JASMINE AND THE LAMP Aladdin's face was wistful, but determined, as the newly minted street urchin addressed the blue being of cosmic power for one last time, prepared to leave behind the wealth and hope he had so briefly tasted for the sake of his friend. "Genie, I make my third wish. I wish for you to be -" Princess Jasmine, who had been staring at this with her mouth open, not quite believing what she was seeing, just barely managed to overcome her paralysis and yank the... lamp out of the boy's hand before he could finish the fatal sentence. "Excuse me," said Jasmine. "Aladdin, my darling, you're cute but you're an idiot, do you know that?  Did you not notice how once Jafar got his hands on this lamp, he got his own three wishes - oh, never mind. Genie, I wish for everyone to always be young and healthy, I wish nobody ever had to die if they didn't want to, and I wish for everyone's intelligence to gradually increase at a rate of 1 IQ point per year."  She tossed the lamp back to Aladdin. "Go back to what you were doing."

Vulcans as they should have been (scroll down to below the comic). HT http://lesswrong.com/lw/hbu/rationality_quotes_may_2013/...

You know, it's actually a surprisingly pleasant commentary on the human condition that children have imaginary friends, instead of imaginary enemies to beat up. Or so I'm told. I didn't have any imaginary friends as a kid - if there was a cognitive niche there, I think it got occupied by all the fiction I read.

Does anyone know of a good way to permanently snapshot images of webpages for later display?  This seems like a good, archetypal example of how once you achieve the rank of C-level Internet celebrity, people will completely, wildly distort what you say to the diametric opposite of its original intent, up to and including twisting the laws of mathematics. I may want to reference that later, and would like to keep a permanent copy in case this disappears. Also, please don't post any explanatory comments in this until I get the snapshot, I want an unalloyed picture of how the concept of "reputation" works on the Internet.

"You were taught that sex is the most degrading, depraved, disgusting, disturbing, nasty, noxious, filthy, foul, venal, evil, sinful and just plain wrong thing in this plane of existence, and you should only share it with the person you love most." -- Tales of Mu

Right now there are a lot of people who sort of think they ought to sign up for cryonics, but haven't gotten around to it. But in the future, we'll see less of them.

Shouldn't they be called research objects, not research subjects?

...sigh. So do I need to dump my Cytosport chocolate protein, or is someone about to tell me why I shouldn't worry?  Offhand, it seems like I should strongly prefer not to have lead in my protein powder, it's supposed to be quite bad for cognition.

"Sandman Slim" has some flaws and it's a bit cliched here and there, but I give the author credit for this:  I'm 63% of the way through the book and the protagonist is currently on the run from - in no particular order - the evil magicians, the respectable magicians, Hell, Heaven, the FBI and Cthulhu.

...wow. I've said this before in mere words, but to come up with such a marvelous concrete illustration... Kudos to Dove for this YouTube advertisement, they well-earned this link.

You know that hoary old plot, "The elegant vampire, the strong werewolf, and the  woman who just can't make up her mind"?  I think those stories should just keep going:  Introduce the secretive wizard, the innocent catboy, the stonehearted assassin, the shy half-demon, the pirate, the ninja... This is *almost* the plot of the Anita Blake novels but for some reason Laurell K. Hamilton just sticks to adding more and more lycanthropes and undead to the harem instead of branching out.

The really key question I'd like to know about is the training of the surgeons. Are they being trained for this operation only, like specialized technicians should be?  They can't possibly doing the crazy-ass artificial-barrier-to-entry 8-year-waste-of-time that US surgeons undergo. This rates fairly high on the list of Nice Things We Can't Have, or rather, nice things that I can easily visualize that can be done with modern technology that I wouldn't expect to see in 30 years. I suppose India hasn't yet reached bureaucratic maturity and still has some will to innovate, and this innovation requires no great technical leaps that they couldn't do without their own scientific lineages (the reason why China can't just go out and hack together a working thorium reactor the way Oak Ridge did in the 1960s - they can put 150 PhDs on the program in an eyeblink, but none of their PhDs have learned from a real innovator or the program manager can't tell the difference, or something along those lines). But I'm drifting off topic. I think the moral is that if a Nice Thing requires literally no technical innovation at all, India or China or Singapore or Dubai might actually go out and do it.

This is well said, but I would also like to add that the threshold for a guy thinking a woman looks hot is lower than a lot of women seem to think. Most women look at least sorta pretty to most guys. You would kinda expect it to be that way, evolutionarily speaking.

Whoa, ricin is scary. It works by cleaving a bond that permanently inactivates a ribosome. A single molecule of the toxic byproduct of absorbed ricin can inactivate 1500 ribosomes per minute. 2mg of ricin absorption won't seem to do anything to you at first... and then a few hours later, the symptoms of your body being unable to produce proteins will start to show up. 3-5 days later you're dead.

I suspect this is an underlooked source of total systemic malfunction.

The exact fringe of cynicism:  Half the commenters on LW seem to think this is obviously false. The other half seem to think it obviously realistic. I never went through the public school system so I've got absolutely no idea myself. I note that the 'obviously false' comments show a tendency to be from CA or NYC and people who identify themselves as being from e.g. Texas seem to find it much more believable.

Same ol' same ol'. Pity he's also a religious speculator - it decreases my confidence in the article, since it means the man has no general ability to distinguish strange truth from strange falsehood.

The top 100 scientists, by lives saved.

Leaving aside distant evolutionary causes, so far as I can tell, the proximate psychological causes of the gender-unbalanced market in sex seems to boil down to two fundamental skews: 1)  Although on statistical average, women enjoy sex around as much as men so far as I can tell - that is, summing over heterosexual MF sex acts of the sort I've witnessed personally, I have no reason to believe more dopamine is accruing to men than women - on average men experience much more disutility, sooner, from lack of sex. (Cue all standard disclaimers about how averages may not be true of any individual.)  The classic demand/supply imbalance that leads to males paying female prostitutes much more often than the converse, isn't about men enjoying sex more than women; it's about men experiencing more pain from lack of sex than women. The saying "After three days without sex, life becomes meaningless" is male-rather-than-female to a much stronger extent than any disparities that are about desire to date, positive enjoyment of sex, or even enhancement of sex by emotional relationships. 2)  On statistical average, sexually experienced men are much more interested in initiating sexually inexperienced women than experienced women are interested in initiating, teaching, passing sexual skills etc. onto inexperienced men. Cue all standard disclaimers as before. An opposing force is that more experienced men probably seem (and also are) less trustworthy to inexperienced women. Still I would guess that on net this accounts for a lot of the disparity in how easy it is to get started. Unlike buying sex, there are no established standard ways for a male to throw money at this challenge. (Romance / dating / relationships are obviously more complicated. This post is just about sex. Opinion is more humble than usual but even so my personal observations have conflicted with the Usual Story to some extent and this seems worth mentioning.)

Apparently there's this long list of beefs "traditionalists" have with the new pope and literally every single one is the sort of moral choice where, if a video game offered it to you, it would be obvious which one would give you Dark Side or Light Side points.

Good people are utilitarians, but virtue ethics is what gets stuff done.

Happy Zombie Day!

I was laughing at this for about ten minutes straight, but it probably requires reading econblogs to get.

There are some hugely popular Plots You Only See In Fanfic - story tropes that have large, dedicated audiences despite having effectively no representation in gatekeeper-approved literature. If you want to write the next surprise bestseller a la _Fifty Shades of Grey_, one strategy might be to pick a plot that has great demonstrated demand and no mainstream supply. Like: Tomione:  A powerful, handsome, and evil Dark Wizard falls in love with a bright young witch who will either redeem him or fall to the lure of the Dark Arts herself. It seems like such an obvious romantic plotline in retrospect, and yet I can't think of any non-fanfic story I've read that has it. The Loving Evil Dad:  Apparently there are all these Star Wars fics where Darth Vader gets his hands on Luke and then is nice to him, like buying him expensive clothes for the Emperor's dinner parties and so on. What the hell is up with that, I do not even have a hypothesis. Mpreg:  I don't understand it, I don't want to understand it, and there's apparently a tremendous demand for it. The first person to put a well-written mainstream mpreg novel on the bookstore shelves is going to win a *lot* of marbles. Polyamory:  It's a standard plot to have a protagonist who has sex with more than side character, or a protagonist who must choose between two would-be seducers. What I haven't seen is complex stable or growing groups, with character interactions between the group members. Occasionally you get a triad with a clear vertex character and that's it. Even in fanfic this will usually go by the keyword 'harem' because it will revolve around a central figure - true polyamory with no center node is rare even in fanfic. But in mainstream fiction, triads are rare and character-driven harems larger than triads are unheard-of. Laurell K. Hamilton writes the only mainstream character-driven harem fics I can think of, all F/M+ and with plotlines regularly surrounding the addition or subtraction of particular males, the men fighting with each other, etc. Those books sell and not just to women. Other examples?

Brief but interesting reading for statistical learning types.

The phone trumpeted the sound of a text message. For some reason I was seized with a presentiment of disaster, a sudden intuition that this particular text message was very bad news. I flipped open the phone, and looked. It was a message from T-Mobile telling me to refill my minutes. Living in a reductionist universe is awesome.

Soylent Green is made from people, but not just any people!  It's made from organic, local, grass-fed people raised without antibiotics on free-range farms. That's why we call it Soylent Green.

I'm trying to think of fictional instances of heroic delayed gratification (a la the marshmallow test) and literally the *only* example coming to mind is Shindou Hikaru holding off on playing a game against Touya Akira in _Hikaru no Go_.

Oddly good news about our civilization's rationality - GiveWell says that they started from the most effective proven interventions, tried to find opportunities to do more of them, and almost all the real opportunities were already being taken by someone. It sounds like this surprised them, too. Are there philanthropic actors in the system who reliably respond to non-probabilistic proofs of great cost efficacy?  Why is human civilization managing to solve this problem?  I'm confused!

The Yudkowsky-Hanson AI Foom Debate in 15 seconds: Yudkowsky: A recursively self-improving intelligence will go FOOM! Hanson: Humans are intelligences. Why don't humans go FOOM? Yudkowsky: Because humans are stupid.... Hanson: Isn't that an unusual and burdensome assumption? Yudkowsky: No. (I *think* this summary is equally unfair to, and parodying of, both positions.)

It begins.

Some of these are gross misrepresentations, but the rest are pretty good.

Someone should write "My Little Pony: Facebook Friendship is Magic". You know, the version where they're just Facebook friends.

PSA:  The three relationships that never work out are poly/mono, rationalist/Muggle, and wants-kids/doesn't-want-kids. Just thought I'd repost this because I just heard about yet another case of it never working out.

Can anyone recommend an unlocked GSM Dumbphone with long battery life which is tiny and light and cheap?  Is there *anyone* who serves the market for people who just want to make phone calls, or is it so impossible to make a profit that there is literally no market entry at all?

"Vampire Ninjas and Werewolf Pirates". Make it happen, Hollywood.

"What if God, instead of having created only this world from nothing out of pure love, has destroyed every world in the plenitude but this one out of pure hate?" -- MrMind, "Destructive mathematics" (slightly edited)

So... it has come to this... By which I mean that I'm now officially desperate enough for reading material to try reading My Little Naruto fanfiction. I'll comment again if it turns out to be any good.

"I have been surprised to see that some of my friends and acquaintances in the effective altruism community identify as Negative Utilitarians. Negative Utilitarianism (NU) is treated as a non-starter in mainstream philosophical circles, and to the best of my knowledge has never been supported by any mainstream philosopher, living or dead. This is quite an amazing lack of support: one can usually find philosophers who support any named position. On considering the theory in some detail, I cannot help but agree that the philosophical community has got this one right."

(Looks out window at night sky.) System 1:  "Overcast, the clouds are blocking out the stars. I wonder if we can see the moon, since it's closer." (100 milliseconds later.)... System 2:  "Wow. Your model of the Solar System... it's just... wow."

If Earth had 1000 times as many people, there would be at least 1000 fanfictions as good as Methods of Rationality. 5 of them would update every day. MIRI would have an annual budget on the order of $1B. How can we remedy Earth's underpopulation problem?

What we need is a new spinoff religion, Completely Reformed Judaism. Unlike regular *partial* Reformed Judaism, in Completely Reformed Judaism there are *no* traces of Judaism left *whatsoever*.

I think it may be about time to get laser beams shot into my eyeballs. No, I can't especially afford LASIK, but it seems like a good thing to consume sooner rather than later (draw savings down a bit). Does anyone have any strong positive recommendations? I do care about price. Resorting to mild geoarbitrage and buying a plane ticket is not out of the question.

This is the literary theory I live by. "The Cool Stuff Theory of Literature is as follows: All literature consists of whatever the writer thinks is cool. The reader will like the book to the degree that he agrees with the writer about what's cool. And that works all the way from the external trappings to the level of metaphor, subtext, and the way one uses words. In other words, I happen not to think that full-plate armor and great big honking greatswords are cool. I don't like 'em. I like cloaks and rapiers. So I write stories with a lot of cloaks and rapiers in 'em, 'cause that's cool. Guys who like military hardware, who think advanced military hardware is cool, are not gonna jump all over my books, because they have other ideas about what's cool. The novel should be understood as a structure built to accommodate the greatest possible amount of cool stuff." -- Steven Brust

*Why* has nobody built Babbage's analytical engine yet?  I bet you could print a single copy using a 3D printer and sell it (on eBay?) for quite a lot of money. (If you actually do this and make a sufficiently large profit, I request a donation to MIRI or CFAR.)

Holy crap. I've been talking about 64-node clustered humans for years, but I wasn't expecting anyone to have enough Mad Science spirit to go out and start developing the tech in mice.

"Friendship is Optimal: Caelum est Conterrans" (Heaven is Terrifying) is the first successful horror novel I have ever read. By which I mean that it is the first story I've ever read that repeatedly makes me flinch, because unlike H. P. Lovecraft it contains elements which are actually scary to me. It may possibly be necessary to read "Friendship is Optimal" first - that certainly contributed to my horror every time I read "satisfy your values through friendship and ponies". Caelum est Conterrans is better-written than the original Friendship is Optimal, though.

MY LITTLE PONY: FRIENDSHIP IS CHAOS "You don't understand," spoke the glorious alicorn, Her wings and mane and horn all shining in the light of the unbearably bright spark that She'd raised over the land. "We only want you to be happy!"  Her sister, as beautifully dark as the other was golden, was weeping black-sparkling tears. "We know that!" cried Pinkie Pie. The unbound essence of the Elements glowed brightly around her and all her friends, as they faced the two incomprensible horrors that had broken loose from their imprisonment. "That's just why Discord locked you up! Because your idea of happiness involves everyone living in peace and harmony instead of totally awesome clouds that rain chocolate cake!" "You'd make us *weak*," Applejack said firmly, her eyes staring straight at the superior Beings. "You'd just make our lives way too boring," added Rainbow Dash, who was flying exactly one centimeter higher than the huge alicorns they were facing. "We'll never become smart for ourselves," Twilight Sparkle said quietly from where she was standing behind Pinkie Pie, "if you're always doing our thinking for us." "I'm sorry," Fluttershy whispered. There were tears dripping from her own eyelashes. "But what you offer - just isn't real." "Don't worry, though," Rarity said with her head and horn held high. "Now that I've seen *you* - I'll never stop learning until I'm just as powerful as you are!" The pink earth pony who was the most favored disciple of Discord took a step forward, advancing on the beings of unearthly beauty. "And when just about any five Elements whatsoever are ignited by the spark that resides in some of us," shouted Pinkie Pie, "it creates the sixth and final Element - the Element of WEEEEN WAKA WAKA LOOK I'M A FISH -"

#greatmovieideas An ambitious science experiment gone horribly wrong successfully reanimates people who "died" by drowning in cold water (hich preserves most brain information). Unfortunately, the revivees wake with global episodic amnesia - they have most of their skills, but not their names or lives, and the reviving process makes them look pale, and occasionally bleed from their ears. Also unfortunately, they smell so incredibly delicious that it triggers some primal emotion - no ordinary human being can resist trying to eat them. Soon the zombies are fleeing through the streets, chased by the ravenous hordes of living humans.

If nobody shouted "IT'S ALIVE" while making this, they are all dead souls.

The loyal one, the ambitious one, the one who lives her dreams without fearing what others will say, and the studious academic. Happiness is the sudden realization that your four girlfriends correspond to the four Hogwarts Houses.

So I made a joke about Judaism being called that because we follow Judas, and then I discovered that Erin has somehow gone through her entire life, including being on the Internet, without ever hearing about Judas. Her reaction was as follows (I'm surprised that I never thought of it myself):  "So, wait, Judas sold out Jesus?  And he did it for thirty pieces of silver?  That's hilarious."

They say "all story premises have the potential to be good", but you know what I just can't figure out how to make work?  In character Belldandy vs. Celestia. I'd still like to see epic art of the two of them in desperate battle. You could just stare at it and wonder how things could possibly have gotten that screwed up.

Wow. That actually worked?

Strength of gender identity test!  What is the *minimum* superpower you would accept in exchange for being flipped to the opposite sex?  (Neglect scientific progress in your answer - assume some other people already have the stated superpower, so you're not contributing to scientific progress or getting much media attention.)  Assume no trauma or sense of misfit afterward, and that anything psychological you especially want to keep stable, you get to keep stable.

Saith the one:  "Last summer our beloved cat was stolen by some street punks. After 171 days we went to the shelter to adopt a kitten. Then a couple walked in (no they weren't the thieves) with our family member in a cardboard carrier, it was better than winning a cash lottery of any size." I replied, "I don't believe you, unless you spent tens of thousands of dollars trying to find that cat." Then I went back and deleted the reply, because messing with somebody's preposterously thin belief-in-belief that they assign infinite value to their cat probably won't make any friends for rationality. It's sort of like kicking a kitten. Still, it's easy to understand how Robin Hanson got to be the way he is about health care and most of everything else.

The Beijing Genomics Institute is undertaking a project to sequence the complete genomes of several thousand unusually-smart individuals, to hunt for correlated genes. I wrote in to see if they wanted to sequence my genome, since this seems like an important project and I don't want my weirder style of intelligence to be left out if China starts manufacturing us. My email includes my childhood-wunderkind scores that I don't usually talk about, since they specifically ask about those. I briefly summarize some of what I've accomplished with my life, in lieu of their questions about completed degrees and academic positions. I worry that they'll write me off as some guy who didn't attend high school and ignore all that other odd-sounding stuff like claiming to have founded a research institute, and someday Chinese genetic engineering will end up creating *boring* *conformist* geniuses. 23 minutes later, the project manager writes back saying that I'll be in the next sequencing round, and my email was, in his words, "totally unnecessary" since he already knows who I am. I am still not used to that sort of thing.

Do you have anything such that you wouldn't trade a $100,000 gain for a 1% chance of losing it?  If you have anything like that, you must have at least $10,000,000 of value - but are you really acting consistently with respect to that valuation?  HT Michael Ellsberg.

I shouldn't be this happy that human beings can solve simple #$(*%ing collective action problems. The largest N for which we can manage to do this is the fundamental parameter of being able to have nice things.

"My fellow Americans, I'm not going to lie to you, our situation is very grim. The truth is, most of you are probably going to die. And the survivors will envy the dead..." -- don't you wish the State of the Union address had gone like this?

This is incredible.

It's time to fight evil with evil. We need an organization that uses troll patents to sue news organizations who do grotesquely inaccurate science reporting. Amend the story, and the patent lawsuit is withdrawn.

Andrew Gelman questions the statistics in that 'collapse of Jewish achievement' thingy. Debelieved, marked as 'unknown'.

Robots may sometimes become attracted to you. If you find yourself in this situation, please observe the following steps.

There are Facebook threads about people who read magazines about soap operas.

People keep asking me about relational quantum mechanics. You can quote me on the following: RQM is MWI in denial. Any times it might uncharitably seem to you like RQM is merely playing semantic word-games, RQM is, in fact, merely playing semantic word-games.... RQM's epistemology is drunk and needs to go home.

Scott Sumner mentions in passing a theory that all of Buffett's excess returns (since 1989?) have been due to in-effect leverage and lower borrowing costs via reinsurance, in favor of the efficient markets hypothesis. Michael Vassar, comments?

I approve of this in principle (because I think it's a good idea to ask for things you want straight out, and because I agree with Hanson's observation that sex is one of the easiest things to add to improve our civilization's utility) so I went through the list and... wow, that was a deeper psychological experience than I was expecting. There are smart sexy rationalist females who I wouldn't bang and... I'm not even sure quite why, in some cases. Well, I know in one case it's because sleeping with her would take too much nerve to be fun, and in another case I'd be terrified of harming our friendship if something went wrong. A lot of beautiful women who I simply don't know all that well, which is odd, because I thought of myself as the sort of person who usually says yes to that sort of thing. I guess when someone else approaches you in real life, that says something about who they are right there. This is a fun exercise if you're honest with yourself about the answers and spend some time looking at your reasons for them. Remember not to click it unless you'd actually go through with it in real life.

I probably shouldn't smile so much when I read some poor, innocent fool posting online, "I've just read Methods of Rationality!  Can anyone point me to some other fanfictions as good?"

The majesty of Azathoth's creation.

Someday, if all goes right, nobody like me will ever be born again. This is obviously a good thing and has nothing to do with saying that I should die or that my current life is unhappy. David Pearce and I disagree on a lot of things - like whether the bright and beautiful children should be able to feel any pain at all - but at least both of us understand that to say nobody like you should ever be born again, doesn't cast the slightest aspersion on the current life you live. It just means that tomorrow can be brighter than today.

Has this been confirmed?  Poe's Law is hitting me pretty hard here.

I think Miri-tan should be about 9 years old, holding out a cake in her hands, looking innocent; while in her background is, say, a galaxy with a huge bright light being born on one edge. Or she could be offering a kitten while in the background a star is being disassembled by huge machines. The general template would be Miri-tan offering you something cute in foreground, with something implying off-the-scale power in the background. Such is my proposal for Miri-tan.

I think Miri-tan should be about 9 years old, holding out a cake in her hands, looking innocent; while in her background is, say, a galaxy with a huge bright light being born on one edge. Or she could be offering a kitten while in the background a star is being disassembled by huge machines. The general template would be Miri-tan offering you something cute in foreground, with something implying a greater degree of power in the background. Such is my proposal for Miri-tan.

So now that we're called the Machine Institute Research Intelligence or something, Lindsey observes that "Miri" sounds like it should be a cute mascot. So what should Miri-tan look like?  I've got my own ideas but I'd like to hear yours. http://www.google.com/search?q=os-tan if you've got no idea what this is about.

Even after reading this all the way through, I'm not quite sure what Howard Tayler thought of "BloodRayne"... he needs to stop dancing around and just say directly whether it was good or bad.

SIAI -> MIRI

Heard on the radio:  "If you could fill up your office water cooler with anything, what would you put in it?" Caller:  "Sangria!" Me (thinks):  So, let's see... what can I pack into a water cooler that has the highest value?  Element-126 in liquid suspension?  Am I allowed to say "Alzheimer's cure"?  Actually, that's not effective, what about "intelligence enhancing drugs"?  Can I ask for FAI code on an SD card?  That'll fit inside a water cooler. But of course knowing what ...you mean when you ask for "FAI" is a Friendly-genie-complete problem. Nanomachines?  A high-fidelity upload?  An SD card containing the Busy Beaver sequence? There's a lot of interesting stuff you could pack into a water cooler and still have room to fill 50% of it with sangria, if the other person insisted on compromising.

Currently sick and attempting to watch anime. Sword Art Online is oddly moving. It deals with people trapped in an MMORPG who die in real life if they die in the game, and they have to clear the game to get out. Except that instead of this happening as the result of an "accident" (yeah, right) the psychotic creator of the game actually went to great lengths to deliberately build a deathtrap, which makes a lot more sense. Out of 10,000 people trapped in the game, most go on ...to lead relatively ordinary lives as merchants, blacksmiths, etcetera within the game, and only around 500 "front-liners" are actually trying to clear the game and get everyone out alive. This sounds about right. There's probably around 5% of the planet that tries to push humanity forward, though obviously very few of them are doing it right. It's oddly moving because the basic scenario of, "A few heroes have to 'clear' the world so everyone can get out and go back to their normal lives" produces conversations oddly like the ones I have in real life. Sword Art Online Episode #15 jumps the shark harder than anything I have ever seen before, ever. Thankfully Episode #14 makes an acceptable end to the series. I honestly think it more than 50% probable that this anime was originally meant to have 14 episodes to start with. Yes, I noticed the gender-role problem.

The comments section of this post is an *amazing* illustration of All The Standard Fallacies lined up one after another.

Nice.

This is *creepily* similar to the Nika riots. I mean it's eerie to read this and *not* have the reporter refer to the Nika riots. http://en.wikipedia.org/wiki/Nika_riots

The best rationality quotes of 2012!

So apparently you *shouldn't* use pencils in zero gravity or you will not go to space today. Thanks, Internet!

"I don't really have anything to say, other than that the world economy is in the hands of a bunch of people who are stark raving mad." -- Scott Sumner

OMFG Yvain

And Judaism leaps back into the lead for "relatively sane as religions go"!  There's no way the Buddhists can possibly match this until a major Buddhist figure gives a similar speech. This counts for _so_ many more sanity points than just endorsing natural selection, btw.

We need a picture of Maslow's Lattice of Needs that gives a more descriptive idea of what people actually pursue when their basic needs are satisfied, with food, sleep, shelter, and a sense of immediate security always at the bottom; but then branching off into all sorts of pathways like Sex, Romance, Children, Compassion, Guilt Reduction, Skill Mastery, Status Competition, and, occupying a prominent place at the top of the traditional version of the pyramid, Bullshit. In my ...case, I think that my drive for world optimization is something like 50% Skill Mastery. Anytime you try to perfect your execution of something, including utilitarianism, that's Skill Mastery - so my answer, 'because it's the exactly right thing to do' is Skill Mastery, as is most of my in-practice pursuit of FAI math and better writing. And then the rest, in terms of its power to actually drive me to do things, is something like 20% Compassion, 10% Status Competition, 17% Guilt Reduction, and 3% Immortality. How much of that is Bullshit isn't for me to know.

Auctioning your virginity for $780,000:  +3 Munchkin. Donating the bulk of the money to charity:  +5 Altruist. If she'd picked an efficient charity, she would've hit the Rational-Altruist-Munchkin trifecta and I would officially consider her a PC.

I don't expect respect from people I haven't personally helped - expecting something unreasonable like that, will only make you bitter when you don't get it. I don't do things for people to get their respect. That trick usually doesn't work, and you can break your heart trying. You can't control what other people think of you - you can try, but most things you can try for that will be quantitatively less effective than you hope, because whatever you do, that act won't be the center of their world the way it was of yours, and they won't interpret it in quite exactly the way you want it interpreted. On the other hand, I've been known to *avoid* doing things for fear of *losing* respect, because that part is predictable and avoidable. And when I do get respect for something that helped someone, I let myself enjoy it and be positively reinforced by it. Just in case anyone thought I was above wanting the respect of others. I'm not. But I try to be sensible about it.

"After 33 years of failed but eagerly pursued personal experimentation in education, morality, lifestyle, work and self-expression, I eventually sidled into the one experinent I'd dreaded most of my life: attempting a conventional career, keeping ordinary hours, behaving appropriately, caring about my appearance, and seeking conventional status markers." (From the linked comment, not main post. I disagree with the last paragraph but it's worth reading anyway.)

Ends at part 14 after getting to the fast-growing hierarchy for the Feferman-Schutte ordinal. You know what really blows my mind?  The fact that the slow-growing hierarchy eventually catches up to the fast-growing hierarchy.

Insight from a conversation with Geoff:  Lois McMaster Bujold, I think, said that much science fiction is a fantasy of political agency - of being able to bring about political change. I think this is actually mistaken, and most heroic fiction is a fantasy of hyperbolic discounting. It *is* possible for individuals to bring about political change, if they spend 30 years or longer trying. The people in fictional stories often do put in hard work and pay costs higher than those in the real world, so it's not a fantasy of reduced effort. In the real world you don't even have to fight ninjas, although unwillingness to fight ninjas is part of the reason why so many people think that individuals can't accomplish political change. But if you look at Scott Sumner, to give an example of somebody who may have been effective at bringing about change on a trillion-dollar scale, he didn't fight any ninjas along the way. But when you read about that in a book, even if the hero spends years of book-time to get their results, *you* get to read about the fruits of their effort fifteen minutes later. You also get to be certain that they won, whereas in real life you've got to stick to things for years not certain that your efforts are going to have any effect. Even in the early parts of the book, heroes are very rarely presented as having to wonder if they're working on even remotely the correct problem. I therefore say that heroic fiction is a fantasy, not of agency, but of low subjective uncertainty and low temporal discounting.

Breaking news:  AaronSW may have left everything to Givewell. Just saw this and posted it to HackerNews. Also, his last post to Reddit was to /r/HPMOR. I don't think I even noticed he was a fan. http://www.reddit.com/user/AaronSw

Heroic attempted liberator of the scientific literature, and very occasional LW poster, Aaron Swartz, is dead.

Erin just got 23AndMe. Do we believe their four-star (most reliable) items, or do we just not believe any genetic studies at all these days?  (@Sarah.)

"The first rule of human club is you don't explicitly discuss the rules of human club." - Silas DoGood "Human club has many rules. Some can be bent. Others can be broken." -dspeyer@LW

This is what Deep Wisdom would sound like if people knew cognitive science.

Once again illustrating that if you practice *anything whatsoever* for long enough, you will acquire eerie-seeming superpowers.

"Faith can move mountains" - no it can't. Seriously, try it, you'll find it doesn't work. There are no famous historical cases of mountain ranges that got relocated by anything, including faith. It's odd that sensitivity varies so much to sentences which are blatantly, obviously false. Can anyone think of any other blatantly completely false proverbs?

"Find some customers whose hair is on fire."  -- edw519@HN

Look here upon the face of the enemy, and be sure to click # rather than Rate or %.

Well this is reassuring.

Under 20 and have big ideas to change the world? Interested in technology, science, and entrepreneurship? Know a hacker or maker with audacious dreams? Apply by December 31st for a chance at $100,000 and 2 years free to pursue your dreams! 

"In Panacea job interviews, I have not yet found a PhD biologist who could do the breast cancer Bayes word problem. And I'm not talking about tricky mental arithmetic: I just ask 'greater than 50% or less than 50%.'"  -- Sarah Constantin Quiet screams, because I already knew that, but still.

I have prevented the Mayan apocalypse. You can all relax now.

Erin:  "What are you getting me for Christmas?" Me:  "A cookie." Erin:  "...can it be an M&M cookie?" Me:  "Sure." Erin:  "So you're getting me a cookie for Christmas."... Me:  "Yeah, if I remember." Erin:  "If you remember?  How romantic." Me:  "So what am I getting for Christmas?" Erin:  "Forgiveness." (Actually, I'm getting her an M&M cookie and she's getting me a blueberry muffin. Eat that, O'Henry.)

On a related note, while watching the "Riddles in the Dark " section of _The Hobbit_ (needed much poorer illumination, really), I was impressed by how the filmmakers interpolated a children's book "Sure, they play riddles" that would've seemed odd on-screen, into "Smeagol is lonely and hasn't had a chance to play riddles in ages" that made perfect sense in a grownup movie. However, I was - seriously - thinking, "You know this is Gollum's ring. He's only chasing you because you have his ring. Does it even occur to you to give it back to him?  It's not yours, you shouldn't take it."  Like, the whole time Gollum is hunting Bilbo, I'm thinking, "Are you going to give him back his ring?"  Sure, it's not strategically wise if you *know* it's the One Ring, but if not, how is it okay to just take other people's stuff?

Orcs, trolls, and goblins in _The Hobbit_ seem much more sentient than the ones in _LotR_. I found myself much more disturbed by the 'good guys' remorselessly slaughtering them, and felt a strong impulse to arrest Thorin.

Haunting - reminiscent of Mark Morgan's _Planescape Torment_ soundtrack (which was also, ahem, good). Definitely not all of Hermione's character, and definitely part of it.

Yvain's guide to maximizing purely biological factors determining your baby's intelligence - iodine, eating fish late in pregnancy, avoid licorice (seriously!) and stay far away from lead paint... and a whole lot more. Send this to any pregnant women or intending couples you know - it may determine whether or not their kid gets to be a mathematician.

AHHHHHHHHHHHHHHH - seriously, what's this logic, "If the king is dead, the country is dead"? Is this some kind of blatant selfishness on the part of the President - treasuring their own life more than anything? But if so, as they asked in Dr. Strangelove, why keep it secret? I don't understand how anyone could have thought this was a good idea, and it makes a good point to cite to anyone who thinks that Petrov or Arkhipov weren't historically necessary because there wouldn't have been a nuclear exchange anyway. People are crazy, the world is mad, this doesn't suddenly stop being true when a global nuclear exchange is at stake. AHHHHHHHHHHHHHHH

This... is brilliant...

http://youwillnotgotospacetoday.tumblr.com/ HT Wendy.See Translation

"Sakura didn't really consider herself all that smart. The thing about smart people was that the smarter they were, the more they were aware of how little they actually knew. They didn't act arrogant because they thought they were smarter than other people, they acted arrogant because if they were stupid then someone who couldn't do fractions had to be *really* stupid."

I don't understand why Scott Sumner doesn't snap and try to strangle everyone who tries to increase fiscal stimulus and decrease monetary stimulus at the same time. "QUICK!  FLOOR THE ACCELERATOR AND HIT THE BRAKES!"

Contrary to what a lot of us would intuitively believe, to be perfectly average is to be godlike.

From a comment on LessWrong about whether LW needs a new king: * Is he willing to improve LW, but not able? Then he is not a dictator. Is he able, but not willing? Then he is not benevolent. Is he both willing and able? Then whence cometh suck? ... Is he neither willing nor able? Then why call him God? * This... this is one of the most awesome things I've ever heard stated as a predicate of which I am the subject. To put it in the form of an Umeshism, if nobody has ever applied an analogue of the Riddle of Epicurus to you, you're not being godly enough.

Newtonmas is coming up!

To understand why I turned out the way I did, you first need to realize that my father always sang the Darth Vader theme music while changing any of his children's diapers, in the hope that his children would someday feel a mysterious and dreadful apprehension upon seeing Darth Vader.

"YOU CAN'T OPT OUT OF SOCIETY!  You can't realistically opt-out of government, of social networks or other social institutions. You can't be expected to carry the burden of a parallel technological progress that does everything in the mainstream MINUS the inconvenient, or imperfect. You can't be expected to string up telegraph wires that run parallel to Western Union's, just to run messages that they can't censor. That's a ridiculous waste of human effort. We don't ALL have ...to build cars; we make factories that comply with a reasonable & shared common sense!  The pragmatic realities of scarce time force me to assimilate, or be assimilated. THERE ARE NO PARALLEL EARTHS." Gavin Morgan, in response to someone who asked "So... who is forcing you to use it?" in response to someone swearing at Apple iTunes. Also applies to many other 'Just opt out' responses to complaints, especially the good old, 'If you don't like taxes, move to the nonexistent country where you don't pay any.' I think the overall thesis is something along the lines of "Since there's only room for so many companies, the companies that do exist are a kind of public good and public policy and it makes perfect sense to complain about them, since we can't actually opt out and are de facto forced to use them."  Just remember, those companies aren't exogenous forces - they're a product of stupid consumers, just like Congress is a product of stupid voters; other people making bad buying decisions have negative externalities for *you*.

A test for the strength of Haidt's five moral emotions - how much money would it get you to do (a) vs. (b)?  What strength of emotion do you feel for each of the five comparisons? Some of these clearly just aren't optimized for me as an audience, but maybe that's part of the point. 1a. Stick a pin into your palm.... 1b. Stick a pin into the palm of a child you don't know. (Harm.) 2a. Accept a wide-screen TV from a friend who received it at no charge because of a computer error. 2b. Accept a wide-screen TV from a friend who received it from a thief who had stolen it from a wealthy family. (Fairness.) 3a. Say something bad about your nation (which you don't believe) on a talk-radio show in your nation. 3b. Say something bad about your nation (which you don't believe) on a talk-radio show in a foreign nation. (Community.) 4a. Slap a friend in the face, with his permission, as part of a comedy skit. 4b. Slap your minister in the face, with his permission, as part of a comedy skit. (Authority.)  (Substitute Richard Dawkins or someone else you respect. -EY) 5a. Attend a performance-art piece in which the actors act like idiots for 30 minutes, including flubbing simple problems and falling down on stage. 5b. Attend a performance-art piece in which the actors act like animals for 30 minutes, including crawling around naked and urinating on stage. (Purity.) From:  http://query.nytimes.com/gst/fullpage.html...

The Virginity Tracking Game! Logic:  Obviously, when somebody *takes* your virginity, they then *have* your virginity until someone else takes it. Lemma 1:  If everyone starts out a virgin, any act that exchanges virginities ends with everyone still a virgin. (Though see Footnote 1.)... Rule 1:  To simplify tracking, we will say that virginities are only exchanged when somebody has "sex" (see Rule 2) with a person they have never had sex with previously. Lemma 2:  Virginities never retrace the same line segment of the graph twice, and as a special case, don't swap back and forth repeatedly. However, they *can* traverse a novel path to end up with their originator. Rule 2:  Between different sexes, virginity transfers in any act where genitals touch (condoms, male or female, do not prevent touching) and at least one person has an orgasm. Between the same sexes, anything counts so long as both genitals are stimulated during the act. Question 1:  Who has your virginity now? Question 2:  Whose virginity do you have? Question 3:  Can you identify any case in your local poly-graph of a looping virgin - any virginity which has traversed a path which crosses its first originator? Footnote 1:  To prevent the one-way accumulation of multiple virginities into a single person - in which case, all of the world's virginity might well collapse into a single 'super-virgin' over time - all acts of group sex must be decomposed into binary acts among the participants. If nobody remembers who did what to who, cycle virginities among participants in alphabetical order, starting from the lexicographically first full name transmitting its virginity to the alphabetically second name, etcetera. All names will be considered transliterated into the dominant language of the country in which the act was performed.

Alleged herein that high-end Jewish achievement on National Merit Scholarship semifinals has completely collapsed in the last 13 years. US Math Olympiad top scorers collapsed from 40% in the 70s and 1/3 in the 80s & 90s to 2.5% in the 00s. Putnam from 1/3 to 10% and not a single Jewish name in the last 7 years. Physics Olympiad 25% to 5%. !!! See the sections "Asian-Americans and Jews" and "The Strange Collapse of Jewish Academic Achievement". This was linked from Marginal Revolution, not sure how that compares up with the obvious alarm signal in the domain name.

It's an amazing coincidence that we live in a universe *without* time travel. What could this be hinting at?

How to definitively settle the moral question of abortion in J. K. Rowling's Potterverse:  See if performing an abortion can be used to create a horcrux. (Credit: J4k0b42 on /r/HPMOR.)

I'm worried that despite the horrible, awful, no-good, very bad monetary policy embodied in Bitcoin, it's going to win out because of sheer convenience which would be VERY NOT GOOD. Cryptographers, I deliver you this urgent challenge:  Come up with a distributed crytocurrency, with no central authority that can potentially be targeted to destroy all stored value, which automatically implements NGDP level targeting a la Scott Sumner.

"Frankly, any value system which says "I'd rather have all life destroyed then everyone live under a value system slightly different than my own" seems more like something out of the worst sort of utopian fanaticism than anything else. One of the major ways human society has improved over time and become more peaceful is that we've learned that we don't have to frame everything as an existential struggle. Sometimes it does actually make sense to compromise, or at least, wait ...to resolve things. We live in a era of truly awesome weaponry, and it is only this willingness to place the survival of humanity over disagreements in values that has seen us to this day. It is the moderation of Reagan, Nixon, Carter, Kruschev, Breznev, Andropov and others that we are around to have this discussion instead of trying to desperately survive in the crumbled, radioactive ruins of human civilization."     -- JoshuaZ on LW

Gerald Crabtree: If selection pressures have eased off over the last 3,000 years, then modern humans probably have at least an extra 2-3 important IQ-affecting deleterious mutations, and a genetic citizen of Athens would be one of the brightest people around if born today. http://bmi205.stanford.edu/_media/crabtree-2.pdf I don't buy it, partially from modus tollens, but mostly because of other work indicating that selective pressures have if anything sped up. Media completely fails to comprehend basic semantic content of paper: http://www.huffingtonpost.com/.../humans-getting-dumber-stanf...

Ordinals make so much more sense now that I've realized that w^(w + 1) is like totally an ordinal and it comes after w copies of w^w. *Every* single time I've seen the approach to e0 described in text, it always goes straight from w^w to w^w^2, if not directly to w^w^w. Kind of embarrassing in retrospect that I missed it, but it's making things a lot clearer.

I am thankful to be born into an era where it's possible to make a huge difference, to have won the genetic lottery on writing capacity allowing me to communicate with many more people than stereotypical isolated geniuses, and to be supported in my quest by people who get less fame for it than I do. I am thankful that the books I read as a child set me up to expect most of my life's hardships and not be emotionally set back by them, that my situation is so much better than Isaac Newton who didn't have air conditioning or girlfriends or the hope of immortality, that I seem to be getting away with my zero-angst theory of heroism, and that it actually looks possible to hack root permissions on my future light cone. I mean, that last one in particular really seems like a frequently overlooked and LARGE point of gratitude.

@Panacea:  Do we believe this?  Large meta-study alleges that 3 drinks/week decreases all-cause mortality by 17%. No randomized studies but they allegedly controlled for SES. I find myself highly skeptical. http://squid314.livejournal.com/342696.html

This... I can't even imagine. There is a lower place. Selling industrial bleach as a remedy to parents of autistic children, to be administered every 2 hours for 72 hours. Why do we even have a fucking FDA?  Why the fuck do we even have a fucking FDA if they add a billion dollars to the cost of developing each real medicine and they can't stop THIS?

Miracle Mineral Supplement is my new go-to example for Bad Things happening to people with low epistemic standards. "MMS" is a supposed cure for everything ranging from the common cold to HIV to cancer. I just saw it recommended in another Facebook thread to someone who was worried about malaria symptoms. It's industrial-strength bleach. *Literally* just bleach. Usually drunk, sometimes injected, and yes, it often kills you. It is every bit as bad as it sounds if not worse. This is *beyond* Poe's Law. Medieval blood draining via leeches was far more of an excusable error than this, they had far less evidence it was a bad idea. I think if I was trying to guess what was the dumbest alternative medicine on the planet, I still would not have guessed this low. My brain is *still not pessimistic enough about human stupidity.*

The Jewish word "Apikoros" - someone cut off from the Jewish people, receiving no share in the World to Come - apparently derives from... to appreciate this, you have to keep in mind that "Apikoros" is a word I knew from childhood as referring to this evil villain atheist type person... derives from... goddamn EPICURUS. If I had known this 12 years earlier, I would've made "Apikoros" my Internet handle.

/r/math:  Multiple reports of students who have to use a calculator to multiply by 1. One commenter reports multiple math-tutoring students who had to use a calculator to multiply by 0. Though apparently... while some of them sort-of know better, they don't trust themselves, but they trust the calculator. In a way, it's hard to argue with that.

So does anyone else, when they get change in the store, leave any coins smaller than a quarter on various places like window ledges and so on, so as to teach people that they can get small amounts of money by searching random objects in the environment?

"You can't prove I'm wrong!" is false. Proof: Analogously to the Godel Sentence G<->~[]'G' which asserts "I am not provable in Peano Arithmetic", construct: R<->~[]~R (Trans. "There does not exist a proof of my negation." / "It is possible that I am true." / "You can't prove I'm wrong.") Negating both sides, ~R<->~~[]~R so... ~R<->[]~R (Trans. "I am false iff I am provably false.) By Lob's Theorem, since PA proves []~R -> ~R, PA proves ~R. QED. (Ref: http://yudkowsky.net/rational/lobs-theorem) Exercise for the reader:  Abbreviating ~[]~x as <>x, standing for "x is possible" or "x is not necessarily false", show that even the weaker claim "It is possible that I am possible" or W<->(<><>W) is also provably false in any system powerful enough to represent Peano Arithmetic. (From some fun with Marcello, Paul, and Mihaly.)

My brain seems to have trouble updating. I'm *still* shocked that Yvain is such a good writer.

"What does not make you stronger, kills you." So which other proverbs are transparently false once you transform A->B to ~B->~A?  #modustollens

(sing to standard melody) When you wish upon a star It makes no difference who you are When you wish upon a star It... does... n't... work!

"The brain needs to fit 10^14 connection weights in only 10^9 seconds."  -- Geoffrey Hinton

It's fascinating to read this debate, and experience the sensation of complicated arguments on both sides sounding reasonable, not knowing who's right, and switching my mind back and forth as I read each successive argument. I'm too ignorant of monetary theory to know who's obviously coherent-and-correct and who's talking total nonsense. It's strange to think that this must be how it feels like to other people when they hear arguments about Bayesianism vs. frequentism, or many-worlds vs. Copenhagen, or central banking vs. the gold standard.

"First, we've learned that it helps to transform probability estimates into log-odds before averaging them. Weights can then correct well for predictable over- or under-confidence. We've also learned better ways to elicit estimates. For example, instead of asking for a 90% confidence interval on a number, it is better to ask for an interval, and then for a probability. It works even better to ask about an interval someone else picked. Also, instead of asking people directly for their confidence, it is better to ask them how much their opinion would change if they knew what others know."

Apparently Tyler Cowen *really* thinks I need more girlfriends. (Marginal Revolution linked my OKCupid profile again.)

Wake up. Eat salmon for breakfast. Find out my OKCupid profile has been linked from Marginal Revolution.

Sunday night waiting for the train, I sit down on a bench near three college students - at least I assume they were college students. Overheard:  "Of course the real root of the problem is private property."  "Yes, private property is the root of all evil."  "But you can't tell people that, they won't believe you." People like this actually exist. Still. Apparently. And I did not steal their jackets, ask them for their jackets, say, "That's why I never lock my door and put a 'FREE STUFF' sign on it", or troll them. I just stood up, quietly walked away, put in earplugs so I wouldn't overhear anything from further away, and checked to make sure I wasn't on the same train car as them. Every now and then, I worry that the rationalist community hasn't reached the threshold of "not being incredibly stupid" yet. And then something reminds me that if you hang around rationalists all day long, you can end up with a distorted concept of what actually constitutes "stupidity" on the rest of the planet.

To clarify a previous status message:  There's such a thing as suffering. There's even suffering that can't and shouldn't be avoided once the disaster is incurred, like the ache of losing a friend. But I don't believe in suffering that's intellectually deep. Religion is sustained by people taking "I talked to God" more seriously than "I talked to God in my hairbrush" - thinking that it's a deeper, more solemn debate associated with more prestigious figures - so that you don't lose face from being dumb enough to associate with the question. This is fundamentally the opposing force when it comes to finally getting over religion - that people think it's intellectually deep to argue about. So, too, the concept that suffering can be intellectually deep is nothing but an obstacle to ending suffering. If a relative died - that's pain. If you're lonely because you have no mate - that's pain. If you have a perfectly good mate and you're existentially lonely because human beings are not telepathic *yet*, then you have too much spare time on your hands. Or maybe some kind of neurotransmitter imbalance is causing you real pain and requires Prozac or ketamine. But what you do *not* have, in *any* of those cases, is any kind of intellectual merit for complicating your suffering further. You want deep, study math. Don't decorate your suffering with frilly ribbons of complexity like it's your private Christmas tree.

Overheard in the bedroom (with Shannon):  "Stop pretending to be a mortal female!  It's creepy!"

I don't believe there's any such thing as intellectually deep suffering. If you have enough computing power and reflectivity to figure out exactly how to suffer correctly, you've got enough spare energy not to suffer in the first place.

More things philosophers have debated...

Holy **** Yvain has turned into a great writer.

Summit '12 videos are online!

I'm having trouble remembering why I used to have a shrieking existential horror of buying flowers for Erin. Does anyone (preferably male) who still has this shrieking existential horror want to comment?

More screaming. "In Math You Have to Remember, In Other Subjects You Can Think About It"

"A total of 97 Members of Parliament were asked this probability problem: if you spin a coin twice, what is the probability of getting two heads? Among Conservative members, 47% gave the wrong answer, which is disappointing enough. But of the 44 Labour MPs who took part, 77% answered incorrectly." AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIIIIIIIIIIIIIIIIIIIIIIIIIIEEEEEEEEEEEEEEEEEEEEEEEEEEEEE... IT GETS WORSE "The survey also asked MPs if they generally felt confident when dealing with numbers - 76% of Tories said they did 72% of Labour MPs surveyed expressed confidence"

"Exactly how many people she infected or killed will never be known... Three deaths have been definitely attributed to her, with estimates running as high as 50... Some difficulties surrounding her case stemmed from Mallon's vehement denial of her possible role, as she refused to acknowledge any connection between her working as a cook and the typhoid cases." Denial. It kills everyone around you.

Caffeine doesn't seem to do anything to me that I can tell. Glucose and sugar and fructose don't seem to produce any energy boost. Drinking a protein shake (made from protein powder with basically pure protein) produces an energy boost that lasts for an hour or two, but then it wears off and I have to drink another one. My observations so far would be compatible with the hypothesis that sugar is not metabolically available to anything but fat cells, fat without sugar causes me to feel temporarily less hungry but doesn't result in any net weight gain or weight loss or energy boost, and only protein actually gets fuel to my brain somehow.

"Nowadays I just hear 'Cold and calculating' as a very strong compliment. Consider this 'opposite' version:  'Heated and mathematically-illiterate'." -- DaFranker

So I'm on the train, and this tall Oriental woman walks in. She's wearing some long, cylindrical-ish baglike object on her shoulder, and my brain, which has read too much manga, instantly says, "That's a sword."  Because that's how every sword gets disguised, in all the manga... I ignore my brain, of course, and then it requests that I go over and find out what it actually is, but you know, that probably isn't going to make a difference, because it's an equally amusing anecdote on Facebook either way, right?  But then it looks like the woman is getting off at the same stop I am, so I stand up a bit early, go over to her, and say, "Pardon me, I can't help but ask, what is than in the bag on your shoulder?" Her: "A sword." Me:  "Wait, did you just say a sword?" Her:  "Yes." (Pause.) Me:  "Is it a wooden sword?" Her:  "No."

The start of a new Sequence, or two.

"It never hurts to flatter an NPC." -- Sir Poley #horribletruths

I think I'm just going to give up on saying people's names until I stop getting them wrong. It's too embarrassing.

"I should have figured you were here. This is an expanding universe, and there is travel which exceeds the speed of expansion. You broke causality!  This is why we never will not have had nice things!" -- Glorious Shotgun Princess

Dear Merlin in a horse-leather jumpsuit. I'm tempted to add rationality to this, but then the universe would implode.

Recently, I wanted to spend some time with a certain lady in a bedroom... but the only available bedroom, her primary's, had doors with many transparent glass windows in them; she remarked that she and her primary were considering trying to put up curtains across the door. At some point thereafter, two large moving boxes were stacked up in front of the door, a blanket had been spread over them, a sitting pillow had gone on top of them, and a bed pillow had been stacked on top... of that. It wasn't perfect privacy but it at least meant somebody would need an effort to see in, which in the generally libertine environment was as much as we cared about. I realized afterward that I'd just turned into Harry in Chapter 16 of HPMOR, except that instead of asking how I could use every object in the room to kill someone, I was glancing at every single object in the room around me and reinterpreting it in terms of how I could use it to achieve my current objective of "block visibility into the room". I wonder if this kind of thinking has anything to do with agentiness - it certainly has something to do with Munchkinism.

I hope I didn't laugh too loud on the bus at Luke Meuhlhauser Facts. True fact:  "Lukeprog's love life" is widely acknowledged to be the ultimate trump card of Cards Against Rationality. http://squid314.livejournal.com/330825.html

I'm not sure what point this author is trying to get across, but I think he's in favor of parsing HTML using regular expressions.

Does anyone happen to know if we've got any anthropological evidence on when in hominid evolution pair-bonding / mate provisioning developed / was developing?  So far, the only thing I've come across is that sexual dimorphism diminished from Australopithecus to Homo, which suggests that it started pretty darned early.

"I expect there's probably also a signaling explanation for why True Love isn't tolerated. Maybe if anyone were allowed to show True Love, everyone would fake it and there would be an arms race or something? I can't put my finger on it right now, but I bet it's a good one. On the other hand, I'm not sure it's good enough. Banning the expression of True Love seems supervillainish enough that it's hard to imagine what could justify it. Actually, I think I support a more general... Supervillain Test: if a supervillain were plotting a specific social change, would we assemble a band of scrappy yet loveable teenagers with mysterious powers to thwart him? If yes, we should want to thwart the change even if it happens organically as a result of impersonal forces."   -- Yvain, http://squid314.livejournal.com/328800.html Yvain used to be a good writer, but that was three years ago. I think he might be on a trajectory toward greatness now.

"In my experience almost everyone misses almost every hint." -- Andrew Rettek He was talking about romantic escalation, but it also applies to writing. You need to drop an *awful* lot of hints to get 50% of the target audience to notice anything that isn't flat-out said straight out.

Seth Baum's new think tank, just starting up apparently. Haven't checked it out yet, but at least he's in the right ballpark as opposed to the many, many, many, many people in the wrong ballpark.

I'm not wondering any more why biotech progress has been so slow. This seriously sounds like if we got all the John Schloendorns of the world together in one small country and got all the regulators out of their way and somehow got them the venture funding required just to *develop* the biotech magic, lots and lots of people would fly there to have biotech magic performed on them. Has anyone thought about this in more detail?  What kind of system would need to be set up to gather only the data on a drug which a Bayesian would actually need to establish positive expectation of utility, and screw the regulators?  I don't ordinarily think in terms this utopian, but if Patri actually gets his Honduran city, this sort of thing might not be as impractical as I thought.

This comment on Hacker News sure is getting tweeted a lot (it has apparently been dubbed the "Yudkowsky Ambition Scale").

"To feel relieved or to feel like you understand is usually your own misunderstanding. Humans aren't something that can be changed so easily. If you have a huge problem, don't relieve yourself of it. Hold it against your chest and march on. That's all." -- Mahou Sensei Negima; spoken to a young boy after he was briefly reunited with an illusion of his long-lost father. #epiphanyjunkieism

Sometimes I still wonder at, smile, treasure this feeling inside myself of finally living my life the way some part of me always knew it was meant to be lived. The way, maybe, that I was acculturated to believe people ought to live by reading about the lives of the characters in my books, growing up with those authors' visions of how reality should be; or maybe it flows from the same source inside me as from within those authors' own hearts. The vision has to start somewhere, after all. I'm not talking about saving the world. I've always intended to do that for as far back as I can remember, though when I was nine I had no idea what my options were and thought in terms of extraplanetary colonization and asteroid mining. Being engaged in saving the world is a background state; it doesn't feel like anything in particular because I have no alternative to contrast it to. No, I'm talking about the wonderful bright lifting feeling that I still get, about a year and a half into the adventure, when I read a fanfiction with polyamory in it and a character says "We're going to need a schedule, and really big beds, or maybe just lay down some mattresses on the floor" and I've been there. There's a mattress on the floor in front of me right now, in fact. I know that not everyone feels this way about it, and not everyone has to feel that way. But for me - Everything is back to normal for the first time, the way it should be.

"When you have siblings, aren't you expected to love all of them equally, and aren't you expected to love both your parents all the same? A teacher is required not to have any favorites, and a prime minister not to have any favorite regions! And yet, when you have romantic feelings for two people at once, everyone demands you to pick one and forget all about the other one! That's not what love is! Love is not about forgetting your loved ones just because there's someone else!" -- "Unequally Rational and Emotional" by OverMaster

So I just spent the last week on the attack phase of the Dukan diet - meaning that I ate literally nothing except meat, of the leaner sort, hard-boiled eggs, and protein-powder drinks. I'll find out soon whether that produced any lasting weight loss. Meanwhile, let's play a game called "Guess what the keto sticks said about whether I was in ketosis." On the one hand, the naive view which metabolically privileged people think constitutes a "law of thermodynamics", says that since I wasn't eating any carbs, and some fat, and I was often feeling hungry... my body must have been burning fat. If the body requires more energy than it intakes, it burns fat; and my caloric intake dropped a lot, so a lot of fat should've been burned. This theory would predict high ketones. Then there's the pessimistic view, which says that there's nothing which contravenes the laws of physics in supposing that someone's fat cells are simply malfunctioning and refusing to release fat. The pessimistic hypothesis would predict that my body would have ramped down its metabolic activity, consumed muscles instead of its stored fat, and otherwise done basically anything *except* release fat and burn it. This theory would predict fewer ketones than baseline, because on my baseline I was eating more dietary fat and burning it. What do you think the result was?  I invite everyone who goes around talking about their favorite diet or how human metabolisms work to stake their prediction now.

Someday, I hope, there will be a huge political controversy about whether or not a man who doesn't want to be a father, can force his partner to have an abortion; or whether, once he files paperwork offering to pay for her abortion, he is immune from child support if she chooses to keep the child. (Reasoning:  Try to imagine that you're a woman who made an appointment to get an abortion, but one dark night while you were sleeping, the Catholic Church surgically removed the f...

Conversations with Lindsey:  "Don't ever do that to a virgin's foot, because then they'll have lost their virginity through their foot."

A camera so high-speed, it can photograph the motion of light itself (scattering from a single pulse of laser light as it moves through e.g. a coke bottle).

From a SPARC conversation about Bitcoin:  "There are two kinds of libertarians, libertarians who read econblogs and understand basic economic theory and comparative advantage and so on, and libertarians who think the US should go back to the gold standard. These are completely different species and you really shouldn't confuse them."

Due to (a) the oil refinery fires and (b) living in El Cerrito, I set out for SPARC with a cloud of darkness and fire behind me.

I am so glad that I'm not trying to go to Burning Man after SPARC. No offense.

Dan Cathy, president of Chick-fil-A, makes a comment about gay marriage violating the will of a nonexistent God... and now people want to boycott Chick-fil-A, even after the company issues a statement saying that they have nondiscriminatory policies?  If the company itself has done something wrong, people should say so. Otherwise companies should have a right to dissociate themselves from the personal follies of idiots in their management; and I say this from personal experience as an idiot associated with the management of two important nonprofits.

Why do universities teach in 3-month or 4-month units instead of 2-week units?  At Minicamp we try to boil down a skill into 90 minutes, which probably *isn't* long enough, but I don't see 3 months being an appropriate size for a skill-practice chunk. Is this is as silly and we-don't-care-in-the-slightest-about-actually-learning as it seems, like universities not using spaced repetition or post-tests after the unit finishes?  Or is there a hidden logic to it?

Here at last!

Political debates are ridiculously more fun to read when they're not between frightened politicians.

Fun Fact #2:  Ricardo's Law of Comparative Advantage implies that *all* unemployment is caused by transaction overhead costs. There is *always* some comparative advantage, something you could be trading your labor for instead of letting those hours die unutilized... except that to legally trade an hour of my labor for an hour of your labor, I have to pay 37% marginal tax on my wages for that hour, and then you have to pay income tax on the money I pay you, plus sales tax, and you need to have a business license. Economists have worked out other forms of taxation that wouldn't prevent as much trade, e.g. a land value tax. Nobody cares.

Ricardo's Law of Comparative Advantage. If you can't explain how it works, you shouldn't be allowed to vote.

+1 Bayes point to Shannon in our ongoing debate on whether all behaviors / internal voices are tied up with "positive intent", i.e., some sort of constructive or protective motivation. I was citing "bitterness", and particularly the emotion that I used to feel when I participated in flame-wars, as a purely negative intent - it doesn't feel good even after you do it; it has "urge"-nature but no "satisfaction". This makes it harder to deal with than, say, the desire to eat a muffin - you might be able to trade off the promise to eat a small, high-quality piece of candy later; but if a part doesn't want anything positive, there's nothing you can promise it as a tradeoff. I still think this is true to some extent of "bitterness", but Shannon did point out that on a sufficiently short timescale, not giving in to the urge to flame results in a frustrated urge, and bitterness can be seen as having the positive intent of avoiding that very-short-term frustration. This is useful because it suggests trying standard anti-hyperbolic-discounting techniques against the urge to participate in a flamewar or be rude to idiots.

This was, in fact, reasonably epic.

"Save the entire Tegmark Level IV multiverse or I'll tickle you until you do!"  (Pause.)  "I think I just made the most grandiose, hard-to-perform tickle threat in the entire history of time."  -- further adventures with Shannon Friedman

From a conversation with Shannon Friedman where she tried to teach me the "Yes, and" technique: "I've probably destroyed the negative sectors of my brain with all this relentless positivity. I'll never be able to think of anything negative ever again."

"Buddhism IS different. It's the followers who aren't."  The main article isn't about Buddhism, but this struck me as sufficiently profound to be worth posting in its own right. Really, a lot of religions *are* genuinely different from each other - it's just that religious people are the same everywhere. Not all the same as each other, obviously, but drawn from the same distribution.

They found the Higgs boson!  I wasn't expecting that. I guess now I've got to start believing in dark matter and dark energy too.

I wish more people would remember this, especially on Less Wrong. Remember, any form of attention whatsoever, including a reply of any sort, equals brain-reward and causes a behavior to repeat.

I cannot possibly, possibly give enough praise to Jean-Baptiste Huynh. Another thousand educational improvements like this and we would be living in a different world.

From Keenan and Circadia's wedding. Sadly, the version of this with bubbles (from Kevin's bubble machine) in the background didn't come out well - it was too blurred. Which is a real pity, because I was half naked, surrounded by moving glowing lights, and had bubbles in the background, which would've made that a photograph of my magical girl transformation sequence.

And this is the other wedding.

Lindsey's paleo cake recipe. I found it oddly sustaining as well as tasty. Maybe my body likes dextrose?

"Not every marriage is a deeply solemn affair. If there's one thing we can all learn from Japanese television, it's that. Sometimes the alien spaceship just crashlands in your backyard and the two of you accidentally end up married according to the traditions of the galactic royal family, but you're only sixteen years old, so you have to tell everyone at your school that it's just your cousin from Osaka who's staying at your house."  -- My opening words from Michael Keenan ...and Circadia St. Clair's wedding ceremony. Willvia's wedding ceremony, which I also officiated, was a lot more deeply solemn. I emphasize this so that people don't think I *only* do silly weddings. But still, someday - someday when it's not a deeply solemn wedding, and both participants are fans - someday, I will write and officiate a full-scale, all-out, no-holds-barred TV Tropes Wedding.

Psychopaths as personal analysts who won't get all indignant at you - this is a key thing that makes rationalists more pleasant to be around; it hadn't occurred to me before how easy it would be for psychopaths. http://www.twitlonger.com/show/dh5l3q

From a Less Wrong thread on "heroism" (as possibly / arguably corrupted).

Paul Bohm:  "Ethics gets weird when you try to account for future results."

In the future, advanced AI implants are common and Earthly life is colonizing the stars. Humanity has organized itself using Governance, a system of Representatives - some Artificially Intelligent, some human - that conglomerate in order to publicly debate, in a fashion visible to all, any important policy matter. One of these Representatives is Governance: Magical Girls. After hiding for centuries, Earth's magical girl population finally revealed itself in the course of fending off an attack on humanity by a technologically superior species, the Cephalopods. Cephalopod attacks continue, and magical girls are now conscripted into military service immediately after they make their contracts. And Akemi Homura has gone missing. "To the Stars", by Hieronym.

Andrew's quote below is from someone who believes die rolls aren't random - they give worse results for *him*.

Remarkably well-written defense of, yes, diagnosing bad students and debugging them, because that can in fact be better than just slapping them with a C report card.

Explicitly inspired by Methods of Rationality. I thought it was quite good.

Moving to Berkeley (actually El Cerrito, a bit further north) on Saturday. And will try like heck to start the next series of Methods updates before then.

Jan 26, 2012. On a carb-free diet, Erin smiles in front of her Birthday Chicken. The candles show her age, 26, in binary. (She's decided to start aging backward - last year she was 27. As for me, in September I celebrated my 4th annual 29th birthday.)

